# app.py â€” Streamlit: chá»n checkpoint trong thÆ° má»¥c Models/ rá»“i dá»± Ä‘oÃ¡n áº£nh
import io


from pathlib import Path
from typing import List, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
from torchvision import transforms
import streamlit as st

# === cÃ¡c kiáº¿n trÃºc báº¡n cÃ³ ===
from model.mtl_cnn import mtl_cnn_v1
from model.mobilenet_v4 import CustomMobileNetV4
from model.efficientnet_b0 import CustomEfficientNetB0

MODELS_DIR = Path("Models")
IMG_TYPES = ["png", "jpg", "jpeg", "bmp", "tif", "tiff", "webp"]

CLASS_NAMES = [
    "BÃ¡nh bÃ¨o","BÃ¡nh bá»™t lá»c","BÃ¡nh cÄƒn","BÃ¡nh canh","BÃ¡nh chÆ°ng",
    "BÃ¡nh cuá»‘n","BÃ¡nh Ä‘Ãºc","BÃ¡nh giÃ²","BÃ¡nh khá»t","BÃ¡nh mÃ¬",
    "BÃ¡nh pÃ­a","BÃ¡nh tÃ©t","BÃ¡nh trÃ¡ng nÆ°á»›ng","BÃ¡nh xÃ¨o",
    "BÃºn bÃ² Huáº¿","BÃºn Ä‘áº­u máº¯m tÃ´m","BÃºn máº¯m","BÃºn riÃªu",
    "BÃºn thá»‹t nÆ°á»›ng","CÃ¡ kho tá»™","Canh chua","Cao láº§u",
    "ChÃ¡o lÃ²ng","CÆ¡m táº¥m","Gá»i cuá»‘n","Há»§ tiáº¿u",
    "MÃ¬ Quáº£ng","Nem chua","Phá»Ÿ","XÃ´i xÃ©o",
    "banh_da_lon","banh_tieu","banh_trung_thu"
]
NUM_CLASSES = len(CLASS_NAMES)

# báº¡n train khÃ´ng normalize â†’ giá»¯ nguyÃªn
TRANSFORM = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

def list_checkpoints(models_dir: Path) -> list[Path]:
    models_dir.mkdir(parents=True, exist_ok=True)
    return sorted([p for p in models_dir.iterdir()
                   if p.is_file() and p.suffix.lower() in (".mtl", ".pt")])

def guess_arch(ckpt_name: str) -> str:
    n = ckpt_name.lower()
    if "mobilenetv4" in n or "mobilev4" in n:
        return "mobilenetv4"
    if "efficientnet" in n or "_b0" in n:
        return "efficientnet_b0"
    return "mtl_cnn"

def _read_state_dict(ckpt_path: Path, device: str):
    obj = torch.load(str(ckpt_path), map_location=device)
    if isinstance(obj, dict) and "net" in obj:
        state = obj["net"]
    elif isinstance(obj, dict) and "state_dict" in obj:
        state = obj["state_dict"]
    else:
        state = obj
    new_state = {}
    for k, v in state.items():
        new_state[k[7:]] = v if k.startswith("module.") else v  # strip "module."
    # náº¿u k khÃ´ng báº¯t Ä‘áº§u "module.", dÃ²ng trÃªn váº«n giá»¯ nguyÃªn v
    return { (k[7:] if k.startswith("module.") else k): v for k, v in state.items() }

def build_model_by_arch(arch: str, num_classes: int) -> nn.Module:
    if arch == "mtl_cnn":
        return mtl_cnn_v1(num_classes=num_classes)
    if arch == "mobilenetv4":
        return CustomMobileNetV4(num_classes=num_classes, pretrained=False)
    if arch == "efficientnet_b0":
        return CustomEfficientNetB0(num_classes=num_classes, pretrained=False)
    raise ValueError(f"Unknown arch: {arch}")

@st.cache_resource(show_spinner=False)
def load_model_cached(ckpt_path: str, arch: str, num_classes: int):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = build_model_by_arch(arch, num_classes).to(device).eval()
    state = _read_state_dict(Path(ckpt_path), device)
    try:
        model.load_state_dict(state, strict=True)
    except Exception:
        missing, unexpected = model.load_state_dict(state, strict=False)
        warn = []
        if missing:    warn.append(f"missing: {len(missing)}")
        if unexpected: warn.append(f"unexpected: {len(unexpected)}")
        if warn: st.warning("Checkpoint khÃ´ng khá»›p hoÃ n toÃ n â†’ dÃ¹ng strict=False. " + " | ".join(warn))
    return model, device




@torch.no_grad()
def predict_image(model: nn.Module, device: str, image: Image.Image, topk: int = 3):
    x = TRANSFORM(image.convert("RGB")).unsqueeze(0).to(device)
    probs = torch.softmax(model(x), dim=1).squeeze(0)
    k = min(topk, probs.numel())
    vals, idxs = torch.topk(probs, k)
    return idxs.tolist(), vals.tolist()

# ================= UI =================
st.set_page_config(page_title="Dá»° ÄOÃN MÃ“N Ä‚N VN", page_icon="ðŸœ", layout="wide")
st.title("ðŸœ Dá»° ÄOÃN MÃ“N Ä‚N VN â€“ BÃ™I QUANG THÃI - 24752551")

with st.sidebar:
    st.subheader("âš™ï¸ Cáº¥u hÃ¬nh")
    ckpt_files = list_checkpoints(MODELS_DIR)
    if not ckpt_files:
        st.error(f"KhÃ´ng tÃ¬m tháº¥y checkpoint trong `{MODELS_DIR}/`.")
        st.stop()

    # HIá»‚N THá»Š TÃŠN FILE NGáº®N, KHÃ”NG CÃ“ 'Models\'
    name_to_path = {p.name: str(p) for p in ckpt_files}
    sel_name = st.selectbox("Chá»n file model ", list(name_to_path.keys()), index=0)
    ckpt_path = name_to_path[sel_name]

    detected_arch = guess_arch(sel_name)
    st.caption(f"Kiáº¿n trÃºc suy luáº­n: **{detected_arch}** (Ä‘á»•i tÃªn file náº¿u muá»‘n nháº­n diá»‡n khÃ¡c)")
    topk = st.slider("Top-K hiá»ƒn thá»‹", 1, 5, 3)
    cols = st.slider("Sá»‘ cá»™t hiá»ƒn thá»‹", 1, 5, 3)
    show_prob = st.toggle("Hiá»‡n % xÃ¡c suáº¥t", value=True)

# load model
model, device = load_model_cached(ckpt_path, detected_arch, NUM_CLASSES)
st.success(f"Model `{detected_arch}` Ä‘Ã£ sáºµn sÃ ng trÃªn **{device.upper()}** â€¢ checkpoint: `{sel_name}`")

# upload áº£nh
files = st.file_uploader("Chá»n 1 hoáº·c nhiá»u áº£nh", type=IMG_TYPES, accept_multiple_files=True)


zip_file = st.file_uploader("Hoáº·c chá»n 1 file .zip chá»©a áº£nh", type=["zip"], accept_multiple_files=False)

images_to_run: list[tuple[str, Image.Image]] = []
if files:
    for f in files:
        try:
            images_to_run.append((f.name, Image.open(io.BytesIO(f.read())).convert("RGB")))
        except Exception as e:
            st.warning(f"áº¢nh lá»—i `{f.name}`: {e}")



if zip_file is not None:
    import zipfile, tempfile
    with tempfile.TemporaryDirectory() as tmpdir:
        zf = zipfile.ZipFile(io.BytesIO(zip_file.read()))
        zf.extractall(tmpdir)
        for p in Path(tmpdir).rglob("*"):
            if p.suffix.lower().strip(".") in IMG_TYPES:
                try:
                    images_to_run.append((p.name, Image.open(p).convert("RGB")))
                except Exception as e:
                    st.warning(f"áº¢nh lá»—i `{p}`: {e}")

# chá»‰ dá»«ng náº¿u SAU HAI KHá»I TRÃŠN váº«n chÆ°a cÃ³ áº£nh
if not images_to_run:
    st.info("ðŸ‘‰ KÃ©o-tháº£ áº£nh (hoáº·c .zip) vÃ o khung trÃªn Ä‘á»ƒ dá»± Ä‘oÃ¡n.")
    st.stop()

# hiá»ƒn thá»‹ káº¿t quáº£ â€” Sá»¬A THá»¤T Lá»€ & TÄ‚NG CHá»ˆ Sá» idx ÄÃšNG VÃ’NG Láº¶P
n = len(images_to_run)
rows = (n + cols - 1) // cols
idx = 0
for _ in range(rows):
    c = st.columns(cols)
    for j in range(cols):
        if idx >= n:
            break
        name, pil_img = images_to_run[idx]
        with c[j]:


            try:
                ids, probs = predict_image(model, device, pil_img, topk=topk)
                st.image(pil_img, use_container_width=True)
                if show_prob:
                    lines = [f"**{CLASS_NAMES[k] if k < NUM_CLASSES else 'class_'+str(k)}** â€” {p*100:.1f}%"
                             for k, p in zip(ids, probs)]
                else:
                    lines = [f"**{CLASS_NAMES[k] if k < NUM_CLASSES else 'class_'+str(k)}**" for k in ids]
                st.markdown(f"**{name}**")
                st.markdown(" â€¢ ".join(lines))





            except Exception as e:


                st.error(f"Lá»—i dá»± Ä‘oÃ¡n `{name}`: {e}")
        idx += 1


