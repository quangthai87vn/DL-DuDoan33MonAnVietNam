# mobilenet_train_enrnptys.py  â€” báº£n chá»‘ng treo & log chi tiáº¿t

import os, time
os.environ.setdefault("TORCH_HOME", r"C:\torch_cache")  # tuá»³ chá»n: nÆ¡i cache model náº¿u cÃ³

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True  # khÃ´ng káº¹t vÃ¬ áº£nh há»ng

torch.backends.cudnn.benchmark = True   # tÄƒng tá»‘c khi input cá»‘ Ä‘á»‹nh

from mobilenet_model import CustomMobileNet  # Ä‘áº£m báº£o weights=None trong file nÃ y!

# ===============================
# HÃ€M TRAIN
# ===============================
def train(train_dir, num_epochs, batch_size, model_path):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ’» Device: {device}")

    transform_train = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    transform_val = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    # ---- Index dataset + log thá»i gian
    print("ğŸ” Äang index dataset...", flush=True)
    t0 = time.time()
    dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)
    print(f"âœ… Index xong: {len(dataset)} áº£nh, {len(dataset.classes)} lá»›p: {dataset.classes} "
          f"in {time.time()-t0:.1f}s", flush=True)

    # ---- Split train/val
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    val_dataset.dataset.transform = transform_val

    # ---- DataLoader 'an toÃ n' cho Windows
    pin = torch.cuda.is_available()
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,
                              num_workers=0, pin_memory=pin, persistent_workers=False)
    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False,
                              num_workers=0, pin_memory=pin, persistent_workers=False)

    # ---- LÆ°u label map
    os.makedirs(os.path.dirname(model_path) or ".", exist_ok=True)
    with open('label.txt', 'w', encoding='utf-8') as f:
        for idx, class_name in enumerate(dataset.classes):
            f.write(f'{idx}: {class_name}\n')

    # ---- Model / loss / optim
    num_classes = len(dataset.classes)
    model = CustomMobileNet(num_classes=num_classes).to(device)  # NHá»š: weights=None trong mobilenet_model.py
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # ---- Thá»­ 1 mini-iter Ä‘á»ƒ phÃ¡t hiá»‡n áº£nh lá»—i sá»›m
    print("ğŸ§ª Kiá»ƒm tra Ä‘á»c 1 batch Ä‘áº§u...")
    try:
        _x, _y = next(iter(train_loader))
        print(f"âœ… Batch máº«u: {_x.shape}")
    except Exception as e:
        print("âŒ Lá»—i khi Ä‘á»c batch Ä‘áº§u. CÃ³ thá»ƒ do áº£nh há»ng hoáº·c Ä‘Æ°á»ng dáº«n sai.")
        raise e

    best_acc = 0.0
    print("ğŸš€ Báº¯t Ä‘áº§u train ...", flush=True)

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for bi, (inputs, labels) in enumerate(train_loader):
            if bi % 10 == 0:
                print(f"  ... epoch {epoch+1}/{num_epochs} | batch {bi}", flush=True)

            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        train_loss = running_loss / len(train_dataset)
        train_acc = 100. * correct / total

        # ---- Eval
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()

        val_loss /= len(val_dataset)
        val_acc = 100. * correct / total

        print(f"ğŸ“ˆ Epoch [{epoch+1}/{num_epochs}] "
              f"TrainLoss: {train_loss:.4f} Acc: {train_acc:.2f}% | "
              f"ValLoss: {val_loss:.4f} Acc: {val_acc:.2f}%")

        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), model_path)
            print(f"ğŸ’¾ Model saved to {model_path} (Val Acc: {best_acc:.2f}%)")

# ===============================
# Cáº¤U HÃŒNH Máº¶C Äá»ŠNH
# ===============================
if __name__ == "__main__":
    train_dir  = r"C:\TRAIN\Deep Learning\vietnamese-foods\Images\Train"  # Ä‘á»•i theo mÃ¡y báº¡n
    num_epochs = 100
    batch_size = 32
    model_path = r".\Models\mtl-mobilenet.pth"  # dÃ¹ng Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i + táº¡o thÆ° má»¥c tá»± Ä‘á»™ng

    print("ğŸš€ Báº¯t Ä‘áº§u huáº¥n luyá»‡n MobileNet...")
    print(f"ğŸ“‚ Dataset: {train_dir}")
    print(f"ğŸ“¦ Model lÆ°u táº¡i: {model_path}")
    print(f"ğŸ§® Epochs: {num_epochs}, Batch size: {batch_size}")

    train(train_dir=train_dir,
          num_epochs=num_epochs,
          batch_size=batch_size,
          model_path=model_path)
