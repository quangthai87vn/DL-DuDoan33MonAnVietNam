{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cd70532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 0: GLOBALS (must run first) ====\n",
    "import os, json, re, math, numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# import model builders (tuỳ file của bạn)\n",
    "from model.mtl_cnn import mtl_cnn_v1\n",
    "from model.mobilenet_v4 import CustomMobileNetV4\n",
    "from model.efficientnet_b0 import CustomEfficientNetB0\n",
    "\n",
    "# 0.1 Nhãn (đúng thứ tự bạn đã dùng khi train)\n",
    "CLASS_NAMES = [\n",
    "    \"Banh beo\",\"Banh bot loc\",\"Banh can\",\"Banh canh\",\"Banh chung\",\"Banh cuon\",\"Banh duc\",\"Banh gio\",\n",
    "    \"Banh khot\",\"Banh mi\",\"Banh pia\",\"Banh tet\",\"Banh trang nuong\",\"Banh xeo\",\"Bun bo Hue\",\"Bun dau mam tom\",\n",
    "    \"Bun mam\",\"Bun rieu\",\"Bun thit nuong\",\"Ca kho to\",\"Canh chua\",\"Cao lau\",\"Chao long\",\"Com tam\",\"Goi cuon\",\n",
    "    \"Hu tieu\",\"Mi quang\",\"Nem chua\",\"Pho\",\"Xoi xeo\",\"banh_da_lon\",\"banh_tieu\",\"banh_trung_thu\"\n",
    "]\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# 0.2 Đường dẫn & cấu hình\n",
    "\n",
    "ROOT = \"C:/TRAIN/Deep Learning/vietnamese-foods/Images\"\n",
    "TEST_DIR = os.path.join(ROOT, \"Test\")  # hoặc thư mục test của bạn\n",
    "RUNS_DIR = \"./Runs\"\n",
    "IMAGES_DIR = \"./images\"\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH = 64\n",
    "NUM_WORKERS=8\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# alias để các cell cũ không lỗi assert \"device\"\n",
    "device = DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6cf31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 1: TEST TRANSFORM & DATALOADER ====\n",
    "TEST_TFM = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def build_test_loader(test_dir: str = TEST_DIR, img_size: int = IMG_SIZE, batch_size: int = BATCH):\n",
    "    \"\"\"Tạo DataLoader test. Trả về (loader, dataset).\"\"\"\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    ds = datasets.ImageFolder(test_dir, transform=tfm)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    return loader, ds\n",
    "\n",
    "# cache 1 lần để tái dùng\n",
    "_TEST_CACHE = {}\n",
    "\n",
    "def make_test_loader_safe():\n",
    "    \"\"\"Dùng TEST_DIR/TEST_TFM/BATCH (global). Không phụ thuộc root_test/test_transform cục bộ.\"\"\"\n",
    "    key = (TEST_DIR, IMG_SIZE, BATCH)\n",
    "    if key not in _TEST_CACHE:\n",
    "        loader, ds = build_test_loader(TEST_DIR, IMG_SIZE, BATCH)\n",
    "        _TEST_CACHE[key] = (loader, ds)\n",
    "    return _TEST_CACHE[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "012e61db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 2: MODEL FACTORY & CHECKPOINT LOADER ====\n",
    "def model_auto(run_name: str, num_classes: int = NUM_CLASSES):\n",
    "    \"\"\"Suy luận loại model từ run_name và khởi tạo đúng số lớp.\"\"\"\n",
    "    nm = run_name.lower()\n",
    "    if \"mobilenetv4\" in nm:\n",
    "        model = CustomMobileNetV4(num_classes=num_classes)\n",
    "    elif \"efficientnet_b0\" in nm or \"efficientnet\" in nm:\n",
    "        model = CustomEfficientNetB0(num_classes=num_classes)\n",
    "    elif \"mtl-cnn\" in nm or \"cnn\" in nm:\n",
    "        model = mtl_cnn_v1(num_classes=num_classes)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Không nhận dạng được model từ run_name = {run_name}\")\n",
    "    return model\n",
    "\n",
    "def pick_checkpoint(run_path: str):\n",
    "    \"\"\"Chọn file checkpoint trong thư mục /checkpoints của run.\"\"\"\n",
    "    ckpt_dir = os.path.join(run_path, \"checkpoints\")\n",
    "    if not os.path.isdir(ckpt_dir):\n",
    "        return None\n",
    "    cand = [f for f in os.listdir(ckpt_dir) if f.lower().endswith((\".pt\", \".pth\", \".mtl\"))]\n",
    "    if not cand:\n",
    "        return None\n",
    "    # Ưu tiên best/last\n",
    "    cand.sort()\n",
    "    for key in (\"best\", \"last\"):\n",
    "        for f in cand:\n",
    "            if key in f.lower():\n",
    "                return os.path.join(ckpt_dir, f)\n",
    "    return os.path.join(ckpt_dir, cand[-1])\n",
    "\n",
    "def load_checkpoint(run_name: str, ckpt_path: str):\n",
    "    \"\"\"Tạo model theo run_name và nạp weights từ ckpt_path.\"\"\"\n",
    "    model = model_auto(run_name, NUM_CLASSES)\n",
    "    state = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    # hỗ trợ cả dict dạng {'state_dict': ...}\n",
    "    if isinstance(state, dict) and \"state_dict\" in state:\n",
    "        state = state[\"state_dict\"]\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fe239e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 3: COLLECT LOGITS & ROC HELPERS ====\n",
    "@torch.no_grad()\n",
    "def collect_logits(model, loader):\n",
    "    model.eval().to(DEVICE)\n",
    "    y_true, y_prob = [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE)\n",
    "        logits = model(x)\n",
    "        prob = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        y_prob.append(prob)\n",
    "        y_true.append(y.numpy())\n",
    "    return np.concatenate(y_true), np.vstack(y_prob)\n",
    "\n",
    "\n",
    "def collect_logits_safe(model, loader, device):\n",
    "    # nếu lỡ truyền vào (loader, ds) thì lấy phần loader\n",
    "    if isinstance(loader, (tuple, list)):\n",
    "        loader = loader[0]\n",
    "\n",
    "    y_true, y_prob = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            prob = F.softmax(logits, dim=1).cpu().numpy()\n",
    "            y_prob.append(prob)\n",
    "            y_true.append(y.numpy())\n",
    "    return np.concatenate(y_true), np.vstack(y_prob)\n",
    "\n",
    "def make_test_loader_safe():\n",
    "    \"\"\"\n",
    "    Luôn trả về `loader` đúng kiểu. Nếu build_test_loader trả (loader, ds) thì lấy loader.\n",
    "    \"\"\"\n",
    "    out = build_test_loader(TEST_DIR, IMG_SIZE, BATCH)\n",
    "    # build_test_loader có thể trả về loader hoặc (loader, ds)\n",
    "    if isinstance(out, (tuple, list)):\n",
    "        loader = out[0]\n",
    "    else:\n",
    "        loader = out\n",
    "    return loader\n",
    "\n",
    "\n",
    "def plot_roc_ovr(y_true, y_prob, class_names, run_label, max_curves=5, out_dir=\"images\"):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))\n",
    "    fprs, tprs, aucs = [], [], []\n",
    "    for c in range(len(class_names)):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, c], y_prob[:, c])\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "    macro_auc = float(np.mean(aucs))\n",
    "\n",
    "    idx = np.argsort(aucs)[::-1][:max_curves]\n",
    "    plt.figure(figsize=(7.5, 6.5), dpi=160)\n",
    "    for i in idx:\n",
    "        plt.plot(fprs[i], tprs[i], lw=2, label=f\"{class_names[i]} (AUC = {aucs[i]:.3f})\")\n",
    "    plt.plot([0,1],[0,1],\"k--\",lw=1, label=\"Random\")\n",
    "    plt.xlim(0,1); plt.ylim(0,1.02)\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curves – {run_label}\\nMacro AUC = {macro_auc:.3f}\")\n",
    "    out_png = os.path.join(out_dir, f\"{run_label}_roc.png\")\n",
    "    plt.legend(loc=\"lower right\", fontsize=9, frameon=True)\n",
    "    plt.tight_layout(); plt.savefig(out_png, dpi=300, bbox_inches=\"tight\"); plt.show()\n",
    "    print(\"✓ Saved:\", out_png)\n",
    "    return macro_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfaf7fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 4: EVALUATE ONE RUN (ROC) ====\n",
    "def eval_and_draw_roc(run_path: str):\n",
    "    run_name = os.path.basename(run_path.rstrip(os.sep))\n",
    "    ckpt = pick_checkpoint(run_path)\n",
    "    if not ckpt:\n",
    "        print(f\"[{run_name}] không tìm thấy checkpoint → bỏ qua.\")\n",
    "        return None\n",
    "\n",
    "    # 1) build model & load weights\n",
    "    model = load_checkpoint(run_name, ckpt)\n",
    "\n",
    "    # 2) lấy test loader an toàn\n",
    "    test_loader, test_ds = make_test_loader_safe()\n",
    "    assert len(test_ds.classes) == NUM_CLASSES, \"Số lớp trong test_ds không khớp NUM_CLASSES\"\n",
    "\n",
    "    # 3) collect & plot\n",
    "    y_true, y_prob = collect_logits(model, test_loader)\n",
    "    auc_macro = plot_roc_ovr(y_true, y_prob, CLASS_NAMES, run_label=run_name, max_curves=5, out_dir=IMAGES_DIR)\n",
    "    return {\"run\": run_name, \"macro_auc\": auc_macro}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b8ecb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Đánh giá: miniCNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17076\\1810520961.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(ckpt_path, map_location=DEVICE)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# === Cách 1: chỉ định 3 run muốn vẽ ===\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# plot_roc_for_three_runs(RUNS_DIR, pick_three=[\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m#     \"mtl-efficientnet_b0-20251029-233246\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# === Cách 2: lấy 3 run đầu trong Runs/ ===\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mplot_roc_for_three_runs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRUNS_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpick_three\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mplot_roc_for_three_runs\u001b[39m\u001b[34m(runs_dir, pick_three)\u001b[39m\n\u001b[32m     26\u001b[39m     run_path = os.path.join(runs_dir, rn)\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m→ Đánh giá:\u001b[39m\u001b[33m\"\u001b[39m, rn)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     res = \u001b[43meval_and_draw_roc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res: results.append(res)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36meval_and_draw_roc\u001b[39m\u001b[34m(run_path)\u001b[39m\n\u001b[32m     10\u001b[39m model = load_checkpoint(run_name, ckpt)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 2) lấy test loader an toàn\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m test_loader, test_ds = make_test_loader_safe()\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(test_ds.classes) == NUM_CLASSES, \u001b[33m\"\u001b[39m\u001b[33mSố lớp trong test_ds không khớp NUM_CLASSES\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# 3) collect & plot\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# ==== CELL 5: RUN ====\n",
    "def plot_roc_for_three_runs(runs_dir: str, pick_three=None):\n",
    "    # đảm bảo globals đã tồn tại\n",
    "    assert \"CLASS_NAMES\" in globals(), \"Chạy CELL 0 trước để có CLASS_NAMES\"\n",
    "    assert \"DEVICE\" in globals(), \"Chạy CELL 0 trước để có DEVICE\"\n",
    "    # alias cho code cũ (nếu cần)\n",
    "    globals()[\"device\"] = DEVICE\n",
    "\n",
    "    all_runs = [d for d in sorted(os.listdir(runs_dir)) if os.path.isdir(os.path.join(runs_dir, d))]\n",
    "    if not all_runs:\n",
    "        print(\"Không có run nào trong Runs/.\")\n",
    "        return []\n",
    "\n",
    "    # xác định 3 run\n",
    "    if pick_three: \n",
    "        run_names = pick_three\n",
    "    else:\n",
    "        # ví dụ chọn 5 run đầu (bạn có thể đổi tiêu chí)\n",
    "        run_names = all_runs[:5]\n",
    "\n",
    "    results = []\n",
    "    # đảm bảo đã có test loader trước khi lặp\n",
    "    _ = make_test_loader_safe()\n",
    "\n",
    "    for rn in run_names:\n",
    "        run_path = os.path.join(runs_dir, rn)\n",
    "        print(\"→ Đánh giá:\", rn)\n",
    "        res = eval_and_draw_roc(run_path)\n",
    "        if res: results.append(res)\n",
    "    return results\n",
    "\n",
    "# === Cách 1: chỉ định 3 run muốn vẽ ===\n",
    "# plot_roc_for_three_runs(RUNS_DIR, pick_three=[\n",
    "#     \"mtl-efficientnet_b0-20251029-233246\",\n",
    "#     \"mtl-mobilenetv4-20251029-223758\",\n",
    "#     \"mtl-cnn-20251029-201543\",\n",
    "# ])\n",
    "\n",
    "# === Cách 2: lấy 3 run đầu trong Runs/ ===\n",
    "plot_roc_for_three_runs(RUNS_DIR, pick_three=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21186a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6034936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc9bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e52b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b4961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5bc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 1: BUILD TEST LOADER ===\n",
    "def build_test_loader(test_dir=TEST_DIR, img_size=IMG_SIZE, batch_size=BATCH):\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        # nếu lúc train có Normalize(...) thì thêm vào đúng mean/std tại đây\n",
    "    ])\n",
    "    ds = datasets.ImageFolder(test_dir, transform=tfm)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return loader, ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadd42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 2: MODEL FACTORY & CHECKPOINT LOADER (AN TOÀN) ===\n",
    "def model_auto(run_name:str, num_classes:int=NUM_CLASSES):\n",
    "    n = run_name.lower()\n",
    "    if \"mobilenetv4\" in n or \"mobile\" in n:\n",
    "        return MobileNetV4(num_classes=num_classes)\n",
    "    if \"efficientnet\" in n or \"b0\" in n:\n",
    "        return CustomEfficientNetB0(num_classes=num_classes)\n",
    "    # mặc định: mô hình CNN tự xây\n",
    "    return mtl_cnn_v1(num_classes=num_classes)\n",
    "\n",
    "def pick_checkpoint(run_path: str):\n",
    "    \"\"\"Ưu tiên best.mtl, sau đó *.mtl, *.pt, *.pth trong folder checkpoints/\"\"\"\n",
    "    ckdir = os.path.join(run_path, \"checkpoints\")\n",
    "    cand = []\n",
    "    if os.path.isdir(ckdir):\n",
    "        for f in os.listdir(ckdir):\n",
    "            if f.lower().endswith((\".mtl\",\".pt\",\".pth\")):\n",
    "                cand.append(os.path.join(ckdir,f))\n",
    "    # ưu tiên best.*\n",
    "    cand = sorted(cand, key=lambda p: (0 if os.path.basename(p).lower().startswith(\"best\") else 1, p))\n",
    "    return cand[0] if cand else None\n",
    "\n",
    "def load_checkpoint(model, ckpt_path, device=DEVICE):\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "    # hỗ trợ nhiều định dạng state\n",
    "    if isinstance(state, dict) and \"state_dict\" in state:\n",
    "        sd = state[\"state_dict\"]\n",
    "    elif isinstance(state, dict) and \"net\" in state:\n",
    "        sd = state[\"net\"]\n",
    "    else:\n",
    "        sd = state\n",
    "    # bỏ tiền tố 'module.' nếu có\n",
    "    new_sd = {}\n",
    "    for k, v in sd.items():\n",
    "        nk = k.replace(\"module.\", \"\")\n",
    "        new_sd[nk] = v\n",
    "    missing, unexpected = model.load_state_dict(new_sd, strict=False)\n",
    "    if missing:   print(\"[load] missing keys:\", missing)\n",
    "    if unexpected:print(\"[load] unexpected keys:\", unexpected)\n",
    "    model.to(device).eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f879a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 3: COLLECT LOGITS (ỔN ĐỊNH NHÃN) ===\n",
    "@torch.no_grad()\n",
    "def collect_logits(model, loader, device=DEVICE, class_names=CLASS_NAMES):\n",
    "    # Nếu thứ tự dataset khác CLASS_NAMES -> remap\n",
    "    ds = loader.dataset\n",
    "    remap = None\n",
    "    if hasattr(ds, \"classes\"):\n",
    "        ds_names = list(ds.classes)\n",
    "        name2idx = {n:i for i,n in enumerate(class_names)}\n",
    "        # map index dataset -> index chuẩn\n",
    "        remap = {i: name2idx[n] for i,n in enumerate(ds_names)}\n",
    "    y_true, y_pred, y_prob = [], [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        if remap is not None:\n",
    "            y = torch.as_tensor([remap[int(t)] for t in y], dtype=torch.long)\n",
    "        logits = model(x).detach().cpu()\n",
    "        prob = F.softmax(logits, dim=1).numpy()\n",
    "        pred = prob.argmax(1)\n",
    "        y_true.append(y.numpy())\n",
    "        y_pred.append(pred)\n",
    "        y_prob.append(prob)\n",
    "    return np.concatenate(y_true), np.concatenate(y_pred), np.concatenate(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 4: PLOT CONFUSION MATRIX ===\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, title, out_png):\n",
    "    cm_counts = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
    "    cm = cm_counts.astype(float) / cm_counts.sum(axis=1, keepdims=True)\n",
    "    cm = np.nan_to_num(cm)\n",
    "\n",
    "    THRESHOLD = 0.10  # 10%\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), dpi=180)\n",
    "    sns.heatmap(cm, vmin=0, vmax=1, cmap=\"Blues\", square=True, cbar_kws={'shrink': .7},\n",
    "                xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            show = (i == j) or (cm[i, j] >= THRESHOLD)\n",
    "            if show and cm_counts[i, j] > 0:\n",
    "                ax.text(j+0.5, i+0.5, f\"{cm[i,j]*100:.0f}%\\n({cm_counts[i,j]})\",\n",
    "                        ha=\"center\", va=\"center\", fontsize=7, color=\"black\")\n",
    "    ax.set_xlabel(\"Predicted\", fontsize=11)\n",
    "    ax.set_ylabel(\"True\", fontsize=11)\n",
    "    ax.set_title(title, fontsize=13, pad=10)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=8)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"✓ Saved:\", out_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884a0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 5 \n",
    "def _read_cfg_size_batch(run_path, default_img=IMG_SIZE, default_bs=BATCH):\n",
    "    \"\"\"Đọc img_size, batch_size từ config.json (nếu có); fallback về global.\"\"\"\n",
    "    img_size, batch_size = default_img, default_bs\n",
    "    cfg_path = os.path.join(run_path, \"config.json\")\n",
    "    if os.path.isfile(cfg_path):\n",
    "        try:\n",
    "            import json\n",
    "            with open(cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                cfg = json.load(f)\n",
    "            # linh hoạt tên khóa\n",
    "            for k in [\"img_size\", \"image_size\", \"input_size\", \"IMG_SIZE\"]:\n",
    "                if k in cfg: img_size = int(cfg[k]) if isinstance(cfg[k], (int, float)) else img_size\n",
    "            for k in [\"batch_size\", \"BATCH\", \"bs\"]:\n",
    "                if k in cfg: batch_size = int(cfg[k]) if isinstance(cfg[k], (int, float)) else batch_size\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] Không đọc được config.json: {e}\")\n",
    "    return img_size, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d47d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL: Benchmark tốc độ & tài nguyên (FPS, ms/ảnh, Params, Size) ====\n",
    "import os, io, time\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "# ---------- 1) Tiện ích kích thước mô hình ----------\n",
    "def estimate_state_size_bytes(state_dict_or_model):\n",
    "    \"\"\"\n",
    "    Ước lượng size (bytes) của state_dict (ưu tiên) hoặc toàn bộ tham số model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Nếu truyền vào là state_dict\n",
    "        tensors = list(state_dict_or_model.values())\n",
    "    except Exception:\n",
    "        # Ngược lại: lấy từ model.parameters()\n",
    "        tensors = [p.data for p in state_dict_or_model.parameters()]\n",
    "\n",
    "    total = 0\n",
    "    for t in tensors:\n",
    "        if isinstance(t, torch.Tensor):\n",
    "            total += t.numel() * t.element_size()\n",
    "    return int(total)\n",
    "\n",
    "def file_size_bytes(path):\n",
    "    try:\n",
    "        return os.path.getsize(path)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ---------- 2) Đếm tham số ----------\n",
    "def count_params(model, trainable_only=False):\n",
    "    if trainable_only:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# ---------- 3) Benchmark 1 model ----------\n",
    "@torch.no_grad()\n",
    "def benchmark_model(model, device, input_size=(1, 3, 224, 224), repeat=50, warmup=10):\n",
    "    \"\"\"\n",
    "    Trả về dict: {'ms_per_img', 'FPS', 'params', 'state_size_mb'}.\n",
    "    - input_size: (B, C, H, W), nên để B=1 để so tốc độ/ảnh.\n",
    "    - repeat: số lần lặp đo; warmup: số lần warm-up bỏ qua thời gian.\n",
    "    \"\"\"\n",
    "    model.eval().to(device)\n",
    "    x = torch.randn(*input_size, device=device)\n",
    "\n",
    "    # warm-up để ổn định kernel/layernorm/cuDNN\n",
    "    for _ in range(warmup):\n",
    "        _ = model(x)\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    t0 = time.time()\n",
    "    for _ in range(repeat):\n",
    "        _ = model(x)\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "\n",
    "    total = (t1 - t0)\n",
    "    avg = total / repeat                              # s / forward\n",
    "    ms_per_img = avg * 1000.0\n",
    "    fps = 1.0 / avg if avg > 0 else float(\"inf\")\n",
    "\n",
    "    params = count_params(model, trainable_only=False)\n",
    "    # Ước size từ state_dict để gần với file checkpoint (nếu sau đó bạn có path file thì thay bằng file_size_bytes)\n",
    "    try:\n",
    "        state_bytes = estimate_state_size_bytes(model.state_dict())\n",
    "    except Exception:\n",
    "        state_bytes = estimate_state_size_bytes(model)\n",
    "    size_mb = state_bytes / (1024**2)\n",
    "\n",
    "    return {\n",
    "        \"ms_per_img\": ms_per_img,\n",
    "        \"FPS\": fps,\n",
    "        \"params\": params,\n",
    "        \"state_size_mb\": size_mb,\n",
    "    }\n",
    "\n",
    "# ---------- 4) Vẽ bảng + bar chart so sánh ----------\n",
    "def plot_speed_summary(rows, title=\"Model Speed & Resource Summary\", out_png=\"images/speed_summary.png\"):\n",
    "    \"\"\"\n",
    "    rows: list of dicts, mỗi dict có:\n",
    "      {'name', 'ms_per_img', 'FPS', 'params', 'state_size_mb'}\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(rows)\n",
    "    # sắp xếp theo FPS giảm dần\n",
    "    df = df.sort_values(\"FPS\", ascending=False)\n",
    "\n",
    "    # Bảng đẹp (matplotlib table)\n",
    "    fig, ax = plt.subplots(figsize=(10, 0.6 + 0.45*len(df)), dpi=180)\n",
    "    ax.axis(\"off\")\n",
    "    tbl = ax.table(\n",
    "        cellText=df[[\"name\", \"FPS\", \"ms_per_img\", \"params\", \"state_size_mb\"]]\n",
    "                 .assign(FPS=lambda d: d[\"FPS\"].map(lambda x: f\"{x:.1f}\"),\n",
    "                         ms_per_img=lambda d: d[\"ms_per_img\"].map(lambda x: f\"{x:.2f}\"),\n",
    "                         params=lambda d: d[\"params\"].map(lambda x: f\"{x/1e6:.2f}M\"),\n",
    "                         state_size_mb=lambda d: d[\"state_size_mb\"].map(lambda x: f\"{x:.1f} MB\"))\n",
    "                 .values,\n",
    "        colLabels=[\"Model\", \"FPS (↑)\", \"ms/img (↓)\", \"Params\", \"State size\"],\n",
    "        loc=\"center\",\n",
    "        cellLoc=\"center\"\n",
    "    )\n",
    "    tbl.auto_set_font_size(False)\n",
    "    tbl.set_fontsize(9)\n",
    "    tbl.scale(1, 1.1)\n",
    "    fig.suptitle(title, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"✓ Saved:\", out_png)\n",
    "\n",
    "    # Bar chart FPS (top dễ nhìn)\n",
    "    fig, ax = plt.subplots(figsize=(10, 0.5 + 0.45*len(df)), dpi=180)\n",
    "    ax.barh(df[\"name\"], df[\"FPS\"])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(\"FPS (ảnh/giây, batch=1)\")\n",
    "    ax.set_title(title + \" – FPS\")\n",
    "    for i, v in enumerate(df[\"FPS\"]):\n",
    "        ax.text(v, i, f\" {v:.1f}\", va=\"center\")\n",
    "    plt.tight_layout()\n",
    "    out_bar = out_png.replace(\".png\", \"_fps.png\")\n",
    "    plt.savefig(out_bar, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"✓ Saved:\", out_bar)\n",
    "\n",
    "# ---------- 5) (Tuỳ chọn) Benchmark trực tiếp từ thư mục Runs ----------\n",
    "def speed_from_runs(runs_dir, device, input_size=(1,3,224,224), repeat=50, warmup=10,\n",
    "                    pick_runs=None, title=\"Speed & Resource (Runs)\"):\n",
    "    \"\"\"\n",
    "    - Duyệt thư mục con trong `runs_dir`, mỗi thư mục là một run.\n",
    "    - Với mỗi run: build model + load checkpoint, rồi benchmark.\n",
    "    - pick_runs: list tên run cần đo (nếu None => đo tất cả).\n",
    "    * YÊU CẦU: bạn đã có 2 hàm sẵn có ở notebook:\n",
    "        - build_model_auto(run_name, num_classes)\n",
    "        - load_checkpoint(run_name, ckpt_path, device)  # return model (đã load state_dict)\n",
    "      Nếu tên khác, đổi ngay 2 dòng bên dưới cho phù hợp.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    all_runs = sorted([d for d in os.listdir(runs_dir)\n",
    "                       if os.path.isdir(os.path.join(runs_dir, d))])\n",
    "\n",
    "    if pick_runs is not None:\n",
    "        pick_set = set(pick_runs)\n",
    "        all_runs = [d for d in all_runs if d in pick_set]\n",
    "\n",
    "    for run_name in all_runs:\n",
    "        run_path = os.path.join(runs_dir, run_name)\n",
    "        ckpt_dir = os.path.join(run_path, \"checkpoints\")\n",
    "        # lấy file .pt/.pth/.mtl/.ptn đầu tiên\n",
    "        ckpt_files = [f for f in os.listdir(ckpt_dir)] if os.path.isdir(ckpt_dir) else []\n",
    "        ckpt_files = [f for f in ckpt_files if os.path.splitext(f)[-1].lower() in [\".pt\",\".pth\",\".mtl\",\".ptn\"]]\n",
    "        if not ckpt_files:\n",
    "            print(f\"[skip] {run_name}: không thấy checkpoint.\")\n",
    "            continue\n",
    "        ckpt_path = os.path.join(ckpt_dir, sorted(ckpt_files)[0])\n",
    "\n",
    "        # === Bạn có thể cần sửa 2 dòng bên dưới cho đúng tên hàm của bạn ===\n",
    "        model = build_model_auto(run_name, num_classes=len(CLASS_NAMES))   # <-- ĐỔI nếu bạn đặt tên khác\n",
    "        model = load_checkpoint(run_name, ckpt_path, device)               # <-- ĐỔI nếu bạn đặt tên khác\n",
    "\n",
    "        stats = benchmark_model(model, device, input_size=input_size, repeat=repeat, warmup=warmup)\n",
    "\n",
    "        # Ưu tiên size thật của file nếu có\n",
    "        fsz = file_size_bytes(ckpt_path)\n",
    "        if fsz is not None:\n",
    "            stats[\"state_size_mb\"] = fsz / (1024**2)\n",
    "\n",
    "        rows.append({\n",
    "            \"name\": run_name,\n",
    "            **stats\n",
    "        })\n",
    "\n",
    "    if rows:\n",
    "        plot_speed_summary(rows, title=title, out_png=\"images/speed_summary.png\")\n",
    "    else:\n",
    "        print(\"Không có run hợp lệ trong thư mục:\", runs_dir)\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cdcae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL: So sánh tốc độ 3 model (FPS, ms/img, Params, Size) ====\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "def _pick_ckpt(run_path):\n",
    "    ckpt_dir = os.path.join(run_path, \"checkpoints\")\n",
    "    if not os.path.isdir(ckpt_dir):\n",
    "        return None\n",
    "    files = [f for f in os.listdir(ckpt_dir)\n",
    "             if os.path.splitext(f)[-1].lower() in [\".pt\", \".pth\", \".mtl\", \".ptn\"]]\n",
    "    return os.path.join(ckpt_dir, sorted(files)[0]) if files else None\n",
    "\n",
    "def speed_for_run(run_name, runs_dir, device, input_size=(1,3,224,224), repeat=50, warmup=10):\n",
    "    \"\"\"Đo tốc độ cho 1 run và trả về dict {'name','FPS','ms_per_img','params','state_size_mb'}.\"\"\"\n",
    "    run_path = os.path.join(runs_dir, run_name)\n",
    "    ckpt_path = _pick_ckpt(run_path)\n",
    "    if ckpt_path is None:\n",
    "        raise FileNotFoundError(f\"{run_name}: không thấy checkpoint trong checkpoints/\")\n",
    "    # Các hàm này bạn đã có: build_model_auto, load_checkpoint, CLASS_NAMES\n",
    "    model = build_model_auto(run_name, num_classes=len(CLASS_NAMES))\n",
    "    model = load_checkpoint(run_name, ckpt_path, device)\n",
    "    stats = benchmark_model(model, device, input_size=input_size, repeat=repeat, warmup=warmup)\n",
    "    # thay size bằng size file thực (nếu lấy được)\n",
    "    try:\n",
    "        stats[\"state_size_mb\"] = os.path.getsize(ckpt_path) / (1024**2)\n",
    "    except Exception:\n",
    "        pass\n",
    "    stats[\"name\"] = run_name\n",
    "    return stats\n",
    "\n",
    "def plot_compare_three_speed(\n",
    "    runs_dir,\n",
    "    pick_three=None,                 # list 3 tên run; nếu None sẽ tự lấy 3 run đầu (sorted)\n",
    "    device=None,\n",
    "    input_size=(1,3,224,224),\n",
    "    repeat=50, warmup=10,\n",
    "    title=\"So sánh tốc độ 3 model\",\n",
    "    out_prefix=\"images/compare_three_speed\"\n",
    "):\n",
    "    assert device is not None, \"Bạn cần truyền biến device (cpu/cuda).\"\n",
    "    # Chọn 3 run\n",
    "    all_runs = sorted([d for d in os.listdir(runs_dir) if os.path.isdir(os.path.join(runs_dir, d))])\n",
    "    if pick_three is None:\n",
    "        if len(all_runs) < 3:\n",
    "            raise ValueError(f\"Trong {runs_dir} có {len(all_runs)} run, cần >= 3.\")\n",
    "        pick_three = all_runs[:3]\n",
    "    else:\n",
    "        for r in pick_three:\n",
    "            if r not in all_runs:\n",
    "                raise ValueError(f\"Run '{r}' không tồn tại trong {runs_dir}.\")\n",
    "    # Đo\n",
    "    rows = []\n",
    "    for r in pick_three:\n",
    "        print(f\"[Measure] {r} ...\")\n",
    "        rows.append(speed_for_run(r, runs_dir, device, input_size=input_size, repeat=repeat, warmup=warmup))\n",
    "\n",
    "    # ---- Vẽ 1: Bar chart FPS & ms/img (2 trục) ----\n",
    "    names = [d[\"name\"] for d in rows]\n",
    "    fps   = [d[\"FPS\"] for d in rows]\n",
    "    msimg = [d[\"ms_per_img\"] for d in rows]\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 4.5), dpi=160)\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # FPS (trục trái)\n",
    "    ax1.bar(names, fps, width=0.55)\n",
    "    for i, v in enumerate(fps):\n",
    "        ax1.text(i, v, f\"{v:.1f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    ax1.set_ylabel(\"FPS (↑)\")\n",
    "    ax1.set_ylim(0, max(fps)*1.25)\n",
    "\n",
    "    # ms/img (trục phải)\n",
    "    ax2.plot(names, msimg, marker=\"o\", linewidth=2)\n",
    "    for i, v in enumerate(msimg):\n",
    "        ax2.text(i, v, f\"{v:.2f} ms\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    ax2.set_ylabel(\"ms/ảnh (↓)\")\n",
    "    ax2.set_ylim(0, max(msimg)*1.25)\n",
    "\n",
    "    plt.title(title + f\" – batch=1, input={input_size[2]}x{input_size[3]}\")\n",
    "    plt.tight_layout()\n",
    "    out1 = f\"{out_prefix}_fps_ms.png\"\n",
    "    plt.savefig(out1, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"✓ Saved:\", out1)\n",
    "\n",
    "    # ---- Vẽ 2: Bar chart Params & Size (MB) ----\n",
    "    params = [d[\"params\"] for d in rows]\n",
    "    sizes  = [d[\"state_size_mb\"] for d in rows]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4.2), dpi=160)\n",
    "\n",
    "    # Params (triệu)\n",
    "    ax[0].barh(names, [p/1e6 for p in params])\n",
    "    ax[0].set_xlabel(\"Params (triệu)\")\n",
    "    for i, v in enumerate(params):\n",
    "        ax[0].text(v/1e6, i, f\" {v/1e6:.2f}M\", va=\"center\")\n",
    "    ax[0].invert_yaxis()\n",
    "    ax[0].set_title(\"Số tham số\")\n",
    "\n",
    "    # Size (MB)\n",
    "    ax[1].barh(names, sizes)\n",
    "    ax[1].set_xlabel(\"Kích thước checkpoint (MB)\")\n",
    "    for i, v in enumerate(sizes):\n",
    "        ax[1].text(v, i, f\" {v:.1f} MB\", va=\"center\")\n",
    "    ax[1].invert_yaxis()\n",
    "    ax[1].set_title(\"Kích thước model\")\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    out2 = f\"{out_prefix}_params_size.png\"\n",
    "    plt.savefig(out2, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"✓ Saved:\", out2)\n",
    "\n",
    "    return rows  # trả về số liệu nếu bạn muốn lưu thêm\n",
    "\n",
    "# ======= CÁCH GỌI MẪU =======\n",
    "# rows = plot_compare_three_speed(\n",
    "#     runs_dir=RUNS_DIR,\n",
    "#     pick_three=[\n",
    "#         \"mtl-efficientnet_b0-20251029-233246\",\n",
    "#         \"mtl-mobilenetv4-20251029-223758\",\n",
    "#         \"mtl-cnn-20251029-201543\",\n",
    "#     ],  # hoặc None để tự lấy 3 run đầu\n",
    "#     device=device,\n",
    "#     input_size=(1,3,224,224),\n",
    "#     repeat=60, warmup=12,\n",
    "#     title=\"So sánh tốc độ 3 model\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 8: Làm gì đó ghi vào ===\n",
    "# ==== CELL X: Phân tích lỗi – ảnh dự đoán sai (top-k) và theo cặp nhầm lẫn ====\n",
    "import os, math\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1) Lấy danh sách đường dẫn ảnh theo đúng thứ tự duyệt loader\n",
    "#    Hỗ trợ: ImageFolder, Subset(ImageFolder, ...).\n",
    "# -------------------------------------------------------------\n",
    "def extract_paths_from_loader(loader):\n",
    "    ds = loader.dataset\n",
    "    # ImageFolder: có .samples (list of (path, target))\n",
    "    if hasattr(ds, \"samples\"):\n",
    "        return [p for p, _ in ds.samples]\n",
    "    # Subset: có .dataset.samples và .indices\n",
    "    if hasattr(ds, \"dataset\") and hasattr(ds, \"indices\") and hasattr(ds.dataset, \"samples\"):\n",
    "        base_samples = ds.dataset.samples\n",
    "        idxs = ds.indices\n",
    "        return [base_samples[i][0] for i in idxs]\n",
    "    # Fallback: không tìm thấy đường dẫn\n",
    "    raise RuntimeError(\n",
    "        \"Không lấy được đường dẫn ảnh từ test_loader. \"\n",
    "        \"Hãy dùng ImageFolder/Subset(ImageFolder, ...) và đặt shuffle=False.\"\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2) Thu thập y_true, y_pred, y_prob (max), và đường dẫn ảnh\n",
    "# -------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def collect_preds_with_paths(model, loader, device):\n",
    "    model.eval().to(device)\n",
    "    paths = extract_paths_from_loader(loader)\n",
    "    y_true, y_pred, y_prob = [], [], []\n",
    "    n_seen = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        prob = torch.softmax(logits, dim=1)\n",
    "        pred = prob.argmax(1)\n",
    "\n",
    "        y_true.append(y.numpy())\n",
    "        y_pred.append(pred.cpu().numpy())\n",
    "        y_prob.append(prob.max(1).values.cpu().numpy())\n",
    "\n",
    "        n_seen += y.shape[0]\n",
    "\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    y_prob = np.concatenate(y_prob)\n",
    "\n",
    "    # Cắt paths theo số lượng đã duyệt (phòng khi loader không duyệt hết vì drop_last)\n",
    "    if len(paths) != n_seen:\n",
    "        paths = paths[:n_seen]\n",
    "\n",
    "    return y_true, y_pred, y_prob, paths\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3) Vẽ lưới ảnh dự đoán sai (top-k theo độ tự tin sai cao nhất)\n",
    "# -------------------------------------------------------------\n",
    "def plot_misclassified_grid(run_label, class_names, y_true, y_pred, y_prob, paths,\n",
    "                            top_k=30, cols=5, out_dir=\"images\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    wrong_idx = np.where(y_true != y_pred)[0]\n",
    "    if wrong_idx.size == 0:\n",
    "        print(f\"[{run_label}] ✅ Không có mẫu dự đoán sai.\")\n",
    "        return\n",
    "\n",
    "    # Sắp xếp các lỗi theo xác suất dự đoán (sai) giảm dần\n",
    "    order = wrong_idx[np.argsort(-y_prob[wrong_idx])]\n",
    "    order = order[:top_k]\n",
    "\n",
    "    rows = math.ceil(len(order) / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*4, rows*4), dpi=160)\n",
    "    axes = np.array(axes).reshape(rows, cols)\n",
    "\n",
    "    for ax in axes.ravel():\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for i, idx in enumerate(order):\n",
    "        r, c = divmod(i, cols)\n",
    "        ax = axes[r, c]\n",
    "        try:\n",
    "            img = Image.open(paths[idx]).convert(\"RGB\")\n",
    "        except Exception:\n",
    "            # Nếu lỗi đọc file, bỏ qua ô này\n",
    "            continue\n",
    "        ax.imshow(img)\n",
    "        t = class_names[y_true[idx]]\n",
    "        p = class_names[y_pred[idx]]\n",
    "        conf = y_prob[idx]\n",
    "        ax.set_title(f\"True: {t}\\nPred: {p} ({conf:.2f})\", fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.suptitle(f\"Ảnh dự đoán sai (Top-{len(order)}) – {run_label}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(out_dir, f\"{run_label}_misclassified_top{len(order)}.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"✓ Đã lưu:\", out_png)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4) (Tùy chọn) Vẽ ví dụ cho cặp nhầm lẫn cụ thể true→pred (m lấy tối đa ảnh)\n",
    "# -------------------------------------------------------------\n",
    "def plot_confused_pair_examples(run_label, class_names, y_true, y_pred, y_prob, paths,\n",
    "                                true_name, pred_name, max_examples=12, cols=6, out_dir=\"images\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    # map tên → index\n",
    "    name2idx = {n: i for i, n in enumerate(class_names)}\n",
    "    if true_name not in name2idx or pred_name not in name2idx:\n",
    "        print(f\"[warn] '{true_name}' hoặc '{pred_name}' không có trong class_names.\")\n",
    "        return\n",
    "    t_id, p_id = name2idx[true_name], name2idx[pred_name]\n",
    "\n",
    "    pair_idx = np.where((y_true == t_id) & (y_pred == p_id))[0]\n",
    "    if pair_idx.size == 0:\n",
    "        print(f\"[{run_label}] Không có mẫu nhầm {true_name} → {pred_name}.\")\n",
    "        return\n",
    "\n",
    "    # chọn theo độ tự tin cao nhất\n",
    "    sel = pair_idx[np.argsort(-y_prob[pair_idx])][:max_examples]\n",
    "    rows = math.ceil(len(sel) / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*3.6, rows*3.6), dpi=150)\n",
    "    axes = np.array(axes).reshape(rows, cols)\n",
    "    for ax in axes.ravel():\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for i, idx in enumerate(sel):\n",
    "        r, c = divmod(i, cols)\n",
    "        ax = axes[r, c]\n",
    "        try:\n",
    "            img = Image.open(paths[idx]).convert(\"RGB\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        ax.imshow(img)\n",
    "        conf = y_prob[idx]\n",
    "        ax.set_title(f\"{true_name} → {pred_name}\\nconf={conf:.2f}\", fontsize=9)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.suptitle(f\"Ví dụ cặp nhầm {true_name} → {pred_name} – {run_label}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(out_dir, f\"{run_label}_pair_{true_name}_to_{pred_name}.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"✓ Đã lưu:\", out_png)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5) Hàm tiện ích: chạy full pipeline “phân tích lỗi” cho 1 model/run\n",
    "#    - model: mô hình đã load\n",
    "#    - test_loader: DataLoader (shuffle=False)\n",
    "#    - class_names: danh sách nhãn\n",
    "#    - run_label: tên hiển thị/đặt file\n",
    "#    - top_pairs: số cặp dễ nhầm muốn show tự động từ Confusion Matrix (mặc định: 0 = bỏ qua)\n",
    "# -------------------------------------------------------------\n",
    "def error_analysis_for_run(model, test_loader, class_names, device,\n",
    "                           run_label=\"model\", top_k_wrong=30, top_pairs=0, out_dir=\"images\"):\n",
    "    y_true, y_pred, y_prob, paths = collect_preds_with_paths(model, test_loader, device)\n",
    "\n",
    "    # 5.1) Lưới ảnh lỗi top-k\n",
    "    plot_misclassified_grid(run_label, class_names, y_true, y_pred, y_prob, paths,\n",
    "                            top_k=top_k_wrong, out_dir=out_dir)\n",
    "\n",
    "    # 5.2) (Tùy chọn) tự động tìm top-cặp nhầm nhiều nhất để vẽ ví dụ\n",
    "    if top_pairs and top_pairs > 0:\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=np.arange(len(class_names)))\n",
    "        # loại đường chéo (đúng); chỉ giữ ô nhầm lẫn\n",
    "        cm_err = cm.astype(float)\n",
    "        np.fill_diagonal(cm_err, 0.0)\n",
    "        # lấy chỉ số các ô nhầm nhiều nhất\n",
    "        flat_idx = np.argsort(-cm_err, axis=None)\n",
    "        count = 0\n",
    "        used = set()\n",
    "        for fid in flat_idx:\n",
    "            i = fid // cm_err.shape[1]\n",
    "            j = fid %  cm_err.shape[1]\n",
    "            if cm_err[i, j] <= 0:\n",
    "                break\n",
    "            pair = (i, j)\n",
    "            if pair in used:\n",
    "                continue\n",
    "            used.add(pair)\n",
    "            true_name = class_names[i]\n",
    "            pred_name = class_names[j]\n",
    "            plot_confused_pair_examples(run_label, class_names, y_true, y_pred, y_prob, paths,\n",
    "                                        true_name, pred_name, max_examples=12, out_dir=out_dir)\n",
    "            count += 1\n",
    "            if count >= top_pairs:\n",
    "                break\n",
    "\n",
    "    return {\n",
    "        \"y_true\": y_true, \"y_pred\": y_pred, \"y_prob\": y_prob, \"paths\": paths\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb3b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === CELL 6 \n",
    "def evaluate_one_run(run_path: str, return_preds: bool = False):\n",
    "    run_name = os.path.basename(run_path.rstrip(os.sep))\n",
    "    ckpt = pick_checkpoint(run_path)\n",
    "    if not ckpt:\n",
    "        print(f\"⚠️  {run_name}: không tìm thấy checkpoint trong {run_path}/checkpoints/\")\n",
    "        return None if not return_preds else (None, None)\n",
    "\n",
    "    run_img, run_bs = _read_cfg_size_batch(run_path, IMG_SIZE, BATCH)\n",
    "    test_loader, _ = build_test_loader(TEST_DIR, run_img, run_bs)\n",
    "\n",
    "    model = model_auto(run_name, NUM_CLASSES)\n",
    "    model = load_checkpoint(model, ckpt, DEVICE)\n",
    "\n",
    "    y_true, y_pred, _ = collect_logits(model, test_loader, DEVICE, CLASS_NAMES)\n",
    "\n",
    "    # tính metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    stats = benchmark_model(model, DEVICE, input_size=(1,3,224,224), repeat=50, warmup=10)\n",
    "    print(stats)\n",
    "    rows = speed_from_runs(\n",
    "        runs_dir=RUNS_DIR,\n",
    "        device=DEVICE,\n",
    "        input_size=(1,3,224,224),\n",
    "        repeat=60, warmup=12,\n",
    "        pick_runs=run_name,   # hoặc truyền list các run cụ thể: [\"mtl-efficientnet_b0-...\", \"mtl-mobilenetv4-...\", ...]\n",
    "        title=\"Speed & Resource – batch=1, 224x224\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # vẽ CM\n",
    "    title = f\"Confusion Matrix (row-norm) – {run_name}\"\n",
    "    out_png = os.path.join(IMAGES_DIR, f\"{run_name}_cm.png\")\n",
    "    plot_confusion_matrix(y_true, y_pred, CLASS_NAMES, title, out_png)\n",
    "\n",
    "    info = {\n",
    "        \"run\": run_name,\n",
    "        \"acc\": float(acc),\n",
    "        \"precision\": float(prec),\n",
    "        \"recall\": float(rec),\n",
    "        \"f1\": float(f1),\n",
    "        \"img_size\": int(run_img),\n",
    "        \"batch_size\": int(run_bs),\n",
    "    }\n",
    "    return info if not return_preds else (info, (y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 7: Top-K confused pairs (hàm độc lập) ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def top_confused_pairs(y_true, y_pred, class_names, topk=20, min_count=1):\n",
    "    \"\"\"\n",
    "    Tính Top-K cặp dễ nhầm nhất dựa trên Confusion Matrix chuẩn hoá theo hàng (recall-row).\n",
    "    Trả về list [(i, j, ratio, count), ...] với i!=j, đã sort giảm dần theo ratio rồi count.\n",
    "    - ratio: tỉ lệ nhầm (phần trăm theo hàng)\n",
    "    - count: số mẫu nhầm thực tế\n",
    "    \"\"\"\n",
    "    n = len(class_names)\n",
    "    cm_counts = confusion_matrix(y_true, y_pred, labels=range(n))\n",
    "    row_sum = cm_counts.sum(axis=1, keepdims=True)\n",
    "    cm_norm = np.divide(cm_counts, np.maximum(row_sum, 1), where=row_sum != 0)\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            c = int(cm_counts[i, j])\n",
    "            if c < min_count:\n",
    "                continue\n",
    "            r = float(cm_norm[i, j])\n",
    "            if r > 0:\n",
    "                pairs.append((i, j, r, c))\n",
    "\n",
    "    # sort theo tỉ lệ nhầm (desc), rồi theo count (desc)\n",
    "    pairs.sort(key=lambda x: (x[2], x[3]), reverse=True)\n",
    "    return pairs[:topk]\n",
    "\n",
    "def plot_top_confusions(y_true, y_pred, class_names, run_name,\n",
    "                        topk=20, min_count=1, out_dir=IMAGES_DIR):\n",
    "    \"\"\"\n",
    "    Vẽ bar chart Top-K cặp dễ nhầm nhất & lưu ảnh:\n",
    "    images/{run_name}_top{topk}_confused.png\n",
    "    \"\"\"\n",
    "    pairs = top_confused_pairs(y_true, y_pred, class_names, topk=topk, min_count=min_count)\n",
    "    if not pairs:\n",
    "        print(f\"[{run_name}] Không đủ mẫu để vẽ top-confusions.\")\n",
    "        return None\n",
    "\n",
    "    labels = [f\"{class_names[i]} → {class_names[j]}\" for (i, j, _, _) in pairs]\n",
    "    ratios = [p[2]*100 for p in pairs]\n",
    "    counts = [p[3] for p in pairs]\n",
    "\n",
    "    fig_h = max(5, 0.45*len(pairs)+1.5)\n",
    "    fig, ax = plt.subplots(figsize=(10, fig_h), dpi=180)\n",
    "    y_pos = np.arange(len(pairs))\n",
    "\n",
    "    ax.barh(y_pos, ratios)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(\"Tỉ lệ nhầm (%)\")\n",
    "    ax.set_title(f\"Top-{topk} cặp dễ nhầm nhất – {run_name}\")\n",
    "\n",
    "    # annotate % và (count)\n",
    "    for y, r, c in zip(y_pos, ratios, counts):\n",
    "        ax.text(r + 0.5, y, f\"{r:.1f}% ({c})\", va=\"center\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(out_dir, f\"{run_name}_top{topk}_confused.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"✓ Saved:\", out_png)\n",
    "    return out_png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 9: Làm gì đó ghi vào ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633eaeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 10: Làm gì đó ghi vào ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 11: Làm gì đó ghi vào ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05571ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 100: tổng hợp & render bảng cột đẹp ===\n",
    "def _render_summary_table(df, out_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # định dạng số 3 chữ số thập phân\n",
    "    show_df = df.copy()\n",
    "    for c in [\"acc\",\"precision\",\"recall\",\"f1\"]:\n",
    "        if c in show_df.columns:\n",
    "            show_df[c] = show_df[c].map(lambda x: f\"{x:.3f}\")\n",
    "    show_df[\"img_size\"] = show_df[\"img_size\"].astype(str)\n",
    "    show_df[\"batch_size\"] = show_df[\"batch_size\"].astype(str)\n",
    "\n",
    "    fig_h = 0.6 * (len(show_df) + 1) + 1\n",
    "    fig, ax = plt.subplots(figsize=(12, fig_h), dpi=220)\n",
    "    ax.axis(\"off\")\n",
    "    tbl = ax.table(\n",
    "        cellText=show_df.values,\n",
    "        colLabels=show_df.columns,\n",
    "        loc='center',\n",
    "        cellLoc='center',\n",
    "    )\n",
    "    tbl.auto_set_font_size(False)\n",
    "    tbl.set_fontsize(10)\n",
    "    tbl.scale(1, 1.2)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"✓ Saved:\", out_path)\n",
    "\n",
    "def evaluate_entry(path_or_parent: str):\n",
    "    path_or_parent = path_or_parent.rstrip(os.sep)\n",
    "    results = []\n",
    "\n",
    "    if os.path.isdir(os.path.join(path_or_parent, \"checkpoints\")):\n",
    "        # 1 run\n",
    "        print(f\"Đánh giá: {os.path.basename(path_or_parent)}\")\n",
    "        res = evaluate_one_run(path_or_parent)\n",
    "        if res: results.append(res)\n",
    "    else:\n",
    "        # thư mục cha\n",
    "        for name in sorted(os.listdir(path_or_parent)):\n",
    "            run_path = os.path.join(path_or_parent, name)\n",
    "            if not os.path.isdir(run_path): \n",
    "                continue\n",
    "            if not os.path.isdir(os.path.join(run_path, \"checkpoints\")):\n",
    "                continue\n",
    "            print(f\"Đánh giá: {name}\")\n",
    "            res = evaluate_one_run(run_path)\n",
    "            if res: results.append(res)\n",
    "\n",
    "    if results:\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(results).sort_values(\"acc\", ascending=False)\n",
    "        display(df)  # bảng tương tác trong notebook\n",
    "\n",
    "        # xuất ảnh bảng\n",
    "        out_png = os.path.join(IMAGES_DIR, \"summary_models.png\")\n",
    "        _render_summary_table(df[[\"run\",\"acc\",\"precision\",\"recall\",\"f1\",\"img_size\",\"batch_size\"]], out_png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # in tốc độ các mô hình\n",
    "        rows = plot_compare_three_speed(\n",
    "                 runs_dir=RUNS_DIR,\n",
    "                 pick_three=[\n",
    "                     \"mtl-efficientnet_b0\",\n",
    "                     \"mtl-mobilenetv4\",\n",
    "                     \"mtl-cnn\",\n",
    "                     \"miniCNN\"\n",
    "                 ],  # hoặc None để tự lấy 3 run đầu\n",
    "                 device=DEVICE,\n",
    "                 input_size=(1,3,224,224),\n",
    "                 repeat=60, warmup=12,\n",
    "                 title=\"So sánh tốc độ 3 model\"\n",
    "             )\n",
    "    else:\n",
    "        print(\"⚠️  Không có mô hình hợp lệ.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97e7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 101: EVALUATE ALL RUNS & RANKING + Top-20 confused pairs ===\n",
    "def evaluate_entry(path_or_parent: str, topk_pairs: int = 20, min_count: int = 1):\n",
    "    path_or_parent = path_or_parent.rstrip(os.sep)\n",
    "    results = []\n",
    "\n",
    "    def _eval_and_draw(run_path):\n",
    "        run_name = os.path.basename(run_path.rstrip(os.sep))\n",
    "        print(f\"Đánh giá: {run_name}\")\n",
    "        out = evaluate_one_run(run_path, return_preds=True)\n",
    "        if not out or out[0] is None:\n",
    "            return\n",
    "        info, (y_true, y_pred) = out\n",
    "        results.append(info)\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "        # 🔹 vẽ Top-K cặp dễ nhầm\n",
    "        try:\n",
    "            plot_top_confusions(y_true, y_pred, CLASS_NAMES, info[\"run\"],\n",
    "                                topk=topk_pairs, min_count=min_count, out_dir=IMAGES_DIR)\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] Không vẽ được top-confusions cho {info['run']}: {e}\")\n",
    "\n",
    "    # 1 run hay folder cha\n",
    "    if os.path.isdir(os.path.join(path_or_parent, \"checkpoints\")):\n",
    "        _eval_and_draw(path_or_parent)\n",
    "    else:\n",
    "        for name in sorted(os.listdir(path_or_parent)):\n",
    "            run_path = os.path.join(path_or_parent, name)\n",
    "            if not os.path.isdir(run_path): \n",
    "                continue\n",
    "            if not os.path.isdir(os.path.join(run_path, \"checkpoints\")):\n",
    "                continue\n",
    "            _eval_and_draw(run_path)\n",
    "\n",
    "    # tổng hợp\n",
    "    if results:\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(results).sort_values(\"acc\", ascending=False)\n",
    "        display(df)\n",
    "\n",
    "        # render bảng ảnh đẹp (giữ hàm _render_summary_table bạn đang có)\n",
    "        out_png = os.path.join(IMAGES_DIR, \"summary_models.png\")\n",
    "        _render_summary_table(df[[\"run\",\"acc\",\"precision\",\"recall\",\"f1\",\"img_size\",\"batch_size\"]], out_png)\n",
    "    else:\n",
    "        print(\"⚠️  Không có mô hình hợp lệ.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 102: Đánh giá một mô hình cụ thể (thư mục có checkpoints/ ===\n",
    "# evaluate_entry(os.path.join(RUNS_DIR, \"mtl-mobilenetv4\"), topk_pairs=20, min_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 103: Đánh giá toàn bộ mô hình trong thư mục cha Runs/ ===\n",
    "evaluate_entry(RUNS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3131b229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Vẽ lịch sử: miniCNN\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m→ Vẽ lịch sử: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[43mplot_history_for_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mplot_history_for_run\u001b[39m\u001b[34m(run_path, run_name)\u001b[39m\n\u001b[32m     24\u001b[39m     df = pd.read_json(hist_path)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     df = \u001b[43mpd\u001b[49m.read_csv(hist_path)\n\u001b[32m     27\u001b[39m df = df.copy()\n\u001b[32m     28\u001b[39m df.columns = [c.strip() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df.columns]\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# ==== CELL 9 (REPLACE): Vẽ Loss/Accuracy CHO TẤT CẢ CÁC RUNS ====\n",
    "def pick_col(df, pats):\n",
    "    \"\"\"Chọn cột đầu tiên khớp pattern (không phân biệt hoa/thường).\"\"\"\n",
    "    pats = [p.lower() for p in pats]\n",
    "    for c in df.columns:\n",
    "        cl = c.lower()\n",
    "        if any(re.search(p, cl) for p in pats):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def plot_history_for_run(run_path, run_name):\n",
    "    # 1) tìm file log hợp lệ\n",
    "    for cand in [\"history.csv\", \"history.json\", \"train_log.csv\", \"metrics.csv\"]:\n",
    "        hp = os.path.join(run_path, cand)\n",
    "        if os.path.isfile(hp):\n",
    "            hist_path = hp\n",
    "            break\n",
    "    else:\n",
    "        print(f\"[-] {run_name}: không thấy history.(csv|json)\")\n",
    "        return\n",
    "\n",
    "    # 2) đọc log và chuẩn hoá cột\n",
    "    if hist_path.endswith(\".json\"):\n",
    "        df = pd.read_json(hist_path)\n",
    "    else:\n",
    "        df = pd.read_csv(hist_path)\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # 3) epoch thực tế trong file; nếu không có cột epoch thì mặc định 1..len\n",
    "    c_epoch = pick_col(df, [r\"^epoch$\", r\"^epochs?$\"])\n",
    "    epoch = df[c_epoch].to_numpy() if c_epoch else np.arange(1, len(df)+1)\n",
    "\n",
    "    # 4) bắt các cột loss/acc “mềm”\n",
    "    c_tr_loss = pick_col(df, [r\"^loss$\", r\"train.*loss\"])\n",
    "    c_va_loss = pick_col(df, [r\"val.*loss\", r\"valid.*loss\"])\n",
    "    c_tr_acc  = pick_col(df, [r\"^acc$\", r\"accuracy$\", r\"train.*acc\", r\"train.*accuracy\"])\n",
    "    c_va_acc  = pick_col(df, [r\"val.*acc\", r\"val.*accuracy\", r\"valid.*acc\", r\"valid.*accuracy\"])\n",
    "\n",
    "    tr_loss = df[c_tr_loss].to_numpy() if c_tr_loss else None\n",
    "    va_loss = df[c_va_loss].to_numpy() if c_va_loss else None\n",
    "    tr_acc  = df[c_tr_acc].to_numpy()  if c_tr_acc  else None\n",
    "    va_acc  = df[c_va_acc].to_numpy()  if c_va_acc  else None\n",
    "\n",
    "    # 5) epoch tốt nhất để annotate\n",
    "    best_ep, note = None, \"\"\n",
    "    if va_acc is not None and len(va_acc) > 0:\n",
    "        best_ep = int(epoch[np.nanargmax(va_acc)])\n",
    "        note = f\"best val_acc@{best_ep}={np.nanmax(va_acc):.3f}\"\n",
    "    elif va_loss is not None and len(va_loss) > 0:\n",
    "        best_ep = int(epoch[np.nanargmin(va_loss)])\n",
    "        note = f\"best val_loss@{best_ep}={np.nanmin(va_loss):.3f}\"\n",
    "\n",
    "    # 6) vẽ 2 subplot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5), dpi=160)\n",
    "\n",
    "    # Loss\n",
    "    if tr_loss is not None: ax[0].plot(epoch, tr_loss, label=\"Train loss\")\n",
    "    if va_loss is not None: ax[0].plot(epoch, va_loss, label=\"Val loss\")\n",
    "    if best_ep is not None: ax[0].axvline(best_ep, ls=\"--\", lw=1, c=\"gray\")\n",
    "    ax[0].set_title(f\"{run_name} – Loss\")\n",
    "    ax[0].set_xlabel(\"Epoch\"); ax[0].set_ylabel(\"Loss\"); ax[0].legend()\n",
    "\n",
    "    # Accuracy\n",
    "    if tr_acc is not None: ax[1].plot(epoch, tr_acc, label=\"Train acc\")\n",
    "    if va_acc is not None: ax[1].plot(epoch, va_acc, label=\"Val acc\")\n",
    "    if best_ep is not None:\n",
    "        ax[1].axvline(best_ep, ls=\"--\", lw=1, c=\"gray\", label=note if va_acc is not None else None)\n",
    "    ax[1].set_title(f\"{run_name} – Accuracy\")\n",
    "    ax[1].set_xlabel(\"Epoch\"); ax[1].set_ylabel(\"Accuracy\"); ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(IMAGES_DIR, f\"{run_name}_history.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"✓ Đã lưu: {out_png}\")\n",
    "\n",
    "# 🔁 DUYỆT HẾT TẤT CẢ RUNS và vẽ\n",
    "if not os.path.isdir(RUNS_DIR):\n",
    "    print(f\"Thư mục '{RUNS_DIR}' không tồn tại.\")\n",
    "else:\n",
    "    for run_name in sorted(os.listdir(RUNS_DIR)):\n",
    "        run_path = os.path.join(RUNS_DIR, run_name)\n",
    "        if not os.path.isdir(run_path):\n",
    "            continue\n",
    "        print(f\"→ Vẽ lịch sử: {run_name}\")\n",
    "        plot_history_for_run(run_path, run_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
