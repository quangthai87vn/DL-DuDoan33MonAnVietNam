# app.py ‚Äî Streamlit inference cho nhi·ªÅu model, ƒë·ªçc checkpoint t·ª´ th∆∞ m·ª•c Models/
import io

from pathlib import Path
from typing import List, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
from torchvision import transforms
import streamlit as st

# ====== c√°c ki·∫øn tr√∫c b·∫°n ƒëang d√πng (ƒë·∫£m b·∫£o c√°c file n√†y c√≥ s·∫µn) ======
from model.mtl_cnn import mtl_cnn_v1
from model.mobilenet_v4 import CustomMobileNetV4
from model.efficientnet_b0 import CustomEfficientNetB0


# ƒë·∫∑t ·ªü ƒë·∫ßu file sau imports
from inspect import signature

def show_img_responsive(img):
    # T·ª± d√≤ ch·ªØ k√Ω h√†m st.image ƒë·ªÉ ch·ªçn tham s·ªë ƒë√∫ng v·ªõi version
    params = signature(st.image).parameters
    if "use_container_width" in params:
        st.image(img, use_container_width=True)
    elif "use_column_width" in params:
        st.image(img, use_column_width=True)
    else:
        st.image(img)



# ====== c·∫•u h√¨nh chung ======
MODELS_DIR = Path("Models")
IMG_TYPES = ["png", "jpg", "jpeg", "bmp", "tif", "tiff", "webp"]

CLASS_NAMES = [
    "B√°nh b√®o","B√°nh b·ªôt l·ªçc","B√°nh cƒÉn","B√°nh canh","B√°nh ch∆∞ng",
    "B√°nh cu·ªën","B√°nh ƒë√∫c","B√°nh gi√≤","B√°nh kh·ªçt","B√°nh m√¨",
    "B√°nh p√≠a","B√°nh t√©t","B√°nh tr√°ng n∆∞·ªõng","B√°nh x√®o",
    "B√∫n b√≤ Hu·∫ø","B√∫n ƒë·∫≠u m·∫Øm t√¥m","B√∫n m·∫Øm","B√∫n ri√™u",
    "B√∫n th·ªãt n∆∞·ªõng","C√° kho t·ªô","Canh chua","Cao l·∫ßu",
    "Ch√°o l√≤ng","C∆°m t·∫•m","G·ªèi cu·ªën","H·ªß ti·∫øu",
    "M√¨ Qu·∫£ng","Nem chua","Ph·ªü","X√¥i x√©o",
    "banh_da_lon","banh_tieu","banh_trung_thu"
]
NUM_CLASSES = len(CLASS_NAMES)

# B·∫°n train kh√¥ng normalize -> gi·ªØ nguy√™n
TRANSFORM = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# ====== page & CSS ======
st.set_page_config(page_title="D·ª∞ ƒêO√ÅN M√ìN ƒÇN VN", page_icon="üçú", layout="wide")

# --- CSS responsive & hide file list ---
st.markdown("""
<style>
/* ·∫®n danh s√°ch file ƒë√£ ch·ªçn c·ªßa st.file_uploader */
[data-testid="stFileUploader"] .uploadedFile { display: none !important; }
[data-testid="stFileUploader"] .uploadedFileList { display: none !important; }
/* Gi·∫•u nh√£n label n·∫øu mu·ªën g·ªçn h∆°n (tu·ª≥ ch·ªçn) */
/* [data-testid="stFileUploader"] label { display:none !important; } */

/* Layout 2 uploader: desktop = 2 c·ªôt, mobile = x·∫øp d·ªçc */
.upload-row { display: flex; gap: 16px; }
.upload-col { flex: 1 1 0; }

/* M√†n h√¨nh h·∫πp (‚â§ 768px) -> x·∫øp d·ªçc */
@media (max-width: 768px) {
  .upload-row { flex-direction: column; }
}
</style>
""", unsafe_allow_html=True)




st.title("üçú D·ª∞ ƒêO√ÅN M√ìN ƒÇN VN ‚Äì B√ôI QUANG TH√ÅI - 24752551")

# ====== ti·ªán √≠ch ======
def list_checkpoints(models_dir: Path) -> list[Path]:
    models_dir.mkdir(parents=True, exist_ok=True)
    return sorted([p for p in models_dir.iterdir()
                   if p.is_file() and p.suffix.lower() in (".mtl", ".pt")])

def guess_arch(ckpt_name: str) -> str:
    n = ckpt_name.lower()
    if "mobilenetv4" in n or "mobilev4" in n:
        return "mobilenetv4"
    if "efficientnet" in n or "_b0" in n:
        return "efficientnet_b0"
    return "mtl_cnn"

def _read_state_dict(ckpt_path: Path, device: str):
    obj = torch.load(str(ckpt_path), map_location=device)
    if isinstance(obj, dict) and "net" in obj:
        state = obj["net"]
    elif isinstance(obj, dict) and "state_dict" in obj:
        state = obj["state_dict"]
    else:
        state = obj
    # b·ªè 'module.' n·∫øu d√πng DataParallel
    new_state = {}
    for k, v in state.items():
        if k.startswith("module."):
            k = k[len("module."):]
        new_state[k] = v
    return new_state

def build_model_by_arch(arch: str, num_classes: int) -> nn.Module:
    if arch == "mtl_cnn":
        return mtl_cnn_v1(num_classes=num_classes)
    if arch == "mobilenetv4":
        return CustomMobileNetV4(num_classes=num_classes, pretrained=False)
    if arch == "efficientnet_b0":
        return CustomEfficientNetB0(num_classes=num_classes, pretrained=False)
    raise ValueError(f"Unknown arch: {arch}")

@st.cache_resource(show_spinner=False)
def load_model_cached(ckpt_path: str, arch: str, num_classes: int):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = build_model_by_arch(arch, num_classes).to(device).eval()
    state = _read_state_dict(Path(ckpt_path), device)
    try:
        model.load_state_dict(state, strict=True)
    except Exception:
        missing, unexpected = model.load_state_dict(state, strict=False)
        warn = []
        if missing:    warn.append(f"missing: {len(missing)}")
        if unexpected: warn.append(f"unexpected: {len(unexpected)}")
        if warn: st.warning("Checkpoint kh√¥ng kh·ªõp ho√†n to√†n ‚Üí d√πng strict=False. " + " | ".join(warn))
    return model, device




@torch.no_grad()
def predict_image(model: nn.Module, device: str, image: Image.Image, topk: int = 3):
    x = TRANSFORM(image.convert("RGB")).unsqueeze(0).to(device)
    probs = torch.softmax(model(x), dim=1).squeeze(0)
    k = min(topk, probs.numel())
    vals, idxs = torch.topk(probs, k)
    return idxs.tolist(), vals.tolist()

# ====== sidebar ======
with st.sidebar:
    st.subheader("‚öôÔ∏è C·∫•u h√¨nh")
    ckpt_files = list_checkpoints(MODELS_DIR)
    if not ckpt_files:
        st.error(f"Kh√¥ng t√¨m th·∫•y checkpoint trong `{MODELS_DIR}/`.")
        st.stop()

    # ch·ªâ hi·ªÉn th·ªã t√™n file, kh√¥ng k√®m 'Models\\'
    name_to_path = {p.name: str(p) for p in ckpt_files}
    sel_name = st.selectbox("Ch·ªçn file model (.mtl/.pt)", list(name_to_path.keys()), index=0)
    ckpt_path = name_to_path[sel_name]

    detected_arch = guess_arch(sel_name)
    st.caption(f"Ki·∫øn tr√∫c suy lu·∫≠n: **{detected_arch}** (ƒë·ªïi t√™n file n·∫øu mu·ªën nh·∫≠n di·ªán kh√°c)")
    topk = st.slider("Top-K hi·ªÉn th·ªã", 1, 5, 3)
    cols = st.slider("S·ªë c·ªôt hi·ªÉn th·ªã", 1, 5, 3)
    show_prob = st.toggle("Hi·ªán % x√°c su·∫•t", value=True)

# ====== load model ======
model, device = load_model_cached(ckpt_path, detected_arch, NUM_CLASSES)
st.success(f"Model `{detected_arch}` ƒë√£ s·∫µn s√†ng tr√™n **{device.upper()}** ‚Ä¢ checkpoint: `{sel_name}`")

# ====== Upload UI (responsive + kh√¥ng show list file) ======
def build_upload_ui() -> list[tuple[str, Image.Image]]:
    """
    Tr·∫£ v·ªÅ danh s√°ch [(t√™n, PIL Image)] ƒë√£ ƒë·ªçc t·ª´ 2 uploader:
    - Tr√°i: ch·ªçn nhi·ªÅu ·∫£nh
    - Ph·∫£i: 1 file .zip ch·ª©a ·∫£nh
    Responsive: 2 c·ªôt desktop, 1 c·ªôt mobile.
    Kh√¥ng hi·ªÉn th·ªã danh s√°ch file ‚Äî ch·ªâ render ·∫£nh ngay sau khi ƒë·ªçc.
    """
    import zipfile, tempfile

    images: list[tuple[str, Image.Image]] = []

    # Kh·ªëi wrapper ƒë·ªÉ CSS nh·∫≠n di·ªán
    with st.container():
        st.markdown('<div class="upload-row">', unsafe_allow_html=True)

        # --- uploader tr√°i: nhi·ªÅu ·∫£nh ---
        st.markdown('<div class="upload-col">', unsafe_allow_html=True)
        up_imgs = st.file_uploader(
            "Ch·ªçn 1 ho·∫∑c nhi·ªÅu ·∫£nh",
            type=IMG_TYPES,
            accept_multiple_files=True,
            label_visibility="collapsed",   # ·∫©n label
            key="uploader_images"
        )
        if up_imgs:
            for f in up_imgs:
                try:
                    images.append((f.name, Image.open(io.BytesIO(f.read())).convert("RGB")))
                except Exception as e:
                    st.warning(f"·∫¢nh l·ªói `{f.name}`: {e}")
        st.markdown('</div>', unsafe_allow_html=True)

        # --- uploader ph·∫£i: 1 file zip ---
        st.markdown('<div class="upload-col">', unsafe_allow_html=True)
        up_zip = st.file_uploader(
            "Ho·∫∑c ch·ªçn 1 file .zip ch·ª©a ·∫£nh",
            type=["zip"],
            accept_multiple_files=False,
            label_visibility="collapsed",
            key="uploader_zip"
        )
        if up_zip is not None:
            with tempfile.TemporaryDirectory() as tmpdir:
                try:
                    zf = zipfile.ZipFile(io.BytesIO(up_zip.read()))
                    zf.extractall(tmpdir)
                    for p in Path(tmpdir).rglob("*"):
                        if p.suffix.lower().strip(".") in IMG_TYPES:
                            try:
                                images.append((p.name, Image.open(p).convert("RGB")))
                            except Exception as e:
                                st.warning(f"·∫¢nh l·ªói `{p}`: {e}")
                except Exception as e:
                    st.error(f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file .zip: {e}")
        st.markdown('</div>', unsafe_allow_html=True)

        st.markdown('</div>', unsafe_allow_html=True)

    return images



images_to_run = build_upload_ui()

if not images_to_run:
    st.info("üëâ K√©o-th·∫£ ·∫£nh (ho·∫∑c .zip) v√†o hai √¥ b√™n tr√™n ƒë·ªÉ d·ª± ƒëo√°n.")
    st.stop()




# ====== hi·ªÉn th·ªã k·∫øt qu·∫£ ======
n = len(images_to_run)
rows = (n + cols - 1) // cols
idx = 0
for _ in range(rows):
    c = st.columns(cols)
    for j in range(cols):
        if idx >= n: break
        name, pil_img = images_to_run[idx]
        with c[j]:


            try:
                ids, probs = predict_image(model, device, pil_img, topk=topk)
                #st.image(pil_img, use_container_width=True)
                show_img_responsive(pil_img)
                if show_prob:
                    lines = [f"**{CLASS_NAMES[k] if k < NUM_CLASSES else 'class_'+str(k)}** ‚Äî {p*100:.1f}%"
                             for k, p in zip(ids, probs)]
                else:
                    lines = [f"**{CLASS_NAMES[k] if k < NUM_CLASSES else 'class_'+str(k)}**" for k in ids]
                st.markdown(f"**{name}**")
                st.markdown(" ‚Ä¢ ".join(lines))





            except Exception as e:
                st.error(f"L·ªói d·ª± ƒëo√°n `{name}`: {e}")
        idx += 1


