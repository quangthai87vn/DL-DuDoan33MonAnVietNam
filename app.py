# app.py
# Streamlit inference cho miniVGG (PyTorch) v·ªõi 30 m√≥n ƒÉn VN

import io
import os
from pathlib import Path
from typing import List, Tuple

import torch
import torch.nn.functional as F
from PIL import Image
from torchvision import transforms
import streamlit as st

# -----------------------------
# 1) C·∫§U H√åNH
# -----------------------------
# ƒê∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh t·ªõi checkpoint .pt (s·ª≠a l·∫°i n·∫øu c·∫ßn)
DEFAULT_CKPT = "checkpoints/classification_best.pt"

# Mapping 30 l·ªõp THEO TH·ª® T·ª∞ TRAIN (index 24 = G·ªèi cu·ªën)
CLASS_NAMES = [
    "B√°nh b√®o", "B√°nh b·ªôt l·ªçc", "B√°nh cƒÉn", "B√°nh canh", "B√°nh ch∆∞ng",
    "B√°nh cu·ªën", "B√°nh ƒë√∫c", "B√°nh gi√≤", "B√°nh kh·ªçt", "B√°nh m√¨",
    "B√°nh p√≠a", "B√°nh t√©t", "B√°nh tr√°ng n∆∞·ªõng", "B√°nh x√®o",
    "B√∫n b√≤ Hu·∫ø", "B√∫n ƒë·∫≠u m·∫Øm t√¥m", "B√∫n m·∫Øm", "B√∫n ri√™u",
    "B√∫n th·ªãt n∆∞·ªõng", "C√° kho t·ªô", "Canh chua", "Cao l·∫ßu",
    "Ch√°o l√≤ng", "C∆°m t·∫•m", "G·ªèi cu·ªën", "H·ªß ti·∫øu",
    "M√¨ Qu·∫£ng", "Nem chua", "Ph·ªü", "X√¥i x√©o"
]

# Ti·ªÅn x·ª≠ l√Ω PH·∫¢I KH·ªöP l√∫c train (224x224 cho miniVGG c·ªßa b·∫°n)
TRANSFORM = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

IMG_TYPES = ["png", "jpg", "jpeg", "bmp", "tif", "tiff", "webp"]


# -----------------------------
# 2) LOAD MODEL (cache)
# -----------------------------
@st.cache_resource(show_spinner=True)
def load_model(ckpt_path: str):
    # ƒë·ªÉ import ƒë∆∞·ª£c model.cnn miniVGG khi ch·∫°y t·ª´ m·ªçi ch·ªó
    import sys
    root = Path(".").resolve()
    # n·∫øu kh√¥ng t√¨m th·∫•y folder model ·ªü cwd, th·ª≠ b√≤ ng∆∞·ª£c v√†i c·∫•p
    for _ in range(6):
        if (root / "model").exists():
            break
        root = root.parent
    sys.path.insert(0, str(root))

    from model.cnn import miniVGG  # <- ƒë√∫ng ki·∫øn tr√∫c ƒë√£ train

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = miniVGG().to(device).eval()

    ckpt = torch.load(ckpt_path, map_location=device)
    state_dict = ckpt["net"] if isinstance(ckpt, dict) and "net" in ckpt else ckpt
    model.load_state_dict(state_dict)
    return model, device


# -----------------------------
# 3) D·ª∞ ƒêO√ÅN
# -----------------------------
@torch.no_grad()
def predict_image(model: torch.nn.Module, device: str, image: Image.Image, topk: int = 3) -> Tuple[List[int], List[float]]:
    x = TRANSFORM(image.convert("RGB")).unsqueeze(0).to(device)  # (1,C,H,W)
    logits = model(x)                                           # (1, num_classes)
    probs = F.softmax(logits, dim=1).squeeze(0)                 # (num_classes,)
    k = min(topk, probs.numel())
    vals, idxs = torch.topk(probs, k)
    return idxs.tolist(), vals.tolist()


# -----------------------------
# 4) UI
# -----------------------------
st.set_page_config(page_title="D·ª∞ ƒêO√ÅN M√ìN ƒÇN VN", page_icon="üçú", layout="wide")
st.title("üçú D·ª∞ ƒêO√ÅN M√ìN ƒÇN VN ‚Äì B√ôI QUANG TH√ÅI")

with st.sidebar:
    st.subheader("‚öôÔ∏è C·∫•u h√¨nh")
    ckpt_path = st.text_input("ƒê∆∞·ªùng d·∫´n checkpoint (.pt)", DEFAULT_CKPT)
    topk = st.slider("Top-K hi·ªÉn th·ªã", 1, 5, 3)
    cols = st.slider("S·ªë c·ªôt hi·ªÉn th·ªã", 1, 5, 3)
    show_prob = st.toggle("Hi·ªán % x√°c su·∫•t", value=True)
    st.caption("N·∫øu l·ªói ‚Äòkh√¥ng th·∫•y model‚Äô, ch·∫°y app t·ª´ th∆∞ m·ª•c g·ªëc d·ª± √°n ho·∫∑c ch·ªânh l·∫°i ƒë∆∞·ªùng d·∫´n ·ªü tr√™n.")

# T·∫£i model
if not Path(ckpt_path).exists():
    st.error(f"Kh√¥ng t√¨m th·∫•y checkpoint: {ckpt_path}")
    st.stop()

model, device = load_model(ckpt_path)
st.success(f"Model ƒë√£ s·∫µn s√†ng tr√™n **{device.upper()}** ‚Ä¢ checkpoint: `{ckpt_path}`")

# Uploader: h·ªó tr·ª£ nhi·ªÅu ·∫£nh
files = st.file_uploader("Ch·ªçn 1 ho·∫∑c nhi·ªÅu ·∫£nh", type=IMG_TYPES, accept_multiple_files=True)

# Option: k√©o-th·∫£ c·∫£ th∆∞ m·ª•c ƒë√£ n√©n .zip
zip_file = st.file_uploader("Ho·∫∑c ch·ªçn 1 file .zip ch·ª©a ·∫£nh", type=["zip"], accept_multiple_files=False)

# Gom t·∫•t c·∫£ ·∫£nh c·∫ßn d·ª± ƒëo√°n
images_to_run = []

if files:
    for f in files:
        try:
            img = Image.open(io.BytesIO(f.read())).convert("RGB")
            images_to_run.append((f.name, img))
        except Exception as e:
            st.warning(f"·∫¢nh l·ªói `{f.name}`: {e}")

# Gi·∫£i n√©n zip (n·∫øu c√≥)
if zip_file is not None:
    import zipfile, tempfile
    with tempfile.TemporaryDirectory() as tmpdir:
        zf = zipfile.ZipFile(io.BytesIO(zip_file.read()))
        zf.extractall(tmpdir)
        for p in Path(tmpdir).rglob("*"):
            if p.suffix.lower().strip(".") in IMG_TYPES:
                try:
                    img = Image.open(p).convert("RGB")
                    images_to_run.append((str(p.name), img))
                except Exception as e:
                    st.warning(f"·∫¢nh l·ªói `{p}`: {e}")

# N·∫øu kh√¥ng c√≥ ·∫£nh ‚Üí demo h∆∞·ªõng d·∫´n
if not images_to_run:
    st.info("üëâ H√£y k√©o-th·∫£ ·∫£nh (ho·∫∑c .zip) v√†o khung tr√™n ƒë·ªÉ d·ª± ƒëo√°n.")
    st.stop()

# Hi·ªÉn th·ªã theo grid
n = len(images_to_run)
rows = (n + cols - 1) // cols
idx = 0
for _ in range(rows):
    c = st.columns(cols)
    for j in range(cols):
        if idx >= n:
            break
        name, pil_img = images_to_run[idx]
        with c[j]:
            # d·ª± ƒëo√°n
            try:
                top_idx, top_prob = predict_image(model, device, pil_img, topk=topk)
                # render
                # st.image(pil_img, use_container_width=True)
                try:
                    st.image(pil_img, use_container_width=True)   # Streamlit m·ªõi (>= ~1.25)
                except TypeError:
                    st.image(pil_img, use_column_width=True)      # Streamlit c≈©
                if show_prob:
                    lines = [f"**{k}. {CLASS_NAMES[k] if k < len(CLASS_NAMES) else 'class_'+str(k)}** ‚Äî {p*100:.1f}%"
                             for k, p in zip(top_idx, top_prob)]
                else:
                    lines = [f"**{k}. {CLASS_NAMES[k] if k < len(CLASS_NAMES) else 'class_'+str(k)}**"
                             for k in top_idx]
                st.markdown(f"**{name}**")
                st.markdown(" ‚Ä¢ ".join(lines))





            except Exception as e:
                st.error(f"L·ªói d·ª± ƒëo√°n `{name}`: {e}")
        idx += 1

