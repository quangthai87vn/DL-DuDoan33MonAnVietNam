{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bc14243c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ==== CELL 0: CONFIG & DEVICE ====\n",
    "import os, torch\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu (ƒë√∫ng c·∫•u tr√∫c Train/Validate/Test nh∆∞ b·∫°n d√πng)\n",
    "ROOT = r\"C:/TRAIN/Deep Learning/vietnamese-foods/Images\"\n",
    "root_test = f\"{ROOT}/Test\"\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 1: TRANSFORMS GI·ªêNG L√öC TRAIN ====\n",
    "from torchvision import transforms\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    # N·∫øu l√∫c train c√≥ Normalize(mean, std) th√¨ PH·∫¢I d√πng y chang:\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "    #                      std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2211803e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l·ªõp: 33\n",
      "V√≠ d·ª• l·ªõp: ['Banh beo', 'Banh bot loc', 'Banh can', 'Banh canh', 'Banh chung', 'Banh cuon', 'Banh duc', 'Banh gio', 'Banh khot', 'Banh mi', 'Banh pia', 'Banh tet', 'Banh trang nuong', 'Banh xeo', 'Bun bo Hue', 'Bun dau mam tom', 'Bun mam', 'Bun rieu', 'Bun thit nuong', 'Ca kho to', 'Canh chua', 'Cao lau', 'Chao long', 'Com tam', 'Goi cuon', 'Hu tieu', 'Mi quang', 'Nem chua', 'Pho', 'Xoi xeo', 'banh_da_lon', 'banh_tieu', 'banh_trung_thu']\n"
     ]
    }
   ],
   "source": [
    "# ==== CELL 2: H√ÄM BUILD + G·ªåI H√ÄM => T·∫†O test_loader, class_names ====\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def build_test_loader(root_test_dir, transform, batch_size):\n",
    "    dataset = ImageFolder(root=root_test_dir, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    class_names = list(dataset.classes)            # th·ª© t·ª± theo th∆∞ m·ª•c c·ªßa ImageFolder\n",
    "    class_to_idx = dict(dataset.class_to_idx)      # mapping {class_name: idx} c·ªßa dataset\n",
    "    return loader, class_names, class_to_idx\n",
    "\n",
    "# >>> G·ªåI H√ÄM (r·∫•t hay b·ªã qu√™n)\n",
    "test_loader, class_names, ds_class_to_idx = build_test_loader(root_test, test_transform, BATCH_SIZE)\n",
    "\n",
    "print(\"S·ªë l·ªõp:\", len(class_names))\n",
    "print(\"V√≠ d·ª• l·ªõp:\", class_names[:33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "440812b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 3: CORE + HELPERS (gi·ªØ nguy√™n class_names ƒë√£ n·∫°p ·ªü Cell 2) ===\n",
    "import os, json, numpy as np, torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "assert \"class_names\" in globals(), \"B·∫°n ph·∫£i n·∫°p class_names ·ªü Cell 2 tr∆∞·ªõc cell n√†y!\"\n",
    "NUM_CLASSES = len(class_names)\n",
    "name2idx = {n:i for i,n in enumerate(class_names)}\n",
    "\n",
    "def make_remap(src_class_to_idx: dict, target_name2idx: dict):\n",
    "    \"\"\"T·∫°o b·∫£ng remap index c·ªßa dataset loader -> index theo class_names chu·∫©n.\"\"\"\n",
    "    ds_idx2name = {v:k for k,v in src_class_to_idx.items()}\n",
    "    return {src_idx: target_name2idx[ds_idx2name[src_idx]] for src_idx in ds_idx2name}\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_logits(model, loader, device, remap=None):\n",
    "    \"\"\"\n",
    "    Tr·∫£ v·ªÅ y_true, y_pred, y_prob v·ªõi c√πng th·ª© t·ª± class_names ƒë√£ c·ªë ƒë·ªãnh.\n",
    "    remap: dict idx_dataset -> idx_chu·∫©n (n·∫øu c·∫ßn)\n",
    "    \"\"\"\n",
    "    y_true, y_pred, y_prob = [], [], []\n",
    "\n",
    "    model.eval()\n",
    "    # dtype c·ªßa model (th∆∞·ªùng l√† float32)\n",
    "    model_dtype = next(model.parameters()).dtype\n",
    "\n",
    "    for x, y in loader:\n",
    "        # ƒê∆∞a ·∫£nh v·ªÅ ƒë√∫ng device + dtype c·ªßa model\n",
    "        x = x.to(device=device, dtype=model_dtype)\n",
    "\n",
    "        # Remap nh√£n n·∫øu dataset idx kh√°c class_names\n",
    "        if remap is not None:\n",
    "            # gi·ªØ y tr√™n CPU v√¨ ch·ªâ d√πng ƒë·ªÉ so s√°nh/stack\n",
    "            y = torch.as_tensor([remap[int(t)] for t in y], dtype=torch.long)\n",
    "        else:\n",
    "            y = y.detach().to(\"cpu\", dtype=torch.long)\n",
    "\n",
    "        # Suy lu·∫≠n\n",
    "        logits = model(x)                      # logits c√≥ dtype == model_dtype\n",
    "        prob = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        pred = prob.argmax(1)\n",
    "\n",
    "        y_prob.append(prob)\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(y.numpy())\n",
    "\n",
    "    import numpy as np\n",
    "    return np.concatenate(y_true), np.concatenate(y_pred), np.concatenate(y_prob)\n",
    "\n",
    "\n",
    "def cm_pretty(cm_counts, labels):\n",
    "    cm = cm_counts.astype(float) / cm_counts.sum(axis=1, keepdims=True)\n",
    "    cm = np.nan_to_num(cm)\n",
    "    return cm\n",
    "\n",
    "def draw_cm(cm_counts, run_name, save_dir=\"images\", threshold=0.10, figsize=(12,10), dpi=200):\n",
    "    import matplotlib.pyplot as plt, seaborn as sns\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    cm = cm_pretty(cm_counts, class_names)\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    sns.heatmap(cm, vmin=0, vmax=1, cmap=\"Blues\", square=True,\n",
    "                xticklabels=class_names, yticklabels=class_names, ax=ax, cbar_kws={'shrink': .7})\n",
    "    # annotate: ƒë∆∞·ªùng ch√©o + √¥ >= threshold\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            show = (i == j) or (cm[i,j] >= threshold)\n",
    "            if show and cm_counts[i,j] > 0:\n",
    "                ax.text(j+0.5, i+0.5, f\"{cm[i,j]*100:.0f}%\\n({cm_counts[i,j]})\",\n",
    "                        ha=\"center\", va=\"center\", fontsize=7, color=\"black\")\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "    ax.set_title(f\"Confusion Matrix (row-norm) ‚Äì {run_name}\", pad=10)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=8)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(save_dir, f\"{run_name}_cm.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\"); plt.show()\n",
    "    print(\"‚úì L∆∞u CM:\", out_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9d30448f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ test_loader & class_names s·∫µn s√†ng.\n"
     ]
    }
   ],
   "source": [
    "# QUICK CHECK tr∆∞·ªõc khi v·∫Ω\n",
    "try:\n",
    "    _ = iter(test_loader)\n",
    "    assert len(class_names) > 0\n",
    "    print(\"‚úÖ test_loader & class_names s·∫µn s√†ng.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå L·ªói:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "456a85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 4: PLOTS ‚Äì CM & TOP CONFUSIONS ====\n",
    "import os, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "def plot_confusion(cm_counts, class_names, run_name, save_path, row_norm=True, threshold=0.10, dpi=300):\n",
    "    \"\"\"\n",
    "    cm_counts: ma tr·∫≠n ƒë·∫øm (ch∆∞a chu·∫©n ho√°) k√≠ch th∆∞·ªõc [C, C]\n",
    "    row_norm : chu·∫©n ho√° theo h√†ng (recall) ƒë·ªÉ nh√¨n t·ªâ l·ªá ƒë√∫ng/sai t·ª´ng l·ªõp\n",
    "    threshold: ch·ªâ annotate c√°c √¥ >= threshold (ngo√†i ƒë∆∞·ªùng ch√©o) ƒë·ªÉ ƒë·ª° r·ªëi\n",
    "    \"\"\"\n",
    "    C = cm_counts.shape[0]\n",
    "    cm = cm_counts.astype(float)\n",
    "    if row_norm:\n",
    "        cm = cm / cm.sum(axis=1, keepdims=True)\n",
    "        cm = np.nan_to_num(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), dpi=200)\n",
    "    sns.heatmap(cm, vmin=0, vmax=1, cmap=\"Blues\", square=True,\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'shrink': .6}, ax=ax)\n",
    "\n",
    "    # annotate\n",
    "    for i in range(C):\n",
    "        for j in range(C):\n",
    "            show = (i == j) or (cm[i, j] >= threshold)\n",
    "            if show and cm_counts[i, j] > 0:\n",
    "                ax.text(j + 0.5, i + 0.5,\n",
    "                        f\"{cm[i,j]*100:.0f}%\\n({cm_counts[i,j]})\",\n",
    "                        ha=\"center\", va=\"center\", fontsize=7, color=\"black\")\n",
    "\n",
    "    ax.set_xlabel(\"Predicted\", fontsize=12)\n",
    "    ax.set_ylabel(\"True\", fontsize=12)\n",
    "    ax.set_title(f\"Confusion Matrix (row-norm) ‚Äì {run_name}\", fontsize=14, pad=10)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=8)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_top_confusions(cm_counts, class_names, run_name, save_path, topk=15, dpi=300):\n",
    "    \"\"\"\n",
    "    V·∫Ω Top-K c·∫∑p d·ªÖ nh·∫ßm nh·∫•t (theo % h√†ng). B·ªè ƒë∆∞·ªùng ch√©o.\n",
    "    \"\"\"\n",
    "    cm = cm_counts.astype(float)\n",
    "    cm = cm / cm.sum(axis=1, keepdims=True)\n",
    "    cm = np.nan_to_num(cm)\n",
    "\n",
    "    pairs = []\n",
    "    C = cm.shape[0]\n",
    "    for i in range(C):\n",
    "        for j in range(C):\n",
    "            if i == j: \n",
    "                continue\n",
    "            if cm_counts[i, j] == 0:\n",
    "                continue\n",
    "            pairs.append((i, j, cm[i, j], cm_counts[i, j]))\n",
    "\n",
    "    # sort theo t·ª∑ l·ªá gi·∫£m d·∫ßn\n",
    "    pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "    pairs = pairs[:topk]\n",
    "\n",
    "    if not pairs:\n",
    "        print(\"Kh√¥ng c√≥ c·∫∑p nh·∫ßm ƒë√°ng k·ªÉ.\")\n",
    "        return\n",
    "\n",
    "    labels = [f\"{class_names[i]} ‚Üí {class_names[j]}\" for (i, j, _, _) in pairs]\n",
    "    perc   = [100 * p for (_, _, p, _) in pairs]\n",
    "    counts = [c for (_, _, _, c) in pairs]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 7), dpi=200)\n",
    "    ax.barh(labels, perc)\n",
    "    ax.invert_yaxis()\n",
    "    for k, (p, c) in enumerate(zip(perc, counts)):\n",
    "        ax.text(p + 0.3, k, f\"{p:.1f}% ({c})\", va=\"center\", fontsize=10)\n",
    "    ax.set_xlabel(\"T·ªâ l·ªá nh·∫ßm (%)\")\n",
    "    ax.set_title(f\"Top-{len(pairs)} c·∫∑p d·ªÖ nh·∫ßm nh·∫•t ‚Äì {run_name}\", fontsize=14, pad=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac57e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 5: EVALUATE ONE RUN ====\n",
    "import os, json, torch\n",
    "import numpy as np\n",
    "\n",
    "# B·∫°n c√≥ th·ªÉ ƒë·ªïi ƒë·ªÉ kh·ªõp folder th·∫≠t c·ªßa b·∫°n\n",
    "RUNS_DIR = \"Runs\"   # m·ªói th∆∞ m·ª•c con l√† 1 l·∫ßn train, c√≥ file .mtl/.pt/.pth\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from model.mtl_cnn import mtl_cnn_v1\n",
    "from model.mobilenet_v4 import CustomMobileNetV4  # file b·∫°n ƒë√£ g·ª≠i\n",
    "from model.efficientnet_b0 import CustomEfficientNetB0\n",
    "\n",
    "def model_auto(run_name, num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    Suy ƒëo√°n ki·∫øn tr√∫c t·ª´ t√™n run. B·∫°n ƒëang d√πng ti·ªÅn t·ªë:\n",
    "    - 'mtl-cnn-...'\n",
    "    - 'mtl-mobilenetv4-...'\n",
    "    - 'mtl-efficientnetb0-...'\n",
    "    \"\"\"\n",
    "    name = run_name.lower()\n",
    "    if \"mobilenetv4\" in name:\n",
    "        return CustomMobileNetV4(num_classes=num_classes)\n",
    "    if \"efficientnetb0\" in name or \"efficientnet_b0\" in name:\n",
    "        return CustomEfficientNetB0(num_classes=num_classes)\n",
    "    # m·∫∑c ƒë·ªãnh: CNN t·ª± x√¢y\n",
    "    return mtl_cnn_v1(num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# --- REPLACE this in Cell 5 ---\n",
    "from glob import glob\n",
    "import os, time\n",
    "\n",
    "EXTS = {\".mtl\", \".pt\", \".pth\"}\n",
    "\n",
    "def find_checkpoint(run_path: str):\n",
    "    \"\"\"\n",
    "    T√¨m checkpoint trong run_path v√† c√°c th∆∞ m·ª•c con ph·ªï bi·∫øn.\n",
    "    ∆Øu ti√™n file c√≥ 'best' trong t√™n; n·∫øu kh√¥ng c√≥, l·∫•y file m·ªõi nh·∫•t.\n",
    "    \"\"\"\n",
    "    # c√°c pattern hay g·∫∑p; ** ƒë·ªÉ ƒë·∫£m b·∫£o qu√©t s√¢u\n",
    "    patterns = [\n",
    "        \"*\", \"checkpoints/*\", \"checkpoint/*\", \"ckpt*/*\",\n",
    "        \"models/*\", \"weights/*\", \"**/*\"\n",
    "    ]\n",
    "    cands = []\n",
    "    for pat in patterns:\n",
    "        for p in glob(os.path.join(run_path, pat), recursive=True):\n",
    "            if os.path.isfile(p) and os.path.splitext(p)[1].lower() in EXTS:\n",
    "                cands.append(p)\n",
    "\n",
    "    if not cands:\n",
    "        return None\n",
    "\n",
    "    # ch·∫•m ƒëi·ªÉm: c√≥ 'best' ƒë∆∞·ª£c +100, 'ema' +10, 'last' +5; sau ƒë√≥ ∆∞u ti√™n mtime m·ªõi h∆°n\n",
    "    def score(p):\n",
    "        name = os.path.basename(p).lower()\n",
    "        s = 0\n",
    "        if \"best\" in name: s += 100\n",
    "        if \"ema\"  in name: s += 10\n",
    "        if \"last\" in name: s += 5\n",
    "        return (s, os.path.getmtime(p))\n",
    "\n",
    "    cands.sort(key=score, reverse=True)\n",
    "    chosen = cands[0]\n",
    "    print(f\"  ‚úì checkpoint: {os.path.relpath(chosen, run_path)}\")\n",
    "    return chosen\n",
    "\n",
    "def load_checkpoint(run_path_or_name, ckpt_path, device):\n",
    "    \"\"\"\n",
    "    T·ª± ƒë·ªông t·∫°o model ƒë√∫ng lo·∫°i d·ª±a theo t√™n run ho·∫∑c object ƒë√£ truy·ªÅn v√†o.\n",
    "    Tr·∫£ v·ªÅ model ƒë√£ load tr·ªçng s·ªë, .to(device).eval()\n",
    "    \"\"\"\n",
    "    # 1Ô∏è‚É£ N·∫øu truy·ªÅn v√†o l√† object model (vd: CustomMobileNet, CNN,...)\n",
    "    if not isinstance(run_path_or_name, (str, bytes, os.PathLike)):\n",
    "        model = run_path_or_name\n",
    "        run_name = model.__class__.__name__\n",
    "    else:\n",
    "        # 2Ô∏è‚É£ N·∫øu truy·ªÅn v√†o l√† ƒë∆∞·ªùng d·∫´n / t√™n run\n",
    "        run_name = os.path.basename(str(run_path_or_name).rstrip(os.sep))\n",
    "        model = build_model_auto(run_name)\n",
    "\n",
    "    # 3Ô∏è‚É£ ƒê∆∞a model l√™n device\n",
    "    model = model.to(device).eval()\n",
    "\n",
    "    # 4Ô∏è‚É£ Load checkpoint ƒë√∫ng device\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "    # 5Ô∏è‚É£ X·ª≠ l√Ω nhi·ªÅu ƒë·ªãnh d·∫°ng state_dict kh√°c nhau\n",
    "    if isinstance(state, dict):\n",
    "        if \"state_dict\" in state:\n",
    "            sd = state[\"state_dict\"]\n",
    "        elif \"net\" in state:\n",
    "            sd = state[\"net\"]\n",
    "        elif \"classification_best\" in state:\n",
    "            sd = state[\"classification_best\"]\n",
    "        elif \"model\" in state and isinstance(state[\"model\"], dict):\n",
    "            sd = state[\"model\"]\n",
    "        else:\n",
    "            sd = state\n",
    "    else:\n",
    "        sd = state\n",
    "\n",
    "    # 6Ô∏è‚É£ Load v√†o model\n",
    "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "    if missing or unexpected:\n",
    "        print(f\"‚ö†Ô∏è  load_state_dict warning ‚Üí missing: {missing}, unexpected: {unexpected}\")\n",
    "\n",
    "    model = model.float().to(device).eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model_at(run_path, run_name):\n",
    "    # 1) loader cho TEST (d√πng build_test_loader b·∫°n ƒë√£ vi·∫øt, nh·ªõ truy·ªÅn batch_size)\n",
    "    test_loader = build_test_loader(root_test, test_transform, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # 2) Remap label n·∫øu c·∫ßn (dataset.class_to_idx -> class_names)\n",
    "    ds_idx2name = {v: k for k, v in test_loader.dataset.class_to_idx.items()}\n",
    "    name2idx = {n: i for i, n in enumerate(class_names)}\n",
    "    remap = {src_idx: name2idx[ds_idx2name[src_idx]] for src_idx in range(len(ds_idx2name))}\n",
    "\n",
    "    # 3) l·∫•y checkpoint t·ªët nh·∫•t\n",
    "    ckpt_path = pick_checkpoint(run_path)  # b·∫°n ƒë√£ c√≥\n",
    "\n",
    "    # 4) load model v·ªÅ ƒë√∫ng device + eval\n",
    "    model = load_checkpoint(run_path, ckpt_path, device)\n",
    "\n",
    "    # 5) thu logits/predicts\n",
    "    y_true, y_pred, y_prob = collect_logits(model, test_loader, device, remap=remap)\n",
    "\n",
    "    # 6) t√≠nh c√°c ch·ªâ s·ªë v√† v·∫Ω h√¨nh (b·∫°n ƒë√£ c√≥ code s·∫µn)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    # ‚Ä¶ (v·∫Ω confusion matrix, top-confusions, l∆∞u ·∫£nh ‚Ä¶)\n",
    "    return {\"run\": run_name, \"acc\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c8b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è  ƒê√°nh gi√°: mtl-cnn-20251029-201543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_31584\\3301479262.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(ckpt_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==== CELL 6: EVALUATE ALL RUNS & RANKING (robust loader tuple) ====\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "RUNS_DIR   = \"Runs\"\n",
    "IMAGES_DIR = \"images\"\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# D√πng l·∫°i class_names ƒë√£ n·∫°p ·ªü cell tr∆∞·ªõc; n·∫øu ch∆∞a c√≥ th√¨ th·ª≠ ƒë·ªçc file d·ª± ph√≤ng\n",
    "if \"class_names\" not in globals():\n",
    "    # n·∫øu b·∫°n ƒë√£ c√≥ file class_names.json d∆∞·ªõi ROOT th√¨ m·ªü ra\n",
    "    fallback_json = os.path.join(ROOT, \"class_names.json\")\n",
    "    if os.path.isfile(fallback_json):\n",
    "        class_names = json.load(open(fallback_json, \"r\", encoding=\"utf-8\"))\n",
    "    else:\n",
    "        raise RuntimeError(\"B·∫°n ch∆∞a n·∫°p class_names. H√£y ch·∫°y cell n·∫°p class_names ho·∫∑c cung c·∫•p file class_names.json.\")\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "\n",
    "# Cache ƒë·ªÉ Cell ROC nhi·ªÅu model\n",
    "if \"ROC_CACHE\" not in globals():\n",
    "    ROC_CACHE = []\n",
    "\n",
    "def load_run_config(run_path, default_img=224, default_bs=64):\n",
    "    cfg_path = os.path.join(run_path, \"config.json\")\n",
    "    img, bs = default_img, default_bs\n",
    "    if os.path.isfile(cfg_path):\n",
    "        try:\n",
    "            cfg = json.load(open(cfg_path, \"r\", encoding=\"utf-8\"))\n",
    "            img = int(cfg.get(\"img_size\", cfg.get(\"IMG_SIZE\", img)))\n",
    "            bs  = int(cfg.get(\"batch_size\", cfg.get(\"BATCH_SIZE\", bs)))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return img, bs\n",
    "\n",
    "def create_test_transform(img_size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "def pick_checkpoint(run_path):\n",
    "    ckpt_dir = os.path.join(run_path, \"checkpoints\")\n",
    "    cands = []\n",
    "    for d in [ckpt_dir, run_path]:\n",
    "        if not os.path.isdir(d): \n",
    "            continue\n",
    "        for fn in os.listdir(d):\n",
    "            if fn.lower().endswith((\".mtl\", \".pt\", \".pth\")):\n",
    "                cands.append(os.path.join(d, fn))\n",
    "    if not cands: \n",
    "        return None\n",
    "    mtls = [p for p in cands if p.lower().endswith(\".mtl\")]\n",
    "    return sorted(mtls or cands, key=os.path.getmtime)[-1]\n",
    "\n",
    "def normalize_loader_tuple(loader_out):\n",
    "    \"\"\"\n",
    "    Tr·∫£ v·ªÅ: (test_loader, ds_class_to_idx)\n",
    "    - Ch·∫•p nh·∫≠n build_test_loader tr·∫£ v·ªÅ DataLoader ho·∫∑c tuple (loader, class_to_idx) / (loader, idx2name)...\n",
    "    \"\"\"\n",
    "    ds_class_to_idx = None\n",
    "    if isinstance(loader_out, tuple):\n",
    "        # ph·∫ßn t·ª≠ ƒë·∫ßu ch·∫Øc ch·∫Øn l√† loader\n",
    "        test_loader = loader_out[0]\n",
    "        # c·ªë t√¨m dict √°nh x·∫° l·ªõp trong c√°c ph·∫ßn t·ª≠ c√≤n l·∫°i\n",
    "        for item in loader_out[1:]:\n",
    "            if isinstance(item, dict):\n",
    "                # n·∫øu l√† class_to_idx: key l√† t√™n l·ªõp (str), value l√† int\n",
    "                if all(isinstance(k, str) for k in item.keys()) and all(isinstance(v, int) for v in item.values()):\n",
    "                    ds_class_to_idx = item\n",
    "                    break\n",
    "                # n·∫øu l√† idx2name: key int, value str -> ƒë·∫£o l·∫°i\n",
    "                if all(isinstance(k, int) for k in item.keys()) and all(isinstance(v, str) for v in item.values()):\n",
    "                    ds_class_to_idx = {v: k for k, v in item.items()}\n",
    "                    break\n",
    "    else:\n",
    "        test_loader = loader_out\n",
    "\n",
    "    # fallback l·∫•y t·ª´ dataset\n",
    "    if ds_class_to_idx is None:\n",
    "        ds_class_to_idx = getattr(getattr(test_loader, \"dataset\", object()), \"class_to_idx\", {})\n",
    "        if not isinstance(ds_class_to_idx, dict):\n",
    "            ds_class_to_idx = {}\n",
    "\n",
    "    return test_loader, ds_class_to_idx\n",
    "\n",
    "def evaluate_model_at(run_path, run_name):\n",
    "    # 1) ƒë·ªçc config\n",
    "    img_size, bs = load_run_config(run_path, default_img=224, default_bs=64)\n",
    "    test_transform = create_test_transform(img_size)\n",
    "\n",
    "    # 2) build loader (c√≥ th·ªÉ tr·∫£ v·ªÅ tuple)\n",
    "    loader_out = build_test_loader(root_test, test_transform, batch_size=bs)\n",
    "    test_loader, ds_class_to_idx = normalize_loader_tuple(loader_out)\n",
    "\n",
    "    # 3) remap nh√£n n·∫øu th·ª© t·ª± dataset kh√°c class_names chu·∫©n\n",
    "    name2idx = {n: i for i, n in enumerate(class_names)}\n",
    "    remap = make_remap(ds_class_to_idx, name2idx) if 'make_remap' in globals() else None\n",
    "\n",
    "    # 4) load checkpoint + model\n",
    "    ckpt_path = pick_checkpoint(run_path)\n",
    "    if ckpt_path is None:\n",
    "        print(f\"  ‚ö† {run_name}: kh√¥ng t√¨m th·∫•y checkpoint (.mtl/.pt/.pth) ‚áí b·ªè qua.\")\n",
    "        return None\n",
    "    model = model_auto(run_name)\n",
    "\n",
    "    model = load_checkpoint(run_name, ckpt_path, device)\n",
    "\n",
    "    # 5) d·ª± ƒëo√°n\n",
    "    y_true, y_pred, y_prob = collect_logits(model, test_loader, device, remap=remap)\n",
    "\n",
    "    # 6) metrics\n",
    "    acc = float(accuracy_score(y_true, y_pred))\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # 7) cache cho ROC ƒëa m√¥ h√¨nh\n",
    "    ROC_CACHE.append({\n",
    "        \"name\": run_name,\n",
    "        \"y_true\": np.asarray(y_true),\n",
    "        \"y_prob\": np.asarray(y_prob),\n",
    "        \"class_names\": class_names,\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"run\": run_name, \"acc\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1,\n",
    "        \"img_size\": img_size, \"batch_size\": bs, \"ckpt\": os.path.basename(ckpt_path)\n",
    "    }\n",
    "\n",
    "# ==== qu√©t & ƒë√°nh gi√° t·∫•t c·∫£ runs ====\n",
    "results = []\n",
    "if not os.path.isdir(RUNS_DIR):\n",
    "    print(f\"‚ö† Th∆∞ m·ª•c {RUNS_DIR} kh√¥ng t·ªìn t·∫°i.\")\n",
    "else:\n",
    "    for run_name in sorted(os.listdir(RUNS_DIR)):\n",
    "        run_path = os.path.join(RUNS_DIR, run_name)\n",
    "        if not os.path.isdir(run_path):\n",
    "            continue\n",
    "        print(f\"‚ñ∂Ô∏è  ƒê√°nh gi√°: {run_name}\")\n",
    "        res = evaluate_model_at(run_path, run_name)\n",
    "        if res:\n",
    "            results.append(res)\n",
    "\n",
    "# ==== b·∫£ng x·∫øp h·∫°ng & l∆∞u th√†nh ·∫£nh ====\n",
    "if results:\n",
    "    df = pd.DataFrame(results).sort_values(\"acc\", ascending=False)\n",
    "    display(df)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 0.45*len(df)+1), dpi=220)\n",
    "    ax.axis(\"off\")\n",
    "    tbl = ax.table(cellText=df.values, colLabels=df.columns, loc=\"center\", cellLoc=\"center\")\n",
    "    tbl.auto_set_font_size(False); tbl.set_fontsize(9); tbl.scale(1, 1.25)\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(IMAGES_DIR, \"summary_models.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"‚úÖ L∆∞u: {out_png}\")\n",
    "else:\n",
    "    print(\"‚ö† Kh√¥ng c√≥ run h·ª£p l·ªá trong th∆∞ m·ª•c Runs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba726ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 7 (REPLACE): V·∫Ω Loss/Accuracy CHO T·∫§T C·∫¢ C√ÅC RUNS ====\n",
    "import os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RUNS_DIR = \"Runs\"          # gi·ªØ ƒë√∫ng ƒë∆∞·ªùng d·∫´n b·∫°n ƒëang d√πng\n",
    "IMAGES_DIR = \"images\"\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "def pick_col(df, pats):\n",
    "    \"\"\"Ch·ªçn c·ªôt ƒë·∫ßu ti√™n kh·ªõp pattern (kh√¥ng ph√¢n bi·ªát hoa/th∆∞·ªùng).\"\"\"\n",
    "    pats = [p.lower() for p in pats]\n",
    "    for c in df.columns:\n",
    "        cl = c.lower()\n",
    "        if any(re.search(p, cl) for p in pats):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def plot_history_for_run(run_path, run_name):\n",
    "    # 1) t√¨m file log h·ª£p l·ªá\n",
    "    for cand in [\"history.csv\", \"history.json\", \"train_log.csv\", \"metrics.csv\"]:\n",
    "        hp = os.path.join(run_path, cand)\n",
    "        if os.path.isfile(hp):\n",
    "            hist_path = hp\n",
    "            break\n",
    "    else:\n",
    "        print(f\"[-] {run_name}: kh√¥ng th·∫•y history.(csv|json)\")\n",
    "        return\n",
    "\n",
    "    # 2) ƒë·ªçc log v√† chu·∫©n ho√° c·ªôt\n",
    "    if hist_path.endswith(\".json\"):\n",
    "        df = pd.read_json(hist_path)\n",
    "    else:\n",
    "        df = pd.read_csv(hist_path)\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # 3) epoch th·ª±c t·∫ø trong file; n·∫øu kh√¥ng c√≥ c·ªôt epoch th√¨ m·∫∑c ƒë·ªãnh 1..len\n",
    "    c_epoch = pick_col(df, [r\"^epoch$\", r\"^epochs?$\"])\n",
    "    epoch = df[c_epoch].to_numpy() if c_epoch else np.arange(1, len(df)+1)\n",
    "\n",
    "    # 4) b·∫Øt c√°c c·ªôt loss/acc ‚Äúm·ªÅm‚Äù\n",
    "    c_tr_loss = pick_col(df, [r\"^loss$\", r\"train.*loss\"])\n",
    "    c_va_loss = pick_col(df, [r\"val.*loss\", r\"valid.*loss\"])\n",
    "    c_tr_acc  = pick_col(df, [r\"^acc$\", r\"accuracy$\", r\"train.*acc\", r\"train.*accuracy\"])\n",
    "    c_va_acc  = pick_col(df, [r\"val.*acc\", r\"val.*accuracy\", r\"valid.*acc\", r\"valid.*accuracy\"])\n",
    "\n",
    "    tr_loss = df[c_tr_loss].to_numpy() if c_tr_loss else None\n",
    "    va_loss = df[c_va_loss].to_numpy() if c_va_loss else None\n",
    "    tr_acc  = df[c_tr_acc].to_numpy()  if c_tr_acc  else None\n",
    "    va_acc  = df[c_va_acc].to_numpy()  if c_va_acc  else None\n",
    "\n",
    "    # 5) epoch t·ªët nh·∫•t ƒë·ªÉ annotate\n",
    "    best_ep, note = None, \"\"\n",
    "    if va_acc is not None and len(va_acc) > 0:\n",
    "        best_ep = int(epoch[np.nanargmax(va_acc)])\n",
    "        note = f\"best val_acc@{best_ep}={np.nanmax(va_acc):.3f}\"\n",
    "    elif va_loss is not None and len(va_loss) > 0:\n",
    "        best_ep = int(epoch[np.nanargmin(va_loss)])\n",
    "        note = f\"best val_loss@{best_ep}={np.nanmin(va_loss):.3f}\"\n",
    "\n",
    "    # 6) v·∫Ω 2 subplot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5), dpi=160)\n",
    "\n",
    "    # Loss\n",
    "    if tr_loss is not None: ax[0].plot(epoch, tr_loss, label=\"Train loss\")\n",
    "    if va_loss is not None: ax[0].plot(epoch, va_loss, label=\"Val loss\")\n",
    "    if best_ep is not None: ax[0].axvline(best_ep, ls=\"--\", lw=1, c=\"gray\")\n",
    "    ax[0].set_title(f\"{run_name} ‚Äì Loss\")\n",
    "    ax[0].set_xlabel(\"Epoch\"); ax[0].set_ylabel(\"Loss\"); ax[0].legend()\n",
    "\n",
    "    # Accuracy\n",
    "    if tr_acc is not None: ax[1].plot(epoch, tr_acc, label=\"Train acc\")\n",
    "    if va_acc is not None: ax[1].plot(epoch, va_acc, label=\"Val acc\")\n",
    "    if best_ep is not None:\n",
    "        ax[1].axvline(best_ep, ls=\"--\", lw=1, c=\"gray\", label=note if va_acc is not None else None)\n",
    "    ax[1].set_title(f\"{run_name} ‚Äì Accuracy\")\n",
    "    ax[1].set_xlabel(\"Epoch\"); ax[1].set_ylabel(\"Accuracy\"); ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(IMAGES_DIR, f\"{run_name}_history.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"‚úì ƒê√£ l∆∞u: {out_png}\")\n",
    "\n",
    "# üîÅ DUY·ªÜT H·∫æT T·∫§T C·∫¢ RUNS v√† v·∫Ω\n",
    "if not os.path.isdir(RUNS_DIR):\n",
    "    print(f\"Th∆∞ m·ª•c '{RUNS_DIR}' kh√¥ng t·ªìn t·∫°i.\")\n",
    "else:\n",
    "    for run_name in sorted(os.listdir(RUNS_DIR)):\n",
    "        run_path = os.path.join(RUNS_DIR, run_name)\n",
    "        if not os.path.isdir(run_path):\n",
    "            continue\n",
    "        print(f\"‚Üí V·∫Ω l·ªãch s·ª≠: {run_name}\")\n",
    "        plot_history_for_run(run_path, run_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035f740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 8A: PH√ÇN T√çCH M√î H√åNH CHUY√äN S√ÇU ====\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "IMAGES_DIR = \"images\"\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# ƒê·∫£m b·∫£o c√≥ class_names v√† test_loader (ƒë√£ build ·ªü Cell 3)\n",
    "assert \"class_names\" in globals(), \"‚ö†Ô∏è C·∫ßn n·∫°p class_names tr∆∞·ªõc Cell 8!\"\n",
    "assert \"test_loader\" in globals(), \"‚ö†Ô∏è C·∫ßn build test_loader tr∆∞·ªõc Cell 8!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8B: Bi·ªÉu ƒë·ªì ROC Curve & AUC (multi-class, one-vs-rest)\n",
    "def plot_roc_auc_for_model(run_name, y_true, y_prob, class_names):\n",
    "    \"\"\"\n",
    "    V·∫Ω ROC & t√≠nh AUC trung b√¨nh cho m√¥ h√¨nh ƒëa l·ªõp.\n",
    "    y_true:  nh√£n th·∫≠t (int)\n",
    "    y_prob:  x√°c su·∫•t softmax [N, num_classes]\n",
    "    \"\"\"\n",
    "    n_classes = len(class_names)\n",
    "    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
    "\n",
    "    # ROC & AUC t·ª´ng l·ªõp\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # AUC trung b√¨nh\n",
    "    macro_auc = roc_auc_score(y_true_bin, y_prob, average=\"macro\")\n",
    "    print(f\"‚Üí {run_name}: macro AUC = {macro_auc:.4f}\")\n",
    "\n",
    "    # V·∫Ω 5 l·ªõp ƒë·∫ßu ƒë·ªÉ tr√°nh r·ªëi\n",
    "    plt.figure(figsize=(7, 6), dpi=140)\n",
    "    for i, cname in enumerate(class_names[:5]):\n",
    "        plt.plot(fpr[i], tpr[i], label=f\"{cname} (AUC = {roc_auc[i]:.3f})\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n",
    "    plt.title(f\"ROC Curves ‚Äì {run_name}\\nMacro AUC = {macro_auc:.3f}\")\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(fontsize=8); plt.tight_layout()\n",
    "    out_png = os.path.join(IMAGES_DIR, f\"{run_name}_roc_auc.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"‚úì ƒê√£ l∆∞u:\", out_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (C) T·ªëc ƒë·ªô & hi·ªáu nƒÉng Inferencing\n",
    "import time\n",
    "\n",
    "def benchmark_model(model, device, input_size=(1, 3, 224, 224), repeat=30):\n",
    "    \"\"\"\n",
    "    ƒêo th·ªùi gian infer (Forward pass) v√† ∆∞·ªõc t√≠nh FPS tr√™n batch 1.\n",
    "    \"\"\"\n",
    "    x = torch.randn(input_size).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # warm-up\n",
    "        for _ in range(5):\n",
    "            _ = model(x)\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        t0 = time.time()\n",
    "        for _ in range(repeat):\n",
    "            _ = model(x)\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        t1 = time.time()\n",
    "\n",
    "    avg = (t1 - t0) / repeat\n",
    "    fps = 1 / avg\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"‚è±Ô∏è {model.__class__.__name__}: {avg*1000:.2f} ms/infer ({fps:.1f} FPS) | Params ‚âà {params/1e6:.2f} M\")\n",
    "    return avg, fps, params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14749bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 9: ·∫¢NH TEST B·ªä NH·∫¶M NHI·ªÄU NH·∫§T (Top Confused Pairs) ====\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "IMAGES_DIR = \"images\"\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "def show_top_confused_pairs(model, test_loader, class_names, run_name, device, top_k=6):\n",
    "    \"\"\"\n",
    "    Hi·ªÉn th·ªã top K c·∫∑p l·ªõp m√† model nh·∫ßm l·∫´n nhi·ªÅu nh·∫•t (d·ª±a tr√™n confusion matrix)\n",
    "    + K√®m ·∫£nh v√≠ d·ª• th·∫≠t b·ªã nh·∫ßm.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true, y_pred, paths = [], [], []\n",
    "\n",
    "    # üîπ B1: Thu nh√£n th·∫≠t, d·ª± ƒëo√°n, v√† ƒë∆∞·ªùng d·∫´n ·∫£nh\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            outputs = model(x)\n",
    "            preds = outputs.argmax(1).cpu().numpy()\n",
    "            y_true.extend(y.numpy())\n",
    "            y_pred.extend(preds)\n",
    "\n",
    "            # N·∫øu dataset c√≥ thu·ªôc t√≠nh filepaths / samples\n",
    "            if hasattr(test_loader.dataset, \"samples\"):\n",
    "                paths.extend([s[0] for s in test_loader.dataset.samples[len(paths):len(paths)+len(y)]])\n",
    "            elif hasattr(test_loader.dataset, \"imgs\"):\n",
    "                paths.extend([s[0] for s in test_loader.dataset.imgs[len(paths):len(paths)+len(y)]])\n",
    "            else:\n",
    "                paths.extend([\"(Kh√¥ng c√≥ ƒë∆∞·ªùng d·∫´n)\"] * len(y))\n",
    "\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize=\"true\")\n",
    "    cm_counts = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # üîπ B2: X√°c ƒë·ªãnh c√°c c·∫∑p b·ªã nh·∫ßm nhi·ªÅu nh·∫•t (kh√¥ng l·∫•y ƒë∆∞·ªùng ch√©o)\n",
    "    pairs = []\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            if i != j and cm[i, j] > 0:\n",
    "                pairs.append((i, j, cm[i, j], cm_counts[i, j]))\n",
    "    top_pairs = sorted(pairs, key=lambda x: x[2], reverse=True)[:top_k]\n",
    "\n",
    "    # üîπ B3: Hi·ªÉn th·ªã t·ª´ng c·∫∑p k√®m ·∫£nh minh h·ªça\n",
    "    fig, axes = plt.subplots(len(top_pairs), 2, figsize=(7, 3 * len(top_pairs)))\n",
    "    fig.suptitle(f\"·∫¢nh test th·ª±c s·ª± b·ªã model nh·∫ßm (Top confused pairs) ‚Äì {run_name}\",\n",
    "                 fontsize=14, fontweight=\"bold\", y=0.995)\n",
    "\n",
    "    for idx, (i, j, rate, count) in enumerate(top_pairs):\n",
    "        # T√¨m ·∫£nh v√≠ d·ª• b·ªã nh·∫ßm n√†y\n",
    "        candidates = np.where((y_true == i) & (y_pred == j))[0]\n",
    "        img_path = paths[candidates[0]] if len(candidates) > 0 else None\n",
    "\n",
    "        # C·ªôt 1: ·∫£nh minh h·ªça\n",
    "        ax_img, ax_text = axes[idx]\n",
    "        ax_img.axis(\"off\")\n",
    "        if img_path and os.path.exists(img_path):\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            ax_img.imshow(img)\n",
    "        else:\n",
    "            ax_img.text(0.5, 0.5, \"Kh√¥ng c√≥ ·∫£nh\", ha=\"center\", va=\"center\", fontsize=10)\n",
    "\n",
    "        # C·ªôt 2: th√¥ng tin nh·∫ßm l·∫´n\n",
    "        ax_text.axis(\"off\")\n",
    "        text = (\n",
    "            f\"·∫¢nh b·ªã nh·∫ßm: {class_names[i]} ‚Üí {class_names[j]}\\n\\n\"\n",
    "            f\"T·ªâ l·ªá nh·∫ßm (CM): {rate*100:.2f}% ({count} m·∫´u)\\n\"\n",
    "            f\"True: {class_names[i]}\\nPred: {class_names[j]}\"\n",
    "        )\n",
    "        ax_text.text(0, 0.5, text, va=\"center\", fontsize=11)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(IMAGES_DIR, f\"{run_name}_top_confused_pairs.png\")\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"‚úì ƒê√£ l∆∞u: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gi·∫£ s·ª≠ b·∫°n ƒë√£ c√≥ results [] t·ª´ Cell 6 ‚Äì ch·ª©a t√™n m·ªói run\n",
    "for r in results:\n",
    "    run_name = r[\"run\"]\n",
    "    run_path = os.path.join(\"Runs\", run_name)\n",
    "    ckpt = pick_checkpoint(run_path)\n",
    "    model = load_checkpoint(run_name, ckpt, device)\n",
    "    print(f\"\\n=== ƒê√ÅNH GI√Å M√î H√åNH {run_name} ===\")\n",
    "\n",
    "    # 1Ô∏è‚É£ Inference & thu logits\n",
    "    y_true, y_pred, y_prob = collect_logits(model, test_loader, device)\n",
    "\n",
    "    # 2Ô∏è‚É£ V·∫Ω ROC & AUC\n",
    "    plot_roc_auc_for_model(run_name, y_true, y_prob, class_names)\n",
    "\n",
    "\n",
    "    # Visualize ‚ÄúTop Confused Pairs‚Äù (·∫¢nh b·ªã nh·∫ßm nhi·ªÅu nh·∫•t)\n",
    "    show_top_confused_pairs(model, test_loader, class_names, run_name, device, top_k=6)\n",
    "\n",
    "    # 4Ô∏è‚É£ Benchmark t·ªëc ƒë·ªô\n",
    "    benchmark_model(model, device, (1, 3, 224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f00a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
