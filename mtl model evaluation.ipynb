{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bc14243c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ==== CELL 0: CONFIG & DEVICE ====\n",
    "import os, torch\n",
    "\n",
    "# Đường dẫn dữ liệu (đúng cấu trúc Train/Validate/Test như bạn dùng)\n",
    "ROOT = r\"C:/TRAIN/Deep Learning/vietnamese-foods/Images\"\n",
    "root_test = f\"{ROOT}/Test\"\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 1: TRANSFORMS GIỐNG LÚC TRAIN ====\n",
    "from torchvision import transforms\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    # Nếu lúc train có Normalize(mean, std) thì PHẢI dùng y chang:\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "    #                      std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2211803e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lớp: 33\n",
      "Ví dụ lớp: ['Banh beo', 'Banh bot loc', 'Banh can', 'Banh canh', 'Banh chung', 'Banh cuon', 'Banh duc', 'Banh gio', 'Banh khot', 'Banh mi', 'Banh pia', 'Banh tet', 'Banh trang nuong', 'Banh xeo', 'Bun bo Hue', 'Bun dau mam tom', 'Bun mam', 'Bun rieu', 'Bun thit nuong', 'Ca kho to', 'Canh chua', 'Cao lau', 'Chao long', 'Com tam', 'Goi cuon', 'Hu tieu', 'Mi quang', 'Nem chua', 'Pho', 'Xoi xeo', 'banh_da_lon', 'banh_tieu', 'banh_trung_thu']\n"
     ]
    }
   ],
   "source": [
    "# ==== CELL 2: HÀM BUILD + GỌI HÀM => TẠO test_loader, class_names ====\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def build_test_loader(root_test_dir, transform, batch_size):\n",
    "    dataset = ImageFolder(root=root_test_dir, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    class_names = list(dataset.classes)            # thứ tự theo thư mục của ImageFolder\n",
    "    class_to_idx = dict(dataset.class_to_idx)      # mapping {class_name: idx} của dataset\n",
    "    return loader, class_names, class_to_idx\n",
    "\n",
    "# >>> GỌI HÀM (rất hay bị quên)\n",
    "test_loader, class_names, ds_class_to_idx = build_test_loader(root_test, test_transform, BATCH_SIZE)\n",
    "\n",
    "print(\"Số lớp:\", len(class_names))\n",
    "print(\"Ví dụ lớp:\", class_names[:33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "440812b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 3: CORE + HELPERS (giữ nguyên class_names đã nạp ở Cell 2) ===\n",
    "import os, json, numpy as np, torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "assert \"class_names\" in globals(), \"Bạn phải nạp class_names ở Cell 2 trước cell này!\"\n",
    "NUM_CLASSES = len(class_names)\n",
    "name2idx = {n:i for i,n in enumerate(class_names)}\n",
    "\n",
    "def make_remap(src_class_to_idx: dict, target_name2idx: dict):\n",
    "    \"\"\"Tạo bảng remap index của dataset loader -> index theo class_names chuẩn.\"\"\"\n",
    "    ds_idx2name = {v:k for k,v in src_class_to_idx.items()}\n",
    "    return {src_idx: target_name2idx[ds_idx2name[src_idx]] for src_idx in ds_idx2name}\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_logits(model, loader, device, remap=None):\n",
    "    \"\"\"\n",
    "    Trả về y_true, y_pred, y_prob với cùng thứ tự class_names đã cố định.\n",
    "    remap: dict idx_dataset -> idx_chuẩn (nếu cần)\n",
    "    \"\"\"\n",
    "    y_true, y_pred, y_prob = [], [], []\n",
    "\n",
    "    model.eval()\n",
    "    # dtype của model (thường là float32)\n",
    "    model_dtype = next(model.parameters()).dtype\n",
    "\n",
    "    for x, y in loader:\n",
    "        # Đưa ảnh về đúng device + dtype của model\n",
    "        x = x.to(device=device, dtype=model_dtype)\n",
    "\n",
    "        # Remap nhãn nếu dataset idx khác class_names\n",
    "        if remap is not None:\n",
    "            # giữ y trên CPU vì chỉ dùng để so sánh/stack\n",
    "            y = torch.as_tensor([remap[int(t)] for t in y], dtype=torch.long)\n",
    "        else:\n",
    "            y = y.detach().to(\"cpu\", dtype=torch.long)\n",
    "\n",
    "        # Suy luận\n",
    "        logits = model(x)                      # logits có dtype == model_dtype\n",
    "        prob = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        pred = prob.argmax(1)\n",
    "\n",
    "        y_prob.append(prob)\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(y.numpy())\n",
    "\n",
    "    import numpy as np\n",
    "    return np.concatenate(y_true), np.concatenate(y_pred), np.concatenate(y_prob)\n",
    "\n",
    "\n",
    "def cm_pretty(cm_counts, labels):\n",
    "    cm = cm_counts.astype(float) / cm_counts.sum(axis=1, keepdims=True)\n",
    "    cm = np.nan_to_num(cm)\n",
    "    return cm\n",
    "\n",
    "def draw_cm(cm_counts, run_name, save_dir=\"images\", threshold=0.10, figsize=(12,10), dpi=200):\n",
    "    import matplotlib.pyplot as plt, seaborn as sns\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    cm = cm_pretty(cm_counts, class_names)\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    sns.heatmap(cm, vmin=0, vmax=1, cmap=\"Blues\", square=True,\n",
    "                xticklabels=class_names, yticklabels=class_names, ax=ax, cbar_kws={'shrink': .7})\n",
    "    # annotate: đường chéo + ô >= threshold\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            show = (i == j) or (cm[i,j] >= threshold)\n",
    "            if show and cm_counts[i,j] > 0:\n",
    "                ax.text(j+0.5, i+0.5, f\"{cm[i,j]*100:.0f}%\\n({cm_counts[i,j]})\",\n",
    "                        ha=\"center\", va=\"center\", fontsize=7, color=\"black\")\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "    ax.set_title(f\"Confusion Matrix (row-norm) – {run_name}\", pad=10)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=8)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(save_dir, f\"{run_name}_cm.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\"); plt.show()\n",
    "    print(\"✓ Lưu CM:\", out_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9d30448f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ test_loader & class_names sẵn sàng.\n"
     ]
    }
   ],
   "source": [
    "# QUICK CHECK trước khi vẽ\n",
    "try:\n",
    "    _ = iter(test_loader)\n",
    "    assert len(class_names) > 0\n",
    "    print(\"✅ test_loader & class_names sẵn sàng.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Lỗi:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "456a85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 4: PLOTS – CM & TOP CONFUSIONS ====\n",
    "import os, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "def plot_confusion(cm_counts, class_names, run_name, save_path, row_norm=True, threshold=0.10, dpi=300):\n",
    "    \"\"\"\n",
    "    cm_counts: ma trận đếm (chưa chuẩn hoá) kích thước [C, C]\n",
    "    row_norm : chuẩn hoá theo hàng (recall) để nhìn tỉ lệ đúng/sai từng lớp\n",
    "    threshold: chỉ annotate các ô >= threshold (ngoài đường chéo) để đỡ rối\n",
    "    \"\"\"\n",
    "    C = cm_counts.shape[0]\n",
    "    cm = cm_counts.astype(float)\n",
    "    if row_norm:\n",
    "        cm = cm / cm.sum(axis=1, keepdims=True)\n",
    "        cm = np.nan_to_num(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 10), dpi=200)\n",
    "    sns.heatmap(cm, vmin=0, vmax=1, cmap=\"Blues\", square=True,\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'shrink': .6}, ax=ax)\n",
    "\n",
    "    # annotate\n",
    "    for i in range(C):\n",
    "        for j in range(C):\n",
    "            show = (i == j) or (cm[i, j] >= threshold)\n",
    "            if show and cm_counts[i, j] > 0:\n",
    "                ax.text(j + 0.5, i + 0.5,\n",
    "                        f\"{cm[i,j]*100:.0f}%\\n({cm_counts[i,j]})\",\n",
    "                        ha=\"center\", va=\"center\", fontsize=7, color=\"black\")\n",
    "\n",
    "    ax.set_xlabel(\"Predicted\", fontsize=12)\n",
    "    ax.set_ylabel(\"True\", fontsize=12)\n",
    "    ax.set_title(f\"Confusion Matrix (row-norm) – {run_name}\", fontsize=14, pad=10)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=8)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_top_confusions(cm_counts, class_names, run_name, save_path, topk=15, dpi=300):\n",
    "    \"\"\"\n",
    "    Vẽ Top-K cặp dễ nhầm nhất (theo % hàng). Bỏ đường chéo.\n",
    "    \"\"\"\n",
    "    cm = cm_counts.astype(float)\n",
    "    cm = cm / cm.sum(axis=1, keepdims=True)\n",
    "    cm = np.nan_to_num(cm)\n",
    "\n",
    "    pairs = []\n",
    "    C = cm.shape[0]\n",
    "    for i in range(C):\n",
    "        for j in range(C):\n",
    "            if i == j: \n",
    "                continue\n",
    "            if cm_counts[i, j] == 0:\n",
    "                continue\n",
    "            pairs.append((i, j, cm[i, j], cm_counts[i, j]))\n",
    "\n",
    "    # sort theo tỷ lệ giảm dần\n",
    "    pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "    pairs = pairs[:topk]\n",
    "\n",
    "    if not pairs:\n",
    "        print(\"Không có cặp nhầm đáng kể.\")\n",
    "        return\n",
    "\n",
    "    labels = [f\"{class_names[i]} → {class_names[j]}\" for (i, j, _, _) in pairs]\n",
    "    perc   = [100 * p for (_, _, p, _) in pairs]\n",
    "    counts = [c for (_, _, _, c) in pairs]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 7), dpi=200)\n",
    "    ax.barh(labels, perc)\n",
    "    ax.invert_yaxis()\n",
    "    for k, (p, c) in enumerate(zip(perc, counts)):\n",
    "        ax.text(p + 0.3, k, f\"{p:.1f}% ({c})\", va=\"center\", fontsize=10)\n",
    "    ax.set_xlabel(\"Tỉ lệ nhầm (%)\")\n",
    "    ax.set_title(f\"Top-{len(pairs)} cặp dễ nhầm nhất – {run_name}\", fontsize=14, pad=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac57e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 5: EVALUATE ONE RUN ====\n",
    "import os, json, torch\n",
    "import numpy as np\n",
    "\n",
    "# Bạn có thể đổi để khớp folder thật của bạn\n",
    "RUNS_DIR = \"Runs\"   # mỗi thư mục con là 1 lần train, có file .mtl/.pt/.pth\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from model.mtl_cnn import mtl_cnn_v1\n",
    "from model.mobilenet_v4 import CustomMobileNetV4  # file bạn đã gửi\n",
    "from model.efficientnet_b0 import CustomEfficientNetB0\n",
    "\n",
    "def model_auto(run_name, num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    Suy đoán kiến trúc từ tên run. Bạn đang dùng tiền tố:\n",
    "    - 'mtl-cnn-...'\n",
    "    - 'mtl-mobilenetv4-...'\n",
    "    - 'mtl-efficientnetb0-...'\n",
    "    \"\"\"\n",
    "    name = run_name.lower()\n",
    "    if \"mobilenetv4\" in name:\n",
    "        return CustomMobileNetV4(num_classes=num_classes)\n",
    "    if \"efficientnetb0\" in name or \"efficientnet_b0\" in name:\n",
    "        return CustomEfficientNetB0(num_classes=num_classes)\n",
    "    # mặc định: CNN tự xây\n",
    "    return mtl_cnn_v1(num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# --- REPLACE this in Cell 5 ---\n",
    "from glob import glob\n",
    "import os, time\n",
    "\n",
    "EXTS = {\".mtl\", \".pt\", \".pth\"}\n",
    "\n",
    "def find_checkpoint(run_path: str):\n",
    "    \"\"\"\n",
    "    Tìm checkpoint trong run_path và các thư mục con phổ biến.\n",
    "    Ưu tiên file có 'best' trong tên; nếu không có, lấy file mới nhất.\n",
    "    \"\"\"\n",
    "    # các pattern hay gặp; ** để đảm bảo quét sâu\n",
    "    patterns = [\n",
    "        \"*\", \"checkpoints/*\", \"checkpoint/*\", \"ckpt*/*\",\n",
    "        \"models/*\", \"weights/*\", \"**/*\"\n",
    "    ]\n",
    "    cands = []\n",
    "    for pat in patterns:\n",
    "        for p in glob(os.path.join(run_path, pat), recursive=True):\n",
    "            if os.path.isfile(p) and os.path.splitext(p)[1].lower() in EXTS:\n",
    "                cands.append(p)\n",
    "\n",
    "    if not cands:\n",
    "        return None\n",
    "\n",
    "    # chấm điểm: có 'best' được +100, 'ema' +10, 'last' +5; sau đó ưu tiên mtime mới hơn\n",
    "    def score(p):\n",
    "        name = os.path.basename(p).lower()\n",
    "        s = 0\n",
    "        if \"best\" in name: s += 100\n",
    "        if \"ema\"  in name: s += 10\n",
    "        if \"last\" in name: s += 5\n",
    "        return (s, os.path.getmtime(p))\n",
    "\n",
    "    cands.sort(key=score, reverse=True)\n",
    "    chosen = cands[0]\n",
    "    print(f\"  ✓ checkpoint: {os.path.relpath(chosen, run_path)}\")\n",
    "    return chosen\n",
    "\n",
    "def load_checkpoint(run_path_or_name, ckpt_path, device):\n",
    "    \"\"\"\n",
    "    Tự động tạo model đúng loại dựa theo tên run hoặc object đã truyền vào.\n",
    "    Trả về model đã load trọng số, .to(device).eval()\n",
    "    \"\"\"\n",
    "    # 1️⃣ Nếu truyền vào là object model (vd: CustomMobileNet, CNN,...)\n",
    "    if not isinstance(run_path_or_name, (str, bytes, os.PathLike)):\n",
    "        model = run_path_or_name\n",
    "        run_name = model.__class__.__name__\n",
    "    else:\n",
    "        # 2️⃣ Nếu truyền vào là đường dẫn / tên run\n",
    "        run_name = os.path.basename(str(run_path_or_name).rstrip(os.sep))\n",
    "        model = build_model_auto(run_name)\n",
    "\n",
    "    # 3️⃣ Đưa model lên device\n",
    "    model = model.to(device).eval()\n",
    "\n",
    "    # 4️⃣ Load checkpoint đúng device\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "    # 5️⃣ Xử lý nhiều định dạng state_dict khác nhau\n",
    "    if isinstance(state, dict):\n",
    "        if \"state_dict\" in state:\n",
    "            sd = state[\"state_dict\"]\n",
    "        elif \"net\" in state:\n",
    "            sd = state[\"net\"]\n",
    "        elif \"classification_best\" in state:\n",
    "            sd = state[\"classification_best\"]\n",
    "        elif \"model\" in state and isinstance(state[\"model\"], dict):\n",
    "            sd = state[\"model\"]\n",
    "        else:\n",
    "            sd = state\n",
    "    else:\n",
    "        sd = state\n",
    "\n",
    "    # 6️⃣ Load vào model\n",
    "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "    if missing or unexpected:\n",
    "        print(f\"⚠️  load_state_dict warning → missing: {missing}, unexpected: {unexpected}\")\n",
    "\n",
    "    model = model.float().to(device).eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model_at(run_path, run_name):\n",
    "    # 1) loader cho TEST (dùng build_test_loader bạn đã viết, nhớ truyền batch_size)\n",
    "    test_loader = build_test_loader(root_test, test_transform, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # 2) Remap label nếu cần (dataset.class_to_idx -> class_names)\n",
    "    ds_idx2name = {v: k for k, v in test_loader.dataset.class_to_idx.items()}\n",
    "    name2idx = {n: i for i, n in enumerate(class_names)}\n",
    "    remap = {src_idx: name2idx[ds_idx2name[src_idx]] for src_idx in range(len(ds_idx2name))}\n",
    "\n",
    "    # 3) lấy checkpoint tốt nhất\n",
    "    ckpt_path = pick_checkpoint(run_path)  # bạn đã có\n",
    "\n",
    "    # 4) load model về đúng device + eval\n",
    "    model = load_checkpoint(run_path, ckpt_path, device)\n",
    "\n",
    "    # 5) thu logits/predicts\n",
    "    y_true, y_pred, y_prob = collect_logits(model, test_loader, device, remap=remap)\n",
    "\n",
    "    # 6) tính các chỉ số và vẽ hình (bạn đã có code sẵn)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    # … (vẽ confusion matrix, top-confusions, lưu ảnh …)\n",
    "    return {\"run\": run_name, \"acc\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c8b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️  Đánh giá: mtl-cnn-20251029-201543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_31584\\3301479262.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(ckpt_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==== CELL 6: EVALUATE ALL RUNS & RANKING (robust loader tuple) ====\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "RUNS_DIR   = \"Runs\"\n",
    "IMAGES_DIR = \"images\"\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# Dùng lại class_names đã nạp ở cell trước; nếu chưa có thì thử đọc file dự phòng\n",
    "if \"class_names\" not in globals():\n",
    "    # nếu bạn đã có file class_names.json dưới ROOT thì mở ra\n",
    "    fallback_json = os.path.join(ROOT, \"class_names.json\")\n",
    "    if os.path.isfile(fallback_json):\n",
    "        class_names = json.load(open(fallback_json, \"r\", encoding=\"utf-8\"))\n",
    "    else:\n",
    "        raise RuntimeError(\"Bạn chưa nạp class_names. Hãy chạy cell nạp class_names hoặc cung cấp file class_names.json.\")\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "\n",
    "# Cache để Cell ROC nhiều model\n",
    "if \"ROC_CACHE\" not in globals():\n",
    "    ROC_CACHE = []\n",
    "\n",
    "def load_run_config(run_path, default_img=224, default_bs=64):\n",
    "    cfg_path = os.path.join(run_path, \"config.json\")\n",
    "    img, bs = default_img, default_bs\n",
    "    if os.path.isfile(cfg_path):\n",
    "        try:\n",
    "            cfg = json.load(open(cfg_path, \"r\", encoding=\"utf-8\"))\n",
    "            img = int(cfg.get(\"img_size\", cfg.get(\"IMG_SIZE\", img)))\n",
    "            bs  = int(cfg.get(\"batch_size\", cfg.get(\"BATCH_SIZE\", bs)))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return img, bs\n",
    "\n",
    "def create_test_transform(img_size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "def pick_checkpoint(run_path):\n",
    "    ckpt_dir = os.path.join(run_path, \"checkpoints\")\n",
    "    cands = []\n",
    "    for d in [ckpt_dir, run_path]:\n",
    "        if not os.path.isdir(d): \n",
    "            continue\n",
    "        for fn in os.listdir(d):\n",
    "            if fn.lower().endswith((\".mtl\", \".pt\", \".pth\")):\n",
    "                cands.append(os.path.join(d, fn))\n",
    "    if not cands: \n",
    "        return None\n",
    "    mtls = [p for p in cands if p.lower().endswith(\".mtl\")]\n",
    "    return sorted(mtls or cands, key=os.path.getmtime)[-1]\n",
    "\n",
    "def normalize_loader_tuple(loader_out):\n",
    "    \"\"\"\n",
    "    Trả về: (test_loader, ds_class_to_idx)\n",
    "    - Chấp nhận build_test_loader trả về DataLoader hoặc tuple (loader, class_to_idx) / (loader, idx2name)...\n",
    "    \"\"\"\n",
    "    ds_class_to_idx = None\n",
    "    if isinstance(loader_out, tuple):\n",
    "        # phần tử đầu chắc chắn là loader\n",
    "        test_loader = loader_out[0]\n",
    "        # cố tìm dict ánh xạ lớp trong các phần tử còn lại\n",
    "        for item in loader_out[1:]:\n",
    "            if isinstance(item, dict):\n",
    "                # nếu là class_to_idx: key là tên lớp (str), value là int\n",
    "                if all(isinstance(k, str) for k in item.keys()) and all(isinstance(v, int) for v in item.values()):\n",
    "                    ds_class_to_idx = item\n",
    "                    break\n",
    "                # nếu là idx2name: key int, value str -> đảo lại\n",
    "                if all(isinstance(k, int) for k in item.keys()) and all(isinstance(v, str) for v in item.values()):\n",
    "                    ds_class_to_idx = {v: k for k, v in item.items()}\n",
    "                    break\n",
    "    else:\n",
    "        test_loader = loader_out\n",
    "\n",
    "    # fallback lấy từ dataset\n",
    "    if ds_class_to_idx is None:\n",
    "        ds_class_to_idx = getattr(getattr(test_loader, \"dataset\", object()), \"class_to_idx\", {})\n",
    "        if not isinstance(ds_class_to_idx, dict):\n",
    "            ds_class_to_idx = {}\n",
    "\n",
    "    return test_loader, ds_class_to_idx\n",
    "\n",
    "def evaluate_model_at(run_path, run_name):\n",
    "    # 1) đọc config\n",
    "    img_size, bs = load_run_config(run_path, default_img=224, default_bs=64)\n",
    "    test_transform = create_test_transform(img_size)\n",
    "\n",
    "    # 2) build loader (có thể trả về tuple)\n",
    "    loader_out = build_test_loader(root_test, test_transform, batch_size=bs)\n",
    "    test_loader, ds_class_to_idx = normalize_loader_tuple(loader_out)\n",
    "\n",
    "    # 3) remap nhãn nếu thứ tự dataset khác class_names chuẩn\n",
    "    name2idx = {n: i for i, n in enumerate(class_names)}\n",
    "    remap = make_remap(ds_class_to_idx, name2idx) if 'make_remap' in globals() else None\n",
    "\n",
    "    # 4) load checkpoint + model\n",
    "    ckpt_path = pick_checkpoint(run_path)\n",
    "    if ckpt_path is None:\n",
    "        print(f\"  ⚠ {run_name}: không tìm thấy checkpoint (.mtl/.pt/.pth) ⇒ bỏ qua.\")\n",
    "        return None\n",
    "    model = model_auto(run_name)\n",
    "\n",
    "    model = load_checkpoint(run_name, ckpt_path, device)\n",
    "\n",
    "    # 5) dự đoán\n",
    "    y_true, y_pred, y_prob = collect_logits(model, test_loader, device, remap=remap)\n",
    "\n",
    "    # 6) metrics\n",
    "    acc = float(accuracy_score(y_true, y_pred))\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # 7) cache cho ROC đa mô hình\n",
    "    ROC_CACHE.append({\n",
    "        \"name\": run_name,\n",
    "        \"y_true\": np.asarray(y_true),\n",
    "        \"y_prob\": np.asarray(y_prob),\n",
    "        \"class_names\": class_names,\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"run\": run_name, \"acc\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1,\n",
    "        \"img_size\": img_size, \"batch_size\": bs, \"ckpt\": os.path.basename(ckpt_path)\n",
    "    }\n",
    "\n",
    "# ==== quét & đánh giá tất cả runs ====\n",
    "results = []\n",
    "if not os.path.isdir(RUNS_DIR):\n",
    "    print(f\"⚠ Thư mục {RUNS_DIR} không tồn tại.\")\n",
    "else:\n",
    "    for run_name in sorted(os.listdir(RUNS_DIR)):\n",
    "        run_path = os.path.join(RUNS_DIR, run_name)\n",
    "        if not os.path.isdir(run_path):\n",
    "            continue\n",
    "        print(f\"▶️  Đánh giá: {run_name}\")\n",
    "        res = evaluate_model_at(run_path, run_name)\n",
    "        if res:\n",
    "            results.append(res)\n",
    "\n",
    "# ==== bảng xếp hạng & lưu thành ảnh ====\n",
    "if results:\n",
    "    df = pd.DataFrame(results).sort_values(\"acc\", ascending=False)\n",
    "    display(df)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 0.45*len(df)+1), dpi=220)\n",
    "    ax.axis(\"off\")\n",
    "    tbl = ax.table(cellText=df.values, colLabels=df.columns, loc=\"center\", cellLoc=\"center\")\n",
    "    tbl.auto_set_font_size(False); tbl.set_fontsize(9); tbl.scale(1, 1.25)\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(IMAGES_DIR, \"summary_models.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"✅ Lưu: {out_png}\")\n",
    "else:\n",
    "    print(\"⚠ Không có run hợp lệ trong thư mục Runs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba726ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 7 (REPLACE): Vẽ Loss/Accuracy CHO TẤT CẢ CÁC RUNS ====\n",
    "import os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RUNS_DIR = \"Runs\"          # giữ đúng đường dẫn bạn đang dùng\n",
    "IMAGES_DIR = \"images\"\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "def pick_col(df, pats):\n",
    "    \"\"\"Chọn cột đầu tiên khớp pattern (không phân biệt hoa/thường).\"\"\"\n",
    "    pats = [p.lower() for p in pats]\n",
    "    for c in df.columns:\n",
    "        cl = c.lower()\n",
    "        if any(re.search(p, cl) for p in pats):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def plot_history_for_run(run_path, run_name):\n",
    "    # 1) tìm file log hợp lệ\n",
    "    for cand in [\"history.csv\", \"history.json\", \"train_log.csv\", \"metrics.csv\"]:\n",
    "        hp = os.path.join(run_path, cand)\n",
    "        if os.path.isfile(hp):\n",
    "            hist_path = hp\n",
    "            break\n",
    "    else:\n",
    "        print(f\"[-] {run_name}: không thấy history.(csv|json)\")\n",
    "        return\n",
    "\n",
    "    # 2) đọc log và chuẩn hoá cột\n",
    "    if hist_path.endswith(\".json\"):\n",
    "        df = pd.read_json(hist_path)\n",
    "    else:\n",
    "        df = pd.read_csv(hist_path)\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    # 3) epoch thực tế trong file; nếu không có cột epoch thì mặc định 1..len\n",
    "    c_epoch = pick_col(df, [r\"^epoch$\", r\"^epochs?$\"])\n",
    "    epoch = df[c_epoch].to_numpy() if c_epoch else np.arange(1, len(df)+1)\n",
    "\n",
    "    # 4) bắt các cột loss/acc “mềm”\n",
    "    c_tr_loss = pick_col(df, [r\"^loss$\", r\"train.*loss\"])\n",
    "    c_va_loss = pick_col(df, [r\"val.*loss\", r\"valid.*loss\"])\n",
    "    c_tr_acc  = pick_col(df, [r\"^acc$\", r\"accuracy$\", r\"train.*acc\", r\"train.*accuracy\"])\n",
    "    c_va_acc  = pick_col(df, [r\"val.*acc\", r\"val.*accuracy\", r\"valid.*acc\", r\"valid.*accuracy\"])\n",
    "\n",
    "    tr_loss = df[c_tr_loss].to_numpy() if c_tr_loss else None\n",
    "    va_loss = df[c_va_loss].to_numpy() if c_va_loss else None\n",
    "    tr_acc  = df[c_tr_acc].to_numpy()  if c_tr_acc  else None\n",
    "    va_acc  = df[c_va_acc].to_numpy()  if c_va_acc  else None\n",
    "\n",
    "    # 5) epoch tốt nhất để annotate\n",
    "    best_ep, note = None, \"\"\n",
    "    if va_acc is not None and len(va_acc) > 0:\n",
    "        best_ep = int(epoch[np.nanargmax(va_acc)])\n",
    "        note = f\"best val_acc@{best_ep}={np.nanmax(va_acc):.3f}\"\n",
    "    elif va_loss is not None and len(va_loss) > 0:\n",
    "        best_ep = int(epoch[np.nanargmin(va_loss)])\n",
    "        note = f\"best val_loss@{best_ep}={np.nanmin(va_loss):.3f}\"\n",
    "\n",
    "    # 6) vẽ 2 subplot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5), dpi=160)\n",
    "\n",
    "    # Loss\n",
    "    if tr_loss is not None: ax[0].plot(epoch, tr_loss, label=\"Train loss\")\n",
    "    if va_loss is not None: ax[0].plot(epoch, va_loss, label=\"Val loss\")\n",
    "    if best_ep is not None: ax[0].axvline(best_ep, ls=\"--\", lw=1, c=\"gray\")\n",
    "    ax[0].set_title(f\"{run_name} – Loss\")\n",
    "    ax[0].set_xlabel(\"Epoch\"); ax[0].set_ylabel(\"Loss\"); ax[0].legend()\n",
    "\n",
    "    # Accuracy\n",
    "    if tr_acc is not None: ax[1].plot(epoch, tr_acc, label=\"Train acc\")\n",
    "    if va_acc is not None: ax[1].plot(epoch, va_acc, label=\"Val acc\")\n",
    "    if best_ep is not None:\n",
    "        ax[1].axvline(best_ep, ls=\"--\", lw=1, c=\"gray\", label=note if va_acc is not None else None)\n",
    "    ax[1].set_title(f\"{run_name} – Accuracy\")\n",
    "    ax[1].set_xlabel(\"Epoch\"); ax[1].set_ylabel(\"Accuracy\"); ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(IMAGES_DIR, f\"{run_name}_history.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"✓ Đã lưu: {out_png}\")\n",
    "\n",
    "# 🔁 DUYỆT HẾT TẤT CẢ RUNS và vẽ\n",
    "if not os.path.isdir(RUNS_DIR):\n",
    "    print(f\"Thư mục '{RUNS_DIR}' không tồn tại.\")\n",
    "else:\n",
    "    for run_name in sorted(os.listdir(RUNS_DIR)):\n",
    "        run_path = os.path.join(RUNS_DIR, run_name)\n",
    "        if not os.path.isdir(run_path):\n",
    "            continue\n",
    "        print(f\"→ Vẽ lịch sử: {run_name}\")\n",
    "        plot_history_for_run(run_path, run_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035f740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 8A: PHÂN TÍCH MÔ HÌNH CHUYÊN SÂU ====\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "IMAGES_DIR = \"images\"\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# Đảm bảo có class_names và test_loader (đã build ở Cell 3)\n",
    "assert \"class_names\" in globals(), \"⚠️ Cần nạp class_names trước Cell 8!\"\n",
    "assert \"test_loader\" in globals(), \"⚠️ Cần build test_loader trước Cell 8!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8B: Biểu đồ ROC Curve & AUC (multi-class, one-vs-rest)\n",
    "def plot_roc_auc_for_model(run_name, y_true, y_prob, class_names):\n",
    "    \"\"\"\n",
    "    Vẽ ROC & tính AUC trung bình cho mô hình đa lớp.\n",
    "    y_true:  nhãn thật (int)\n",
    "    y_prob:  xác suất softmax [N, num_classes]\n",
    "    \"\"\"\n",
    "    n_classes = len(class_names)\n",
    "    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
    "\n",
    "    # ROC & AUC từng lớp\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # AUC trung bình\n",
    "    macro_auc = roc_auc_score(y_true_bin, y_prob, average=\"macro\")\n",
    "    print(f\"→ {run_name}: macro AUC = {macro_auc:.4f}\")\n",
    "\n",
    "    # Vẽ 5 lớp đầu để tránh rối\n",
    "    plt.figure(figsize=(7, 6), dpi=140)\n",
    "    for i, cname in enumerate(class_names[:5]):\n",
    "        plt.plot(fpr[i], tpr[i], label=f\"{cname} (AUC = {roc_auc[i]:.3f})\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n",
    "    plt.title(f\"ROC Curves – {run_name}\\nMacro AUC = {macro_auc:.3f}\")\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(fontsize=8); plt.tight_layout()\n",
    "    out_png = os.path.join(IMAGES_DIR, f\"{run_name}_roc_auc.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"✓ Đã lưu:\", out_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (C) Tốc độ & hiệu năng Inferencing\n",
    "import time\n",
    "\n",
    "def benchmark_model(model, device, input_size=(1, 3, 224, 224), repeat=30):\n",
    "    \"\"\"\n",
    "    Đo thời gian infer (Forward pass) và ước tính FPS trên batch 1.\n",
    "    \"\"\"\n",
    "    x = torch.randn(input_size).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # warm-up\n",
    "        for _ in range(5):\n",
    "            _ = model(x)\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        t0 = time.time()\n",
    "        for _ in range(repeat):\n",
    "            _ = model(x)\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        t1 = time.time()\n",
    "\n",
    "    avg = (t1 - t0) / repeat\n",
    "    fps = 1 / avg\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"⏱️ {model.__class__.__name__}: {avg*1000:.2f} ms/infer ({fps:.1f} FPS) | Params ≈ {params/1e6:.2f} M\")\n",
    "    return avg, fps, params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14749bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 9: ẢNH TEST BỊ NHẦM NHIỀU NHẤT (Top Confused Pairs) ====\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "IMAGES_DIR = \"images\"\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "def show_top_confused_pairs(model, test_loader, class_names, run_name, device, top_k=6):\n",
    "    \"\"\"\n",
    "    Hiển thị top K cặp lớp mà model nhầm lẫn nhiều nhất (dựa trên confusion matrix)\n",
    "    + Kèm ảnh ví dụ thật bị nhầm.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true, y_pred, paths = [], [], []\n",
    "\n",
    "    # 🔹 B1: Thu nhãn thật, dự đoán, và đường dẫn ảnh\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            outputs = model(x)\n",
    "            preds = outputs.argmax(1).cpu().numpy()\n",
    "            y_true.extend(y.numpy())\n",
    "            y_pred.extend(preds)\n",
    "\n",
    "            # Nếu dataset có thuộc tính filepaths / samples\n",
    "            if hasattr(test_loader.dataset, \"samples\"):\n",
    "                paths.extend([s[0] for s in test_loader.dataset.samples[len(paths):len(paths)+len(y)]])\n",
    "            elif hasattr(test_loader.dataset, \"imgs\"):\n",
    "                paths.extend([s[0] for s in test_loader.dataset.imgs[len(paths):len(paths)+len(y)]])\n",
    "            else:\n",
    "                paths.extend([\"(Không có đường dẫn)\"] * len(y))\n",
    "\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize=\"true\")\n",
    "    cm_counts = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # 🔹 B2: Xác định các cặp bị nhầm nhiều nhất (không lấy đường chéo)\n",
    "    pairs = []\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            if i != j and cm[i, j] > 0:\n",
    "                pairs.append((i, j, cm[i, j], cm_counts[i, j]))\n",
    "    top_pairs = sorted(pairs, key=lambda x: x[2], reverse=True)[:top_k]\n",
    "\n",
    "    # 🔹 B3: Hiển thị từng cặp kèm ảnh minh họa\n",
    "    fig, axes = plt.subplots(len(top_pairs), 2, figsize=(7, 3 * len(top_pairs)))\n",
    "    fig.suptitle(f\"Ảnh test thực sự bị model nhầm (Top confused pairs) – {run_name}\",\n",
    "                 fontsize=14, fontweight=\"bold\", y=0.995)\n",
    "\n",
    "    for idx, (i, j, rate, count) in enumerate(top_pairs):\n",
    "        # Tìm ảnh ví dụ bị nhầm này\n",
    "        candidates = np.where((y_true == i) & (y_pred == j))[0]\n",
    "        img_path = paths[candidates[0]] if len(candidates) > 0 else None\n",
    "\n",
    "        # Cột 1: ảnh minh họa\n",
    "        ax_img, ax_text = axes[idx]\n",
    "        ax_img.axis(\"off\")\n",
    "        if img_path and os.path.exists(img_path):\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            ax_img.imshow(img)\n",
    "        else:\n",
    "            ax_img.text(0.5, 0.5, \"Không có ảnh\", ha=\"center\", va=\"center\", fontsize=10)\n",
    "\n",
    "        # Cột 2: thông tin nhầm lẫn\n",
    "        ax_text.axis(\"off\")\n",
    "        text = (\n",
    "            f\"Ảnh bị nhầm: {class_names[i]} → {class_names[j]}\\n\\n\"\n",
    "            f\"Tỉ lệ nhầm (CM): {rate*100:.2f}% ({count} mẫu)\\n\"\n",
    "            f\"True: {class_names[i]}\\nPred: {class_names[j]}\"\n",
    "        )\n",
    "        ax_text.text(0, 0.5, text, va=\"center\", fontsize=11)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(IMAGES_DIR, f\"{run_name}_top_confused_pairs.png\")\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"✓ Đã lưu: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử bạn đã có results [] từ Cell 6 – chứa tên mỗi run\n",
    "for r in results:\n",
    "    run_name = r[\"run\"]\n",
    "    run_path = os.path.join(\"Runs\", run_name)\n",
    "    ckpt = pick_checkpoint(run_path)\n",
    "    model = load_checkpoint(run_name, ckpt, device)\n",
    "    print(f\"\\n=== ĐÁNH GIÁ MÔ HÌNH {run_name} ===\")\n",
    "\n",
    "    # 1️⃣ Inference & thu logits\n",
    "    y_true, y_pred, y_prob = collect_logits(model, test_loader, device)\n",
    "\n",
    "    # 2️⃣ Vẽ ROC & AUC\n",
    "    plot_roc_auc_for_model(run_name, y_true, y_prob, class_names)\n",
    "\n",
    "\n",
    "    # Visualize “Top Confused Pairs” (Ảnh bị nhầm nhiều nhất)\n",
    "    show_top_confused_pairs(model, test_loader, class_names, run_name, device, top_k=6)\n",
    "\n",
    "    # 4️⃣ Benchmark tốc độ\n",
    "    benchmark_model(model, device, (1, 3, 224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f00a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
