{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f622d5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CELL 0 — Imports & Config\n",
    "# =========================\n",
    "import os, re, json, math, time, random, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# ---- Paths (chỉnh lại nếu khác) ----\n",
    "RUNS_DIR   = \"runs\"          # thư mục cha chứa các run đã train\n",
    "IMAGES_DIR = \"images\"        # nơi lưu hình xuất ra\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# ---- Dataloader/test config (được cell khác dùng) ----\n",
    "INPUT_SIZE  = 224            # cỡ ảnh (HxW) mà model dùng lúc train\n",
    "BATCH_SIZE  = 32             # batch size khi evaluate (tùy GPU)\n",
    "\n",
    "# ---- Device ----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---- Seed (tùy chọn) ----\n",
    "def set_seed(seed=1337):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(1337)\n",
    "\n",
    "# ===========================================\n",
    "# Tiện ích: checkpoint, model, thống kê, v.v.\n",
    "# ===========================================\n",
    "def pick_checkpoint(run_path: str):\n",
    "    \"\"\"\n",
    "    Trả về đường dẫn checkpoint 'đẹp nhất' trong run:\n",
    "    ưu tiên: best.* > last.* > *.mtl/*.pt/*.pth ở thư mục checkpoints/\n",
    "    \"\"\"\n",
    "    ckpt_dir = os.path.join(run_path, \"checkpoints\")\n",
    "    if not os.path.isdir(ckpt_dir):\n",
    "        # fallback: tìm ngay trong run_path\n",
    "        ckpts = sorted(\n",
    "            [p for p in glob.glob(os.path.join(run_path, \"*\")) if p.endswith((\".mtl\",\".pt\",\".pth\",\".bin\",\".pth.tar\",\".ckpt\"))]\n",
    "        )\n",
    "        return ckpts[-1] if ckpts else None\n",
    "\n",
    "    # ưu tiên best -> last -> còn lại\n",
    "    patterns = [\"best.*\", \"last.*\", \"*.mtl\", \"*.pt\", \"*.pth\", \"*.bin\", \"*.pth.tar\", \"*.ckpt\"]\n",
    "    for pat in patterns:\n",
    "        found = sorted(glob.glob(os.path.join(ckpt_dir, pat)))\n",
    "        if found:\n",
    "            return found[-1]\n",
    "    return None\n",
    "\n",
    "\n",
    "def _strip_module_prefix(state_dict: dict):\n",
    "    \"\"\"Bỏ prefix 'module.' nếu tồn tại (trong trường hợp DDP).\"\"\"\n",
    "    new_sd = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith(\"module.\"): k = k[len(\"module.\"):]\n",
    "        new_sd[k] = v\n",
    "    return new_sd\n",
    "\n",
    "\n",
    "def load_checkpoint_to_model(model: nn.Module, ckpt_path: str, device):\n",
    "    \"\"\"\n",
    "    map mọi biến thể checkpoint về state_dict tiêu chuẩn:\n",
    "    - {'state_dict': ...} hoặc {'model': ...} hoặc chính state_dict\n",
    "    \"\"\"\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "    if isinstance(state, dict) and \"state_dict\" in state:\n",
    "        sd = state[\"state_dict\"]\n",
    "    elif isinstance(state, dict) and \"model\" in state:\n",
    "        sd = state[\"model\"]\n",
    "    elif isinstance(state, dict):\n",
    "        sd = state\n",
    "    else:\n",
    "        raise RuntimeError(\"Không nhận diện được định dạng checkpoint.\")\n",
    "\n",
    "    sd = _strip_module_prefix(sd)\n",
    "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "    if missing:   print(\"[ckpt] Missing keys:\", list(missing)[:5], \"...\")\n",
    "    if unexpected:print(\"[ckpt] Unexpected keys:\", list(unexpected)[:5], \"...\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def count_params(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "def file_size_mb(path: str):\n",
    "    try:\n",
    "        return os.path.getsize(path) / (1024*1024)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# Auto build model theo tên run (mô-đun bạn có)\n",
    "# ===========================================\n",
    "def build_model_auto(run_name: str, num_classes: int):\n",
    "    \"\"\"\n",
    "    Suy ra kiến trúc theo tên run & gọi module tương ứng:\n",
    "    - 'mobilenetv4'  -> mobilenet_v4.build_model(num_classes)\n",
    "    - 'efficientnet' -> efficientnet_b0.build_model(num_classes)\n",
    "    - 'cnn'          -> mtl_cnn.build_model(num_classes)\n",
    "    Nếu không match, thử lần lượt 3 module; cuối cùng raise lỗi.\n",
    "    \"\"\"\n",
    "    lname = run_name.lower()\n",
    "\n",
    "    tried = []\n",
    "    def _try(build_module_name):\n",
    "        tried.append(build_module_name)\n",
    "        mod = __import__(build_module_name, fromlist=['*'])\n",
    "        if hasattr(mod, \"build_model\"):\n",
    "            return mod.build_model(num_classes=num_classes)\n",
    "        # fallback tên hàm khác (nếu bạn đặt khác)\n",
    "        for cand in [\"get_model\", \"create_model\", \"make_model\"]:\n",
    "            if hasattr(mod, cand):\n",
    "                return getattr(mod, cand)(num_classes=num_classes)\n",
    "        raise AttributeError(f\"Module {build_module_name} không có build_model/get_model/...\")\n",
    "\n",
    "    # đoán theo tên\n",
    "    try:\n",
    "        if \"model.mobilenet_v4\" in lname or \"mobile\" in lname:\n",
    "            return _try(\"mobilenet_v4\")\n",
    "        if \"model.efficientnet_b0\" in lname or \"b0\" in lname:\n",
    "            return _try(\"CustomEfficientNetB0\")\n",
    "        if \"model.mtl_cnn\" in lname:\n",
    "            return _try(\"mtl_cnn\")\n",
    "    except Exception as e:\n",
    "        print(\"[auto_model] đoán theo tên thất bại:\", e)\n",
    "\n",
    "    # thử lần lượt\n",
    "    for m in [\"mobilenet_v4\", \"efficientnet_b0\", \"mtl_cnn\"]:\n",
    "        try:\n",
    "            return _try(m)\n",
    "        except Exception as e:\n",
    "            print(f\"[auto_model] thử {m} lỗi:\", e)\n",
    "\n",
    "    raise RuntimeError(f\"Không build được model cho run '{run_name}'. Đã thử: {tried}\")\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# FIX Confusion Matrix: class_names theo RUN & remap\n",
    "# ===================================================\n",
    "def load_class_names_for_run(run_path: str):\n",
    "    \"\"\"\n",
    "    Lấy class_names đúng thứ tự lúc TRAIN của run này.\n",
    "    Ưu tiên:\n",
    "      1) runs/<run>/config.json (keys: 'class_names' | 'idx_to_class' | 'classes')\n",
    "      2) runs/<run>/label.txt (mỗi dòng 1 lớp)\n",
    "      3) label.txt(labels.txt) ở project root (fallback)\n",
    "    \"\"\"\n",
    "    # 1) config.json trong run\n",
    "    cfg_path = os.path.join(run_path, \"config.json\")\n",
    "    if os.path.isfile(cfg_path):\n",
    "        try:\n",
    "            with open(cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                cfg = json.load(f)\n",
    "            for key in [\"class_names\", \"idx_to_class\", \"classes\"]:\n",
    "                if key in cfg and cfg[key]:\n",
    "                    arr = cfg[key]\n",
    "                    # nếu là dict idx->name thì sort theo idx\n",
    "                    if isinstance(arr, dict):\n",
    "                        try:\n",
    "                            arr = [arr[str(i)] if str(i) in arr else arr[i] for i in sorted(map(int, arr.keys()))]\n",
    "                        except Exception:\n",
    "                            # có thể là name->idx, đảo lại\n",
    "                            name2idx = arr\n",
    "                            inv = [None]*len(name2idx)\n",
    "                            for name, idx in name2idx.items():\n",
    "                                inv[int(idx)] = name\n",
    "                            arr = inv\n",
    "                    return list(arr)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 2) label.txt trong run\n",
    "    for f in [\"label.txt\", \"labels.txt\"]:\n",
    "        p = os.path.join(run_path, f)\n",
    "        if os.path.isfile(p):\n",
    "            with open(p, \"r\", encoding=\"utf-8\") as g:\n",
    "                return [line.strip() for line in g if line.strip()]\n",
    "\n",
    "    # 3) fallback ở project root\n",
    "    for f in [\"label.txt\", \"labels.txt\"]:\n",
    "        if os.path.isfile(f):\n",
    "            with open(f, \"r\", encoding=\"utf-8\") as g:\n",
    "                return [line.strip() for line in g if line.strip()]\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_remap_from_loader_to_run(loader, run_class_names):\n",
    "    \"\"\"\n",
    "    Tạo ánh xạ chỉ số từ dataset.test (loader.dataset.class_to_idx)\n",
    "    -> index theo run_class_names (đúng thứ tự train).\n",
    "    \"\"\"\n",
    "    if not hasattr(loader.dataset, \"class_to_idx\"):\n",
    "        return None\n",
    "    ds_map = loader.dataset.class_to_idx               # {'Pho': 0, ...} (theo alphabet ImageFolder)\n",
    "    run_name2idx = {n: i for i, n in enumerate(run_class_names)}\n",
    "    remap = {}\n",
    "    for name, src_idx in ds_map.items():\n",
    "        if name in run_name2idx:\n",
    "            remap[src_idx] = run_name2idx[name]\n",
    "    # chỉ chấp nhận nếu mapping đủ “dày”\n",
    "    return remap if len(remap) >= max(1, int(0.6 * len(run_class_names))) else None\n",
    "\n",
    "\n",
    "def apply_remap_array(y: np.ndarray, remap: dict | None):\n",
    "    \"\"\"Remap mảng nhãn theo dict ánh xạ (nếu có).\"\"\"\n",
    "    if remap is None:\n",
    "        return y\n",
    "    return np.array([remap.get(int(t), int(t)) for t in y])\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# (tùy chọn) trích đường dẫn ảnh thật từ DataLoader\n",
    "# ===================================================\n",
    "def extract_paths_from_loader(loader):\n",
    "    \"\"\"\n",
    "    Cố gắng lấy list đường dẫn file từ loader.dataset:\n",
    "    - Với ImageFolder-like: loader.dataset.samples -> [(path, idx), ...]\n",
    "    - Hoặc loader.dataset.imgs\n",
    "    Trả về list[str] hoặc None.\n",
    "    \"\"\"\n",
    "    ds = loader.dataset\n",
    "    if hasattr(ds, \"samples\") and isinstance(ds.samples, list):\n",
    "        return [p for p, _ in ds.samples]\n",
    "    if hasattr(ds, \"imgs\") and isinstance(ds.imgs, list):\n",
    "        return [p for p, _ in ds.imgs]\n",
    "    # cuối cùng trả None (cell phân tích lỗi sẽ tự bỏ qua nếu None)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4eecb416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 1: ROC Curve (OvR) & Macro AUC ====\n",
    "def plot_roc_ovr(y_true, y_prob, class_names, run_label, max_curves=5, out_dir=IMAGES_DIR):\n",
    "    C = len(class_names)\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(C))\n",
    "    fprs, tprs, aucs = [], [], []\n",
    "    for c in range(C):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, c], y_prob[:, c])\n",
    "        fprs.append(fpr); tprs.append(tpr); aucs.append(auc(fpr, tpr))\n",
    "    macro_auc = float(np.mean(aucs))\n",
    "    idx = np.argsort(aucs)[::-1][:max_curves]\n",
    "\n",
    "    plt.figure(figsize=(7.5,6.5), dpi=160)\n",
    "    for i in idx:\n",
    "        plt.plot(fprs[i], tprs[i], lw=2, label=f\"{class_names[i]} (AUC={aucs[i]:.3f})\")\n",
    "    plt.plot([0,1],[0,1],'k--', lw=1, label=\"Random\")\n",
    "    plt.xlim(0,1); plt.ylim(0,1.02)\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curves – {run_label}\\nMacro AUC = {macro_auc:.3f}\")\n",
    "    plt.legend(loc=\"lower right\", fontsize=9, frameon=True)\n",
    "    out_png = os.path.join(out_dir, f\"{run_label}_roc.png\")\n",
    "    plt.tight_layout(); plt.savefig(out_png, dpi=300, bbox_inches=\"tight\"); plt.show()\n",
    "    print(\"✓ Saved:\", out_png)\n",
    "    return macro_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1c8c6059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 2: Tốc độ & tài nguyên ====\n",
    "@torch.no_grad()\n",
    "def benchmark_model(model, device, input_size=(1,3,224,224), repeat=50, warmup=10):\n",
    "    model.eval().to(device)\n",
    "    x = torch.randn(*input_size, device=device)\n",
    "    for _ in range(warmup):\n",
    "        _ = model(x)\n",
    "    if device.type == \"cuda\": torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    for _ in range(repeat):\n",
    "        _ = model(x)\n",
    "    if device.type == \"cuda\": torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    avg = (t1 - t0) / repeat\n",
    "    return {\n",
    "        \"ms_per_img\": avg*1000.0,\n",
    "        \"FPS\": 1.0/avg if avg>0 else float(\"inf\")\n",
    "    }\n",
    "\n",
    "def plot_speed_table(rows, title=\"Speed & Resource\", out_png=os.path.join(IMAGES_DIR, \"speed_summary.png\")):\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(rows).sort_values(\"FPS\", ascending=False)\n",
    "    display(df)\n",
    "    fig, ax = plt.subplots(figsize=(10, 0.6 + 0.45*len(df)), dpi=180)\n",
    "    ax.axis(\"off\")\n",
    "    tbl = ax.table(\n",
    "        cellText=df[[\"run\",\"FPS\",\"ms_per_img\",\"params(M)\",\"size(MB)\"]]\n",
    "                .assign(FPS=lambda d: d[\"FPS\"].map(lambda x: f\"{x:.1f}\"),\n",
    "                        **{\"ms_per_img\":lambda d: d[\"ms_per_img\"].map(lambda x: f\"{x:.2f}\")})\n",
    "                .values,\n",
    "        colLabels=[\"Model\",\"FPS (↑)\",\"ms/img (↓)\",\"Params\",\"Size\"],\n",
    "        loc=\"center\", cellLoc=\"center\"\n",
    "    )\n",
    "    tbl.auto_set_font_size(False); tbl.set_fontsize(9); tbl.scale(1,1.1)\n",
    "    plt.title(title); plt.tight_layout(); plt.savefig(out_png, dpi=300, bbox_inches=\"tight\"); plt.show()\n",
    "    print(\"✓ Saved:\", out_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fea08e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 3: Biểu đồ Loss/Accuracy theo epoch từ history.* ====\n",
    "import pandas as pd\n",
    "\n",
    "def _pick_history_path(run_path):\n",
    "    for f in [\"history.csv\", \"train_log.csv\", \"metrics.csv\", \"history.json\"]:\n",
    "        p = os.path.join(run_path, f)\n",
    "        if os.path.isfile(p): return p\n",
    "    return None\n",
    "\n",
    "def _pick_col(df, pats):\n",
    "    pats = [p.lower() for p in pats]\n",
    "    for c in df.columns:\n",
    "        cl = c.lower().strip()\n",
    "        if any(re.search(p, cl) for p in pats):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def plot_history_from_run(run_path, run_label):\n",
    "    hist = _pick_history_path(run_path)\n",
    "    if hist is None:\n",
    "        print(f\"[{run_label}] Không tìm thấy history.csv/json.\")\n",
    "        return None\n",
    "    df = pd.read_json(hist) if hist.endswith(\".json\") else pd.read_csv(hist)\n",
    "    df = df.copy()\n",
    "    # epoch\n",
    "    c_epoch = _pick_col(df, [r\"^epoch$\", r\"^epochs?$\"])\n",
    "    epoch = df[c_epoch].to_numpy() if c_epoch else np.arange(1, len(df)+1)\n",
    "    # keys\n",
    "    c_tr_loss = _pick_col(df, [r\"^loss$\", r\"train.*loss\"])\n",
    "    c_va_loss = _pick_col(df, [r\"val.*loss\", r\"valid.*loss\"])\n",
    "    c_tr_acc  = _pick_col(df, [r\"^acc$\", r\"train.*acc\", r\"train.*accuracy\", r\"accuracy$\"])\n",
    "    c_va_acc  = _pick_col(df, [r\"val.*acc\", r\"valid.*acc\", r\"val.*accuracy\", r\"valid.*accuracy\"])\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12,4.5), dpi=160)\n",
    "    if c_tr_loss: ax[0].plot(epoch, df[c_tr_loss], label=\"Train loss\")\n",
    "    if c_va_loss: ax[0].plot(epoch, df[c_va_loss], label=\"Val loss\")\n",
    "    ax[0].set_title(f\"{run_label} – Loss\"); ax[0].set_xlabel(\"Epoch\"); ax[0].set_ylabel(\"Loss\"); ax[0].legend()\n",
    "\n",
    "    if c_tr_acc: ax[1].plot(epoch, df[c_tr_acc], label=\"Train acc\")\n",
    "    if c_va_acc: ax[1].plot(epoch, df[c_va_acc], label=\"Val acc\")\n",
    "    ax[1].set_title(f\"{run_label} – Accuracy\"); ax[1].set_xlabel(\"Epoch\"); ax[1].set_ylabel(\"Acc\"); ax[1].legend()\n",
    "\n",
    "    out_png = os.path.join(IMAGES_DIR, f\"{run_label}_history.png\")\n",
    "    plt.tight_layout(); plt.savefig(out_png, dpi=300, bbox_inches=\"tight\"); plt.show()\n",
    "    print(\"✓ Saved:\", out_png)\n",
    "    return out_png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f884e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 4: Confusion Matrix (chuẩn hoá theo hàng) ====\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, run_label, threshold=0.10, out_dir=IMAGES_DIR):\n",
    "    cm_counts = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
    "    cm = cm_counts.astype(float) / cm_counts.sum(axis=1, keepdims=True)\n",
    "    cm = np.nan_to_num(cm)\n",
    "    fig, ax = plt.subplots(figsize=(14,11), dpi=160)\n",
    "    sns.heatmap(cm, vmin=0, vmax=1, cmap=\"Blues\", square=True,\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'shrink': .6}, ax=ax)\n",
    "    # annotate\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            show = (i==j) or (cm[i,j] >= threshold)\n",
    "            if show and cm_counts[i,j] > 0:\n",
    "                ax.text(j+0.5, i+0.5, f\"{cm[i,j]*100:.0f}%\\n({cm_counts[i,j]})\",\n",
    "                        ha=\"center\", va=\"center\", fontsize=7, color=\"black\")\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "    ax.set_title(f\"Confusion Matrix (row-norm) – {run_label}\")\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=8)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=8)\n",
    "    out_png = os.path.join(out_dir, f\"{run_label}_cm.png\")\n",
    "    plt.tight_layout(); plt.savefig(out_png, dpi=300, bbox_inches=\"tight\"); plt.show()\n",
    "    print(\"✓ Saved:\", out_png)\n",
    "    return out_png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "923c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 5: Top-20 cặp dễ nhầm nhất ====\n",
    "def plot_top_confusions(y_true, y_pred, class_names, topk=20, out_dir=IMAGES_DIR, run_label=\"model\"):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
    "    row_sum = cm.sum(axis=1, keepdims=True).clip(min=1)\n",
    "    cmn = cm / row_sum\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(cmn.shape[0]):\n",
    "        for j in range(cmn.shape[1]):\n",
    "            if i==j: continue\n",
    "            pairs.append((i,j, cmn[i,j], cm[i,j]))  # (true, pred, rate, count)\n",
    "    pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "    pairs = pairs[:topk]\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({\n",
    "        \"True → Pred\": [f\"{class_names[i]} → {class_names[j]}\" for i,j,_,_ in pairs],\n",
    "        \"Nhầm (%)\":   [round(r*100,2) for _,_,r,_ in pairs],\n",
    "        \"Số ảnh\":     [int(c) for *_,c in pairs],\n",
    "    })\n",
    "    display(df)\n",
    "\n",
    "    # Bar chart\n",
    "    fig, ax = plt.subplots(figsize=(11, 0.5*len(df)+1.5), dpi=160)\n",
    "    ax.barh(df[\"True → Pred\"][::-1], df[\"Nhầm (%)\"][::-1])\n",
    "    ax.set_xlabel(\"Tỉ lệ nhầm (%)\"); ax.set_title(f\"Top-{topk} cặp dễ nhầm – {run_label}\")\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(out_dir, f\"{run_label}_top{topk}_confusions.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\"); plt.show()\n",
    "    print(\"✓ Saved:\", out_png)\n",
    "    return out_png, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d155d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 6: Phân tích lỗi – ảnh sai & ví dụ theo cặp ====\n",
    "@torch.no_grad()\n",
    "def collect_preds_with_paths(model, loader, device):\n",
    "    y_true, y_pred, y_prob = [], [], []\n",
    "    paths = extract_paths_from_loader(loader)\n",
    "    n_seen = 0\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        prob = F.softmax(model(x), dim=1).cpu().numpy()\n",
    "        pred = prob.argmax(1)\n",
    "        y_true.append(y.numpy()); y_pred.append(pred); y_prob.append(prob.max(1))\n",
    "        n_seen += y.shape[0]\n",
    "    y_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred); y_prob = np.concatenate(y_prob)\n",
    "    if len(paths) != n_seen: paths = paths[:n_seen]\n",
    "    return y_true, y_pred, y_prob, paths\n",
    "\n",
    "def plot_misclassified_grid(run_label, class_names, y_true, y_pred, y_prob, paths,\n",
    "                            top_k=30, cols=5, out_dir=IMAGES_DIR):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    wrong = np.where(y_true != y_pred)[0]\n",
    "    if wrong.size == 0:\n",
    "        print(f\"[{run_label}] ✅ Không có lỗi.\"); return None\n",
    "    order = wrong[np.argsort(-y_prob[wrong])][:top_k]\n",
    "    rows = math.ceil(len(order)/cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*4, rows*4), dpi=150)\n",
    "    axes = np.array(axes).reshape(rows, cols)\n",
    "    for ax in axes.ravel(): ax.axis(\"off\")\n",
    "    for i, idx in enumerate(order):\n",
    "        r, c = divmod(i, cols); ax = axes[r,c]\n",
    "        try: img = Image.open(paths[idx]).convert(\"RGB\")\n",
    "        except: continue\n",
    "        ax.imshow(img)\n",
    "        t = class_names[y_true[idx]]; p = class_names[y_pred[idx]]; conf = y_prob[idx]\n",
    "        ax.set_title(f\"True: {t}\\nPred: {p} ({conf:.2f})\", fontsize=9)\n",
    "        ax.axis(\"off\")\n",
    "    fig.suptitle(f\"Ảnh dự đoán sai (Top-{len(order)}) – {run_label}\", fontsize=13)\n",
    "    out_png = os.path.join(out_dir, f\"{run_label}_mis_top{len(order)}.png\")\n",
    "    plt.tight_layout(); plt.savefig(out_png, dpi=300, bbox_inches=\"tight\"); plt.show()\n",
    "    print(\"✓ Saved:\", out_png)\n",
    "    return out_png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e7438746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_run(run_path: str):\n",
    "    run_name = os.path.basename(run_path.rstrip(os.sep))\n",
    "    print(f\"▶️ Evaluate: {run_name}\")\n",
    "\n",
    "    # 1) checkpoint & model\n",
    "    ckpt = pick_checkpoint(run_path)\n",
    "    if ckpt is None:\n",
    "        print(f\"  ⚠️ Không thấy checkpoint trong {run_name}.\"); \n",
    "        return None\n",
    "\n",
    "    # 2) test loader\n",
    "    loader, names_from_ds = make_test_loader_safe()\n",
    "\n",
    "    # 3) LẤY CLASS NAMES ĐÚNG THỨ TỰ TRAIN CHO RUN NÀY\n",
    "    run_class_names = load_class_names_for_run(run_path)\n",
    "    if run_class_names is None:\n",
    "        # fallback: nếu bạn đã gán CLASS_NAMES ở Cell khác thì dùng; nếu không dùng từ dataset\n",
    "        run_class_names = CLASS_NAMES or names_from_ds\n",
    "    if run_class_names is None:\n",
    "        raise RuntimeError(\"Không xác định được class_names cho run này.\")\n",
    "\n",
    "    # 4) build & load model đúng num_classes theo run\n",
    "    model = build_model_auto(run_name, num_classes=len(run_class_names))\n",
    "    model = load_checkpoint_to_model(model, ckpt, device).to(device).eval()\n",
    "\n",
    "    # 5) thu thập logits\n",
    "    y_true, y_pred, y_prob = collect_logits(model, loader, device)\n",
    "\n",
    "    # 6) remap y_true từ không gian của dataset.test -> không gian NHÃN THEO RUN\n",
    "    remap = build_remap_from_loader_to_run(loader, run_class_names)\n",
    "    if remap is None:\n",
    "        print(\"  ⚠️ Không tạo được remap đáng tin giữa dataset.test và nhãn theo run. \"\n",
    "              \"Giả định cùng thứ tự. Nếu CM vẫn sai cột, hãy kiểm tra label order.\")\n",
    "    y_true = apply_remap_array(y_true, remap)\n",
    "\n",
    "    # 7) VẼ: ROC, CM, TOP CONFUSIONS, MIS-IMAGES\n",
    "    macro_auc = plot_roc_ovr(y_true, y_prob, run_class_names, run_label=run_name, max_curves=5)\n",
    "    _ = plot_confusion_matrix(y_true, y_pred, run_class_names, run_label=run_name, threshold=0.10)\n",
    "    _ = plot_top_confusions(y_true, y_pred, run_class_names, topk=20, run_label=run_name)\n",
    "    _ = plot_misclassified_grid(\n",
    "            run_name, run_class_names, y_true, y_pred, y_prob.max(1), extract_paths_from_loader(loader))\n",
    "\n",
    "    # 8) Loss/Acc theo epoch (nếu có)\n",
    "    _ = plot_history_from_run(run_path, run_name)\n",
    "\n",
    "    # 9) Tốc độ & tài nguyên\n",
    "    speed = benchmark_model(model, device, input_size=(1,3,INPUT_SIZE,INPUT_SIZE), repeat=60, warmup=12)\n",
    "    params_m = count_params(model)/1e6\n",
    "    size_mb  = file_size_mb(ckpt) or 0.0\n",
    "\n",
    "    result = {\n",
    "        \"run\": run_name,\n",
    "        \"macro_auc\": float(macro_auc),\n",
    "        \"acc\": float((y_true==y_pred).mean()),\n",
    "        \"params(M)\": round(params_m, 2),\n",
    "        \"size(MB)\": round(size_mb, 1),\n",
    "        \"FPS\": round(speed[\"FPS\"], 1),\n",
    "        \"ms_per_img\": round(speed[\"ms_per_img\"], 2)\n",
    "    }\n",
    "    print(\"— Summary:\", result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "feff8451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CELL 8: Đánh giá tất cả runs & vẽ bảng tốc độ/tài nguyên ====\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_all_runs(runs_dir=RUNS_DIR):\n",
    "    if not os.path.isdir(runs_dir):\n",
    "        print(\"⚠️ RUNS_DIR không tồn tại:\", runs_dir); return None\n",
    "    rows = []\n",
    "    for run_name in sorted(os.listdir(runs_dir)):\n",
    "        run_path = os.path.join(runs_dir, run_name)\n",
    "        if not os.path.isdir(run_path): continue\n",
    "        try:\n",
    "            res = evaluate_one_run(run_path)\n",
    "            if res: rows.append(res)\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] Lỗi {run_name}: {e}\")\n",
    "    if not rows:\n",
    "        print(\"⚠️ Không có kết quả.\"); return None\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(\"macro_auc\", ascending=False)\n",
    "    display(df)\n",
    "\n",
    "    # Bảng tốc độ & tài nguyên\n",
    "    plot_speed_table(\n",
    "        rows=[{\"run\":r[\"run\"], \"FPS\":r[\"FPS\"], \"ms_per_img\":r[\"ms_per_img\"],\n",
    "               \"params(M)\":f'{r[\"params(M)\"]:.2f}M', \"size(MB)\":f'{r[\"size(MB)\"]:.1f} MB'}\n",
    "              for r in rows],\n",
    "        title=\"Speed & Resource Summary\"\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "305b79d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Evaluate: mtl-cnn\n",
      "[auto_model] thử mobilenet_v4 lỗi: No module named 'mobilenet_v4'\n",
      "[auto_model] thử efficientnet_b0 lỗi: No module named 'efficientnet_b0'\n",
      "[auto_model] thử mtl_cnn lỗi: No module named 'mtl_cnn'\n",
      "[warn] Lỗi mtl-cnn: Không build được model cho run 'mtl-cnn'. Đã thử: ['mobilenet_v4', 'efficientnet_b0', 'mtl_cnn']\n",
      "▶️ Evaluate: mtl-efficientnet_b0\n",
      "[auto_model] đoán theo tên thất bại: No module named 'CustomEfficientNetB0'\n",
      "[auto_model] thử mobilenet_v4 lỗi: No module named 'mobilenet_v4'\n",
      "[auto_model] thử efficientnet_b0 lỗi: No module named 'efficientnet_b0'\n",
      "[auto_model] thử mtl_cnn lỗi: No module named 'mtl_cnn'\n",
      "[warn] Lỗi mtl-efficientnet_b0: Không build được model cho run 'mtl-efficientnet_b0'. Đã thử: ['CustomEfficientNetB0', 'mobilenet_v4', 'efficientnet_b0', 'mtl_cnn']\n",
      "▶️ Evaluate: mtl-mobilenetv4\n",
      "[auto_model] đoán theo tên thất bại: No module named 'mobilenet_v4'\n",
      "[auto_model] thử mobilenet_v4 lỗi: No module named 'mobilenet_v4'\n",
      "[auto_model] thử efficientnet_b0 lỗi: No module named 'efficientnet_b0'\n",
      "[auto_model] thử mtl_cnn lỗi: No module named 'mtl_cnn'\n",
      "[warn] Lỗi mtl-mobilenetv4: Không build được model cho run 'mtl-mobilenetv4'. Đã thử: ['mobilenet_v4', 'mobilenet_v4', 'efficientnet_b0', 'mtl_cnn']\n",
      "⚠️ Không có kết quả.\n"
     ]
    }
   ],
   "source": [
    "# ==== CELL 9: GỌI CHẠY ====\n",
    "\n",
    "# Cách 1: Chạy 1 mô hình (điền đúng tên thư mục run)\n",
    "# _ = evaluate_one_run(os.path.join(RUNS_DIR, \"mtl-efficientnet_b0-20251029-233246\"))\n",
    "\n",
    "# Cách 2: Chạy tất cả mô hình trong RUNS_DIR\n",
    "_ = evaluate_all_runs(RUNS_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
